{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O6yce3zIOLoK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52tejXgkOLoP",
        "outputId": "50f24ca8-0a88-408e-b3f5-d5e19d635c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_zip = keras.utils.get_file('spa-eng.zip', origin='https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ceQPf7WmOLoS",
        "outputId": "5a6af7ae-8e27-4692-e08a-4ce9ccdd63ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng.zip'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_to_zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EvP9MIIgOLoU",
        "outputId": "c5bc72b1-6c04-464d-ed6a-e7a6ad62b5fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_to_file=os.path.join(os.path.dirname(path_to_zip),'spa-eng','spa.txt')\n",
        "path_to_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JHck7eUbOLoV"
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wsb5y6odOLoW"
      },
      "outputs": [],
      "source": [
        "def preprocess_senetence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.~,])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.~,]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    w = '<strat> ' + w + ' <end>'\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XagA1y16OLoX",
        "outputId": "e271316f-299d-40ff-d98e-58efaa0c5d84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<strat> i have some friends to help . <end>'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_sentence = \"I have some friends to help.\"\n",
        "preprocess_senetence(en_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5UCvsGI8OLoY",
        "outputId": "ea527ecd-762a-4ee8-b84b-7c95b76ac60d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<strat> aun no he dicho nada . <end>'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sp_sentence = \"AÃºn no he dicho nada.\"\n",
        "preprocess_senetence(sp_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_IEz-ezsOLoa"
      },
      "outputs": [],
      "source": [
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = [[preprocess_senetence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "    return zip(*word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBR0hCegOLob",
        "outputId": "fb2a140c-ccbf-4592-8550-42ab9c8761a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<zip object at 0x7b086e1581c0>\n"
          ]
        }
      ],
      "source": [
        "print(create_dataset(path_to_file, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0P2gTpk0OLoc"
      },
      "outputs": [],
      "source": [
        "en, sp = create_dataset(path_to_file, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en5o2FEOLod",
        "outputId": "ae888cdf-b7cd-47f4-e8c4-a8b9bb958e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(118964, 118964)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(en),len(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OZNepkpBOLod"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6IA1ovAuOLoe"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jcGdft3OLof"
      },
      "source": [
        "equal = to words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EYsWR8cbOLok"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HaBkQN-MOLol"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, target_lang_tokenizer = tokenize(targ_lang)\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, target_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Sr_p6XpAOLom"
      },
      "outputs": [],
      "source": [
        "input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer = load_dataset(path_to_file, 20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7IEqfZd-OLom"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFcXJdjvOLon",
        "outputId": "ce9e3a72-9668-4259-f6e6-a7cef021283b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  1,  97,   3, ...,   0,   0,   0],\n",
              "       [  1, 179,   3, ...,   0,   0,   0],\n",
              "       [  1, 466,   3, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  1,   7,  10, ...,   0,   0,   0],\n",
              "       [  1,   7,  10, ...,   0,   0,   0],\n",
              "       [  1,   7,  10, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yangh7cgOLoo"
      },
      "outputs": [],
      "source": [
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "21e307-8OLoq"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ia4gW0UmOLoq"
      },
      "outputs": [],
      "source": [
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t != 0:\n",
        "            print(t, ' .... ', lang.index_word[t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PICoSWp6OLor",
        "outputId": "d8e6a496-06f1-4e6e-c539-241509b9e08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1  ....  <strat>\n",
            "97  ....  ve\n",
            "3  ....  .\n",
            "2  ....  <end>\n"
          ]
        }
      ],
      "source": [
        "convert(input_lang_tokenizer, input_tensor[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHiqpfidOLos",
        "outputId": "5f6296fa-6f31-42d6-c619-7cddbc4669f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1, 97,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tensor[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edYQr56pOLot",
        "outputId": "a580c0a9-118e-45a8-a4af-568bd6b5354a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<strat>': 1,\n",
              " '<end>': 2,\n",
              " '.': 3,\n",
              " 'i': 4,\n",
              " 'you': 5,\n",
              " '?': 6,\n",
              " 'tom': 7,\n",
              " 'is': 8,\n",
              " 'it': 9,\n",
              " 's': 10,\n",
              " 'a': 11,\n",
              " 'he': 12,\n",
              " 't': 13,\n",
              " 'the': 14,\n",
              " 'we': 15,\n",
              " 'm': 16,\n",
              " 'me': 17,\n",
              " 're': 18,\n",
              " 'that': 19,\n",
              " 'this': 20,\n",
              " 'to': 21,\n",
              " 'do': 22,\n",
              " 'are': 23,\n",
              " 'can': 24,\n",
              " 'my': 25,\n",
              " 'they': 26,\n",
              " 'was': 27,\n",
              " 'she': 28,\n",
              " 'don': 29,\n",
              " 'have': 30,\n",
              " 'your': 31,\n",
              " 'go': 32,\n",
              " 'what': 33,\n",
              " 'in': 34,\n",
              " 'not': 35,\n",
              " 'll': 36,\n",
              " 'like': 37,\n",
              " 'here': 38,\n",
              " 'on': 39,\n",
              " 'him': 40,\n",
              " 'let': 41,\n",
              " 'be': 42,\n",
              " 'did': 43,\n",
              " 'know': 44,\n",
              " 'come': 45,\n",
              " 'up': 46,\n",
              " 'am': 47,\n",
              " 'want': 48,\n",
              " 'how': 49,\n",
              " ',': 50,\n",
              " 'mary': 51,\n",
              " 'get': 52,\n",
              " 'who': 53,\n",
              " 'very': 54,\n",
              " 'now': 55,\n",
              " 'need': 56,\n",
              " 'has': 57,\n",
              " 'please': 58,\n",
              " 'no': 59,\n",
              " 'there': 60,\n",
              " 'help': 61,\n",
              " 'her': 62,\n",
              " 'love': 63,\n",
              " 'at': 64,\n",
              " 'see': 65,\n",
              " 'just': 66,\n",
              " 'out': 67,\n",
              " 'his': 68,\n",
              " 've': 69,\n",
              " 'got': 70,\n",
              " 'for': 71,\n",
              " 'where': 72,\n",
              " 'look': 73,\n",
              " 'stop': 74,\n",
              " 'one': 75,\n",
              " 'us': 76,\n",
              " 'good': 77,\n",
              " 'car': 78,\n",
              " 'too': 79,\n",
              " 'so': 80,\n",
              " 'all': 81,\n",
              " 'why': 82,\n",
              " 'will': 83,\n",
              " 'an': 84,\n",
              " 'home': 85,\n",
              " 'of': 86,\n",
              " 'with': 87,\n",
              " 'give': 88,\n",
              " 'back': 89,\n",
              " 'were': 90,\n",
              " 'keep': 91,\n",
              " 'take': 92,\n",
              " 'dog': 93,\n",
              " 'saw': 94,\n",
              " 'didn': 95,\n",
              " 'isn': 96,\n",
              " 'may': 97,\n",
              " 'happy': 98,\n",
              " 'stay': 99,\n",
              " 'won': 100,\n",
              " 'work': 101,\n",
              " 'hate': 102,\n",
              " 'must': 103,\n",
              " 'wait': 104,\n",
              " 'leave': 105,\n",
              " 'again': 106,\n",
              " 'likes': 107,\n",
              " 'down': 108,\n",
              " 'feel': 109,\n",
              " 'book': 110,\n",
              " 'try': 111,\n",
              " 'made': 112,\n",
              " 'eat': 113,\n",
              " 'right': 114,\n",
              " 'them': 115,\n",
              " 'still': 116,\n",
              " 'had': 117,\n",
              " 'time': 118,\n",
              " 'going': 119,\n",
              " 'does': 120,\n",
              " 'money': 121,\n",
              " 'call': 122,\n",
              " 'say': 123,\n",
              " 'lost': 124,\n",
              " 'came': 125,\n",
              " 'tell': 126,\n",
              " 'went': 127,\n",
              " 'well': 128,\n",
              " 'today': 129,\n",
              " 'old': 130,\n",
              " 'busy': 131,\n",
              " 'looks': 132,\n",
              " 'ask': 133,\n",
              " 'away': 134,\n",
              " 'loves': 135,\n",
              " 'job': 136,\n",
              " 'man': 137,\n",
              " 'bad': 138,\n",
              " 'everyone': 139,\n",
              " 'never': 140,\n",
              " 'some': 141,\n",
              " 'over': 142,\n",
              " 'pay': 143,\n",
              " 'mine': 144,\n",
              " 'from': 145,\n",
              " 'ready': 146,\n",
              " 'alone': 147,\n",
              " 'read': 148,\n",
              " 'wrong': 149,\n",
              " 'room': 150,\n",
              " 'live': 151,\n",
              " 'angry': 152,\n",
              " 'tired': 153,\n",
              " 'talk': 154,\n",
              " 'more': 155,\n",
              " 'make': 156,\n",
              " 'could': 157,\n",
              " 'about': 158,\n",
              " 'nice': 159,\n",
              " 'nobody': 160,\n",
              " 'off': 161,\n",
              " 'french': 162,\n",
              " 'house': 163,\n",
              " 'hurt': 164,\n",
              " 'speak': 165,\n",
              " 'watch': 166,\n",
              " 'should': 167,\n",
              " 'left': 168,\n",
              " 'cold': 169,\n",
              " 'big': 170,\n",
              " 'late': 171,\n",
              " 'play': 172,\n",
              " 'new': 173,\n",
              " 'true': 174,\n",
              " 'and': 175,\n",
              " 'drink': 176,\n",
              " 'life': 177,\n",
              " 'our': 178,\n",
              " 'drunk': 179,\n",
              " 'lot': 180,\n",
              " 'open': 181,\n",
              " 'said': 182,\n",
              " 'these': 183,\n",
              " 'wasn': 184,\n",
              " 'boston': 185,\n",
              " 'way': 186,\n",
              " 'fast': 187,\n",
              " 'boy': 188,\n",
              " 'nothing': 189,\n",
              " 'turn': 190,\n",
              " 'understand': 191,\n",
              " 'ok': 192,\n",
              " 'hungry': 193,\n",
              " 'wants': 194,\n",
              " 'when': 195,\n",
              " 'really': 196,\n",
              " 'ate': 197,\n",
              " 'hurry': 198,\n",
              " 'died': 199,\n",
              " 'hot': 200,\n",
              " 'felt': 201,\n",
              " 'think': 202,\n",
              " 'name': 203,\n",
              " 'find': 204,\n",
              " 'sick': 205,\n",
              " 'yours': 206,\n",
              " 'everybody': 207,\n",
              " 'sit': 208,\n",
              " 'gave': 209,\n",
              " 'smart': 210,\n",
              " 'answer': 211,\n",
              " 'broke': 212,\n",
              " 'aren': 213,\n",
              " 'been': 214,\n",
              " 'hold': 215,\n",
              " 'miss': 216,\n",
              " 'stupid': 217,\n",
              " 'fun': 218,\n",
              " 'done': 219,\n",
              " 'sleep': 220,\n",
              " 'everything': 221,\n",
              " 'already': 222,\n",
              " 'listen': 223,\n",
              " 'fine': 224,\n",
              " 'bed': 225,\n",
              " 'first': 226,\n",
              " 'much': 227,\n",
              " 'sing': 228,\n",
              " 'loved': 229,\n",
              " 'coming': 230,\n",
              " 'great': 231,\n",
              " 'bought': 232,\n",
              " 'two': 233,\n",
              " 'father': 234,\n",
              " 'long': 235,\n",
              " 'cry': 236,\n",
              " 'married': 237,\n",
              " 'cat': 238,\n",
              " 'best': 239,\n",
              " 'tv': 240,\n",
              " 'hear': 241,\n",
              " 'friend': 242,\n",
              " 'ran': 243,\n",
              " 'stand': 244,\n",
              " 'crazy': 245,\n",
              " 'knows': 246,\n",
              " 'mad': 247,\n",
              " 'swim': 248,\n",
              " 'close': 249,\n",
              " 'idea': 250,\n",
              " 'easy': 251,\n",
              " 'rich': 252,\n",
              " 'hard': 253,\n",
              " 'walk': 254,\n",
              " 'start': 255,\n",
              " 'kill': 256,\n",
              " 'run': 257,\n",
              " 'put': 258,\n",
              " 'knew': 259,\n",
              " 'both': 260,\n",
              " 'doctor': 261,\n",
              " 'needs': 262,\n",
              " 'something': 263,\n",
              " 'almost': 264,\n",
              " 'wife': 265,\n",
              " 'only': 266,\n",
              " 'hair': 267,\n",
              " 'show': 268,\n",
              " 'by': 269,\n",
              " 'sad': 270,\n",
              " 'move': 271,\n",
              " 'remember': 272,\n",
              " 'dead': 273,\n",
              " 'gone': 274,\n",
              " 'crying': 275,\n",
              " 'drive': 276,\n",
              " 'free': 277,\n",
              " 'write': 278,\n",
              " 'school': 279,\n",
              " 'pretty': 280,\n",
              " 'those': 281,\n",
              " 'doesn': 282,\n",
              " 'trust': 283,\n",
              " 'tall': 284,\n",
              " 'd': 285,\n",
              " 'better': 286,\n",
              " 'friends': 287,\n",
              " 'fat': 288,\n",
              " 'sat': 289,\n",
              " 'bus': 290,\n",
              " 'bit': 291,\n",
              " 'heard': 292,\n",
              " 'water': 293,\n",
              " 'lie': 294,\n",
              " 'early': 295,\n",
              " 'called': 296,\n",
              " 'die': 297,\n",
              " 'hand': 298,\n",
              " 'met': 299,\n",
              " 'yourself': 300,\n",
              " 'bag': 301,\n",
              " 'teacher': 302,\n",
              " 'eyes': 303,\n",
              " 'bring': 304,\n",
              " 'lying': 305,\n",
              " 'yes': 306,\n",
              " 'day': 307,\n",
              " 'door': 308,\n",
              " 'believe': 309,\n",
              " 'doing': 310,\n",
              " 'enemy': 311,\n",
              " 'mean': 312,\n",
              " 'soon': 313,\n",
              " 'dogs': 314,\n",
              " 'wine': 315,\n",
              " 'buy': 316,\n",
              " 'as': 317,\n",
              " 'young': 318,\n",
              " 'monday': 319,\n",
              " 'singing': 320,\n",
              " 'red': 321,\n",
              " 'helped': 322,\n",
              " 'looked': 323,\n",
              " 'afraid': 324,\n",
              " 'someone': 325,\n",
              " 'quit': 326,\n",
              " 'guys': 327,\n",
              " 'use': 328,\n",
              " 'follow': 329,\n",
              " 'food': 330,\n",
              " 'found': 331,\n",
              " 'lucky': 332,\n",
              " 'key': 333,\n",
              " 'lunch': 334,\n",
              " 'tomorrow': 335,\n",
              " 'coffee': 336,\n",
              " 'kind': 337,\n",
              " 'hit': 338,\n",
              " 'safe': 339,\n",
              " 'forget': 340,\n",
              " 'study': 341,\n",
              " 'later': 342,\n",
              " 'whose': 343,\n",
              " 'seen': 344,\n",
              " 'enough': 345,\n",
              " 'running': 346,\n",
              " 'small': 347,\n",
              " 'son': 348,\n",
              " 'always': 349,\n",
              " 'enjoy': 350,\n",
              " 'might': 351,\n",
              " 'hope': 352,\n",
              " 'awake': 353,\n",
              " 'shot': 354,\n",
              " 'told': 355,\n",
              " 'fish': 356,\n",
              " 'arrived': 357,\n",
              " 'hat': 358,\n",
              " 'break': 359,\n",
              " 'short': 360,\n",
              " 'took': 361,\n",
              " 'quiet': 362,\n",
              " 'next': 363,\n",
              " 'works': 364,\n",
              " 'eating': 365,\n",
              " 'night': 366,\n",
              " 'asked': 367,\n",
              " 'cats': 368,\n",
              " 'milk': 369,\n",
              " 'seems': 370,\n",
              " 'dream': 371,\n",
              " 'dinner': 372,\n",
              " 'watching': 373,\n",
              " 'mother': 374,\n",
              " 'began': 375,\n",
              " 'thanks': 376,\n",
              " 'cool': 377,\n",
              " 'care': 378,\n",
              " 'real': 379,\n",
              " 'hurts': 380,\n",
              " 'cook': 381,\n",
              " 'check': 382,\n",
              " 'beer': 383,\n",
              " 'smoke': 384,\n",
              " 'hide': 385,\n",
              " 'fired': 386,\n",
              " 'rain': 387,\n",
              " 'send': 388,\n",
              " 'changed': 389,\n",
              " 'myself': 390,\n",
              " 'talking': 391,\n",
              " 'fault': 392,\n",
              " 'which': 393,\n",
              " 'hands': 394,\n",
              " 'yet': 395,\n",
              " 'brave': 396,\n",
              " 'full': 397,\n",
              " 'around': 398,\n",
              " 'liked': 399,\n",
              " 'problem': 400,\n",
              " 'win': 401,\n",
              " 'seat': 402,\n",
              " 'joking': 403,\n",
              " 'broken': 404,\n",
              " 'secret': 405,\n",
              " 'rest': 406,\n",
              " 'books': 407,\n",
              " 'hates': 408,\n",
              " 'english': 409,\n",
              " 'owe': 410,\n",
              " 'girl': 411,\n",
              " 'family': 412,\n",
              " 'would': 413,\n",
              " 'fell': 414,\n",
              " 'shy': 415,\n",
              " 'sorry': 416,\n",
              " 'along': 417,\n",
              " 'men': 418,\n",
              " 'kids': 419,\n",
              " 'naive': 420,\n",
              " 'reading': 421,\n",
              " 'working': 422,\n",
              " 'joke': 423,\n",
              " 'clean': 424,\n",
              " 'sure': 425,\n",
              " 'word': 426,\n",
              " 'little': 427,\n",
              " 'lied': 428,\n",
              " 'calm': 429,\n",
              " 'forgot': 430,\n",
              " 'warm': 431,\n",
              " 'patient': 432,\n",
              " 'missed': 433,\n",
              " 'begin': 434,\n",
              " 'snow': 435,\n",
              " 'needed': 436,\n",
              " 'woman': 437,\n",
              " 'lawyer': 438,\n",
              " 'beautiful': 439,\n",
              " 'happen': 440,\n",
              " 'kept': 441,\n",
              " 'lives': 442,\n",
              " 'child': 443,\n",
              " 'person': 444,\n",
              " 'tried': 445,\n",
              " 'shut': 446,\n",
              " 'fix': 447,\n",
              " 'failed': 448,\n",
              " 'hey': 449,\n",
              " 'promised': 450,\n",
              " 'anybody': 451,\n",
              " 'change': 452,\n",
              " 'funny': 453,\n",
              " 'once': 454,\n",
              " 'pen': 455,\n",
              " 'drank': 456,\n",
              " 'things': 457,\n",
              " 'plan': 458,\n",
              " 'own': 459,\n",
              " 'insane': 460,\n",
              " 'truth': 461,\n",
              " 'game': 462,\n",
              " 'born': 463,\n",
              " 'hang': 464,\n",
              " 'wake': 465,\n",
              " 'smiled': 466,\n",
              " 'cut': 467,\n",
              " 'boring': 468,\n",
              " 'empty': 469,\n",
              " 'kidding': 470,\n",
              " 'smell': 471,\n",
              " 'meet': 472,\n",
              " 'happened': 473,\n",
              " 'wish': 474,\n",
              " 'blue': 475,\n",
              " 'outside': 476,\n",
              " 'studying': 477,\n",
              " 'useless': 478,\n",
              " 'box': 479,\n",
              " 'somebody': 480,\n",
              " 'clever': 481,\n",
              " 'shoes': 482,\n",
              " 'fire': 483,\n",
              " 'moved': 484,\n",
              " 'perfect': 485,\n",
              " 'kiss': 486,\n",
              " 'laughed': 487,\n",
              " 'blind': 488,\n",
              " 'far': 489,\n",
              " 'worked': 490,\n",
              " 'dark': 491,\n",
              " 'thank': 492,\n",
              " 'anyone': 493,\n",
              " 'meat': 494,\n",
              " 'hiding': 495,\n",
              " 'alive': 496,\n",
              " 'white': 497,\n",
              " 'dance': 498,\n",
              " 'cheated': 499,\n",
              " 'confused': 500,\n",
              " 'black': 501,\n",
              " 'sweet': 502,\n",
              " 'cake': 503,\n",
              " 'japanese': 504,\n",
              " 'people': 505,\n",
              " 'raining': 506,\n",
              " 'minute': 507,\n",
              " 'keys': 508,\n",
              " 'breath': 509,\n",
              " 'idiot': 510,\n",
              " 'phone': 511,\n",
              " 'betrayed': 512,\n",
              " 'story': 513,\n",
              " 'hi': 514,\n",
              " 'agree': 515,\n",
              " 'cute': 516,\n",
              " 'save': 517,\n",
              " 'fly': 518,\n",
              " 'slowly': 519,\n",
              " 'tea': 520,\n",
              " 'single': 521,\n",
              " 'fight': 522,\n",
              " 'blame': 523,\n",
              " 'trapped': 524,\n",
              " 'party': 525,\n",
              " 'face': 526,\n",
              " 'rules': 527,\n",
              " 'music': 528,\n",
              " 'lonely': 529,\n",
              " 'last': 530,\n",
              " 'stopped': 531,\n",
              " 'explain': 532,\n",
              " 'asleep': 533,\n",
              " 'six': 534,\n",
              " 'guy': 535,\n",
              " 'brother': 536,\n",
              " 'any': 537,\n",
              " 'place': 538,\n",
              " 'started': 539,\n",
              " 'beat': 540,\n",
              " 'deep': 541,\n",
              " 'talked': 542,\n",
              " 'warn': 543,\n",
              " 'dying': 544,\n",
              " 'sign': 545,\n",
              " 'ice': 546,\n",
              " 'wrote': 547,\n",
              " 'count': 548,\n",
              " 'finish': 549,\n",
              " 'dumb': 550,\n",
              " 'often': 551,\n",
              " 'naked': 552,\n",
              " 'waiting': 553,\n",
              " 'anything': 554,\n",
              " 'became': 555,\n",
              " 'bath': 556,\n",
              " 'sang': 557,\n",
              " 'light': 558,\n",
              " 'listening': 559,\n",
              " 'touch': 560,\n",
              " 'head': 561,\n",
              " 'seem': 562,\n",
              " 'glasses': 563,\n",
              " 'sounds': 564,\n",
              " 'tie': 565,\n",
              " 'into': 566,\n",
              " 'couldn': 567,\n",
              " 'mouth': 568,\n",
              " 'being': 569,\n",
              " 'speaks': 570,\n",
              " 'slept': 571,\n",
              " 'welcome': 572,\n",
              " 'bald': 573,\n",
              " 'weak': 574,\n",
              " 'helps': 575,\n",
              " 'paid': 576,\n",
              " 'after': 577,\n",
              " 'inside': 578,\n",
              " 'cried': 579,\n",
              " 'forgive': 580,\n",
              " 'god': 581,\n",
              " 'survived': 582,\n",
              " 'moving': 583,\n",
              " 'sleepy': 584,\n",
              " 'green': 585,\n",
              " 'curious': 586,\n",
              " 'excited': 587,\n",
              " 'doll': 588,\n",
              " 'pain': 589,\n",
              " 'another': 590,\n",
              " 'arm': 591,\n",
              " 'losing': 592,\n",
              " 'fill': 593,\n",
              " 'gun': 594,\n",
              " 'comes': 595,\n",
              " 'tennis': 596,\n",
              " 'week': 597,\n",
              " 'advice': 598,\n",
              " 'important': 599,\n",
              " 'horse': 600,\n",
              " 'dry': 601,\n",
              " 'learn': 602,\n",
              " 'turned': 603,\n",
              " 'fishing': 604,\n",
              " 'canadian': 605,\n",
              " 'summer': 606,\n",
              " 'choice': 607,\n",
              " 'quite': 608,\n",
              " 'war': 609,\n",
              " 'cannot': 610,\n",
              " 'paper': 611,\n",
              " 'three': 612,\n",
              " 'smile': 613,\n",
              " 'fair': 614,\n",
              " 'catch': 615,\n",
              " 'weird': 616,\n",
              " 'ours': 617,\n",
              " 'careful': 618,\n",
              " 'serious': 619,\n",
              " 'hero': 620,\n",
              " 'liar': 621,\n",
              " 'normal': 622,\n",
              " 'trying': 623,\n",
              " 'cheese': 624,\n",
              " 'walked': 625,\n",
              " 'strong': 626,\n",
              " 'song': 627,\n",
              " 'shall': 628,\n",
              " 'sleeping': 629,\n",
              " 'horses': 630,\n",
              " 'student': 631,\n",
              " 'forgetful': 632,\n",
              " 'together': 633,\n",
              " 'second': 634,\n",
              " 'luck': 635,\n",
              " 'raise': 636,\n",
              " 'mistake': 637,\n",
              " 'clock': 638,\n",
              " 'trouble': 639,\n",
              " 'end': 640,\n",
              " 'getting': 641,\n",
              " 'noise': 642,\n",
              " 'maybe': 643,\n",
              " 'brown': 644,\n",
              " 'himself': 645,\n",
              " 'shirt': 646,\n",
              " 'okay': 647,\n",
              " 'poor': 648,\n",
              " 'doubt': 649,\n",
              " 'laugh': 650,\n",
              " 'strange': 651,\n",
              " 'news': 652,\n",
              " 'baffled': 653,\n",
              " 'cooking': 654,\n",
              " 'nervous': 655,\n",
              " 'worried': 656,\n",
              " 'mess': 657,\n",
              " 'invited': 658,\n",
              " 'quickly': 659,\n",
              " 'apples': 660,\n",
              " 'women': 661,\n",
              " 'thrilled': 662,\n",
              " 'writing': 663,\n",
              " 'closed': 664,\n",
              " 'boss': 665,\n",
              " 'thirsty': 666,\n",
              " 'deal': 667,\n",
              " 'satisfied': 668,\n",
              " 'worse': 669,\n",
              " 'duty': 670,\n",
              " 'simple': 671,\n",
              " 'cup': 672,\n",
              " 'also': 673,\n",
              " 'truck': 674,\n",
              " 'if': 675,\n",
              " 'throw': 676,\n",
              " 'killed': 677,\n",
              " 'apple': 678,\n",
              " 'letter': 679,\n",
              " 'sister': 680,\n",
              " 'teeth': 681,\n",
              " 'bicycle': 682,\n",
              " 'easily': 683,\n",
              " 'jump': 684,\n",
              " 'join': 685,\n",
              " 'wash': 686,\n",
              " 'waited': 687,\n",
              " 'ignore': 688,\n",
              " 'walks': 689,\n",
              " 'cruel': 690,\n",
              " 'bored': 691,\n",
              " 'town': 692,\n",
              " 'bread': 693,\n",
              " 'soup': 694,\n",
              " 'gas': 695,\n",
              " 'saved': 696,\n",
              " 'many': 697,\n",
              " 'kissed': 698,\n",
              " 'team': 699,\n",
              " 'bear': 700,\n",
              " 'trap': 701,\n",
              " 'snowing': 702,\n",
              " 'smoking': 703,\n",
              " 'pale': 704,\n",
              " 'dad': 705,\n",
              " 'nose': 706,\n",
              " 'kid': 707,\n",
              " 'trusted': 708,\n",
              " 'watched': 709,\n",
              " 'robbed': 710,\n",
              " 'favor': 711,\n",
              " 'feeling': 712,\n",
              " 'undressing': 713,\n",
              " 'used': 714,\n",
              " 'cheap': 715,\n",
              " 'wonderful': 716,\n",
              " 'heart': 717,\n",
              " 'blew': 718,\n",
              " 'swimming': 719,\n",
              " 'paris': 720,\n",
              " 'side': 721,\n",
              " 'lit': 722,\n",
              " 'embarrassed': 723,\n",
              " 'tonight': 724,\n",
              " 'voice': 725,\n",
              " 'table': 726,\n",
              " 'park': 727,\n",
              " 'parents': 728,\n",
              " 'drop': 729,\n",
              " 'ahead': 730,\n",
              " 'agreed': 731,\n",
              " 'birds': 732,\n",
              " 'step': 733,\n",
              " 'stood': 734,\n",
              " 'ill': 735,\n",
              " 'prepared': 736,\n",
              " 'closer': 737,\n",
              " 'hated': 738,\n",
              " 'share': 739,\n",
              " 'dancing': 740,\n",
              " 'healthy': 741,\n",
              " 'talks': 742,\n",
              " 'woke': 743,\n",
              " 'cheered': 744,\n",
              " 'evil': 745,\n",
              " 'half': 746,\n",
              " 'jealous': 747,\n",
              " 'divorced': 748,\n",
              " 'angel': 749,\n",
              " 'looking': 750,\n",
              " 'control': 751,\n",
              " 'dreaming': 752,\n",
              " 'caught': 753,\n",
              " 'rope': 754,\n",
              " 'accept': 755,\n",
              " 'mom': 756,\n",
              " 'budge': 757,\n",
              " 'danger': 758,\n",
              " 'copy': 759,\n",
              " 'japan': 760,\n",
              " 'law': 761,\n",
              " 'map': 762,\n",
              " 'dirty': 763,\n",
              " 'winning': 764,\n",
              " 'form': 765,\n",
              " 'rather': 766,\n",
              " 'baby': 767,\n",
              " 'excuse': 768,\n",
              " 'continue': 769,\n",
              " 'thirty': 770,\n",
              " 'wanted': 771,\n",
              " 'surprised': 772,\n",
              " 'bank': 773,\n",
              " 'brush': 774,\n",
              " 'legs': 775,\n",
              " 'interfering': 776,\n",
              " 'ridiculous': 777,\n",
              " 'relax': 778,\n",
              " 'slow': 779,\n",
              " 'goodbye': 780,\n",
              " 'wet': 781,\n",
              " 'grab': 782,\n",
              " 'spoke': 783,\n",
              " 'runs': 784,\n",
              " 'fantastic': 785,\n",
              " 'hers': 786,\n",
              " 'tight': 787,\n",
              " 'drove': 788,\n",
              " 'screamed': 789,\n",
              " 'scared': 790,\n",
              " 'cheat': 791,\n",
              " 'glad': 792,\n",
              " 'shoot': 793,\n",
              " 'grew': 794,\n",
              " 'cars': 795,\n",
              " 'nuts': 796,\n",
              " 'age': 797,\n",
              " 'or': 798,\n",
              " 'mind': 799,\n",
              " 'innocent': 800,\n",
              " 'restless': 801,\n",
              " 'closely': 802,\n",
              " 'leg': 803,\n",
              " 'point': 804,\n",
              " 'ended': 805,\n",
              " 'dreams': 806,\n",
              " 'bird': 807,\n",
              " 'type': 808,\n",
              " 'american': 809,\n",
              " 'guilty': 810,\n",
              " 'finally': 811,\n",
              " 'soccer': 812,\n",
              " 'spring': 813,\n",
              " 'behind': 814,\n",
              " 'exhausted': 815,\n",
              " 'babbling': 816,\n",
              " 'ball': 817,\n",
              " 'knife': 818,\n",
              " 'genius': 819,\n",
              " 'glass': 820,\n",
              " 'laughing': 821,\n",
              " 'sugar': 822,\n",
              " 'correct': 823,\n",
              " 'says': 824,\n",
              " 'seemed': 825,\n",
              " 'brothers': 826,\n",
              " 'husband': 827,\n",
              " 'breathe': 828,\n",
              " 'writes': 829,\n",
              " 'matter': 830,\n",
              " 'cousin': 831,\n",
              " 'proud': 832,\n",
              " 'yesterday': 833,\n",
              " 'taught': 834,\n",
              " 'train': 835,\n",
              " 'oh': 836,\n",
              " 'bowed': 837,\n",
              " 'phoned': 838,\n",
              " 'refuse': 839,\n",
              " 'stayed': 840,\n",
              " 'lazy': 841,\n",
              " 'lies': 842,\n",
              " 'fainted': 843,\n",
              " 'then': 844,\n",
              " 'carry': 845,\n",
              " 'envy': 846,\n",
              " 'eaten': 847,\n",
              " 'sharp': 848,\n",
              " 'jumped': 849,\n",
              " 'even': 850,\n",
              " 'worry': 851,\n",
              " 'fruit': 852,\n",
              " 'rice': 853,\n",
              " 'golf': 854,\n",
              " 'unlucky': 855,\n",
              " 'escaped': 856,\n",
              " 'refused': 857,\n",
              " 'annoying': 858,\n",
              " 'doubts': 859,\n",
              " 'misled': 860,\n",
              " 'sue': 861,\n",
              " 'ears': 862,\n",
              " 'pregnant': 863,\n",
              " 'worn': 864,\n",
              " 'amazing': 865,\n",
              " 'smiling': 866,\n",
              " 'feet': 867,\n",
              " 'command': 868,\n",
              " 'built': 869,\n",
              " 'sent': 870,\n",
              " 'deny': 871,\n",
              " 'sells': 872,\n",
              " 'fear': 873,\n",
              " 'nearly': 874,\n",
              " 'rescued': 875,\n",
              " 'allow': 876,\n",
              " 'diet': 877,\n",
              " 'famous': 878,\n",
              " 'gets': 879,\n",
              " 'hoax': 880,\n",
              " 'unfair': 881,\n",
              " 'lock': 882,\n",
              " 'number': 883,\n",
              " 'stingy': 884,\n",
              " 'helping': 885,\n",
              " 'special': 886,\n",
              " 'kite': 887,\n",
              " 'sons': 888,\n",
              " 'sun': 889,\n",
              " 'teach': 890,\n",
              " 'heavy': 891,\n",
              " 'desk': 892,\n",
              " 'cooks': 893,\n",
              " 'bike': 894,\n",
              " 'ticket': 895,\n",
              " 'creep': 896,\n",
              " 'bite': 897,\n",
              " 'carefully': 898,\n",
              " 'honest': 899,\n",
              " 'death': 900,\n",
              " 'fever': 901,\n",
              " 'policeman': 902,\n",
              " 'defenseless': 903,\n",
              " 'dangerous': 904,\n",
              " 'radio': 905,\n",
              " 'sky': 906,\n",
              " 'cap': 907,\n",
              " 'singer': 908,\n",
              " 'hotel': 909,\n",
              " 'drinking': 910,\n",
              " 'intelligent': 911,\n",
              " 'pick': 912,\n",
              " 'housesitting': 913,\n",
              " 'children': 914,\n",
              " 'thing': 915,\n",
              " 'weren': 916,\n",
              " 'stuck': 917,\n",
              " 'fit': 918,\n",
              " 'brief': 919,\n",
              " 'awful': 920,\n",
              " 'burned': 921,\n",
              " 'seize': 922,\n",
              " 'voted': 923,\n",
              " 'burns': 924,\n",
              " 'human': 925,\n",
              " 'skinny': 926,\n",
              " 'happens': 927,\n",
              " 'magic': 928,\n",
              " 'windy': 929,\n",
              " 'vote': 930,\n",
              " 'deaf': 931,\n",
              " 'ugly': 932,\n",
              " 'wood': 933,\n",
              " 'decide': 934,\n",
              " 'lips': 935,\n",
              " 'loser': 936,\n",
              " 'rule': 937,\n",
              " 'thief': 938,\n",
              " 'huge': 939,\n",
              " 'crashed': 940,\n",
              " 'upset': 941,\n",
              " 'twins': 942,\n",
              " 'pity': 943,\n",
              " 'confident': 944,\n",
              " 'upstairs': 945,\n",
              " 'exist': 946,\n",
              " 'framed': 947,\n",
              " 'sushi': 948,\n",
              " 'games': 949,\n",
              " 'cab': 950,\n",
              " 'adult': 951,\n",
              " 'shopping': 952,\n",
              " 'burn': 953,\n",
              " 'shame': 954,\n",
              " 'focused': 955,\n",
              " 'boys': 956,\n",
              " 'answered': 957,\n",
              " 'canceled': 958,\n",
              " 'waste': 959,\n",
              " 'years': 960,\n",
              " 'rude': 961,\n",
              " 'tough': 962,\n",
              " 'body': 963,\n",
              " 'rush': 964,\n",
              " 'few': 965,\n",
              " 'smells': 966,\n",
              " 'cancer': 967,\n",
              " 'sports': 968,\n",
              " 'supper': 969,\n",
              " 'ride': 970,\n",
              " 'easygoing': 971,\n",
              " 'charge': 972,\n",
              " 'takes': 973,\n",
              " 'theirs': 974,\n",
              " 'adores': 975,\n",
              " 'remembers': 976,\n",
              " 'moment': 977,\n",
              " 'thinks': 978,\n",
              " 'sound': 979,\n",
              " 'cows': 980,\n",
              " 'grass': 981,\n",
              " 'towel': 982,\n",
              " 'year': 983,\n",
              " 'uncle': 984,\n",
              " 'animal': 985,\n",
              " 'disgusting': 986,\n",
              " 'borrow': 987,\n",
              " 'arrested': 988,\n",
              " 'sisters': 989,\n",
              " 'chicken': 990,\n",
              " 'travel': 991,\n",
              " 'tokyo': 992,\n",
              " 'having': 993,\n",
              " 'wide': 994,\n",
              " 'likely': 995,\n",
              " 'delicious': 996,\n",
              " 'their': 997,\n",
              " 'bill': 998,\n",
              " 'ruined': 999,\n",
              " 'missing': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_lang_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qckRePAnOLou"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(input_lang_tokenizer.word_index) + 1\n",
        "vocab_targ_size = len(target_lang_tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbrffBupOLou"
      },
      "source": [
        "convert to tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "COCMJQtmOLou"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "99d4rFOKOLov"
      },
      "outputs": [],
      "source": [
        "class Encoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    def initilize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.enc_units))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xHlRYdtqOLov"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7OZF20oOLov",
        "outputId": "2ca7f6f1-969e-4401-e5ee-2156a5f3256e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.Encoder at 0x7b086cbe3d90>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyvkNhPGOLow",
        "outputId": "b3715e70-42da-4d49-e1c1-9746fa28a7ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_hidden = encoder.initilize_hidden_state()\n",
        "simple_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "h00gA8hGOLow"
      },
      "outputs": [],
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFoEjcVLOLox",
        "outputId": "9341034b-d99d-4ca6-b908-b60f4da080da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 16, 1024), dtype=float32, numpy=\n",
              " array([[[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-3.8181278e-03,  3.0817572e-04, -3.9349422e-03, ...,\n",
              "          -5.1668617e-03, -3.2297852e-03, -1.0563156e-02],\n",
              "         [-1.4705049e-02,  1.1103795e-02, -7.9958886e-03, ...,\n",
              "          -3.2451171e-03, -1.9584314e-03, -1.1390633e-02],\n",
              "         ...,\n",
              "         [ 1.9635055e-02,  5.1810266e-03,  4.0658031e-04, ...,\n",
              "           8.1495903e-03, -1.5585002e-02, -1.5376742e-02],\n",
              "         [ 1.9614244e-02,  4.9648858e-03,  6.9931068e-04, ...,\n",
              "           8.2933428e-03, -1.5761487e-02, -1.5432717e-02],\n",
              "         [ 1.9578893e-02,  4.8386822e-03,  8.9701317e-04, ...,\n",
              "           8.3865533e-03, -1.5850341e-02, -1.5463739e-02]],\n",
              " \n",
              "        [[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-9.5584244e-03,  3.7205432e-04, -3.9382512e-03, ...,\n",
              "           3.7582491e-03,  6.5343716e-06, -1.3154483e-03],\n",
              "         [-4.7244402e-03,  4.8500183e-03,  4.6997508e-03, ...,\n",
              "          -2.8915261e-03,  5.9224078e-03, -2.9726566e-03],\n",
              "         ...,\n",
              "         [ 1.9704606e-02,  5.1726969e-03,  4.5574570e-04, ...,\n",
              "           8.0032786e-03, -1.5663246e-02, -1.5319854e-02],\n",
              "         [ 1.9670404e-02,  4.9602492e-03,  7.4345380e-04, ...,\n",
              "           8.1965420e-03, -1.5801096e-02, -1.5408634e-02],\n",
              "         [ 1.9621260e-02,  4.8365863e-03,  9.3241024e-04, ...,\n",
              "           8.3238129e-03, -1.5868533e-02, -1.5454910e-02]],\n",
              " \n",
              "        [[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-5.0190371e-03, -6.8991249e-03, -1.4054320e-03, ...,\n",
              "           1.0141444e-02, -2.7432365e-03, -4.6825297e-03],\n",
              "         [-1.3055881e-03, -5.0478363e-03,  8.1798742e-03, ...,\n",
              "           2.5251608e-03, -1.0743632e-02, -4.2021805e-03],\n",
              "         ...,\n",
              "         [ 1.9645158e-02,  5.0308439e-03,  6.9848372e-04, ...,\n",
              "           8.2396185e-03, -1.5871003e-02, -1.5444498e-02],\n",
              "         [ 1.9601502e-02,  4.8778160e-03,  8.9748862e-04, ...,\n",
              "           8.3546797e-03, -1.5915761e-02, -1.5475358e-02],\n",
              "         [ 1.9560143e-02,  4.7905990e-03,  1.0265263e-03, ...,\n",
              "           8.4283305e-03, -1.5930463e-02, -1.5490741e-02]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-1.0222644e-02, -4.0807649e-03, -5.1694154e-03, ...,\n",
              "           8.1949625e-03,  8.8003447e-04,  8.3000790e-03],\n",
              "         [-6.4432113e-03,  1.9304052e-03, -2.6474409e-03, ...,\n",
              "           6.5405825e-03,  5.3880420e-03,  1.5666183e-02],\n",
              "         ...,\n",
              "         [ 1.9363454e-02,  4.7786580e-03,  8.2097616e-04, ...,\n",
              "           8.2707889e-03, -1.5914436e-02, -1.5458438e-02],\n",
              "         [ 1.9421829e-02,  4.7257296e-03,  9.7652694e-04, ...,\n",
              "           8.3633075e-03, -1.5946642e-02, -1.5480562e-02],\n",
              "         [ 1.9446965e-02,  4.6999948e-03,  1.0769112e-03, ...,\n",
              "           8.4268600e-03, -1.5950844e-02, -1.5491383e-02]],\n",
              " \n",
              "        [[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-1.3592910e-03, -1.2170392e-02, -1.0205678e-02, ...,\n",
              "          -5.2198940e-03,  3.8405852e-03, -6.0874544e-04],\n",
              "         [-1.3786524e-02, -7.3771370e-03, -1.2743727e-02, ...,\n",
              "           4.1717784e-03,  2.6348010e-03, -1.4062467e-03],\n",
              "         ...,\n",
              "         [ 1.9618487e-02,  4.9613775e-03,  7.7713944e-04, ...,\n",
              "           8.2491729e-03, -1.5851136e-02, -1.5443412e-02],\n",
              "         [ 1.9585535e-02,  4.8327851e-03,  9.4767596e-04, ...,\n",
              "           8.3540631e-03, -1.5905662e-02, -1.5471213e-02],\n",
              "         [ 1.9550517e-02,  4.7616037e-03,  1.0574685e-03, ...,\n",
              "           8.4235696e-03, -1.5925543e-02, -1.5486500e-02]],\n",
              " \n",
              "        [[-1.3867304e-02, -1.4910647e-02, -2.7736884e-03, ...,\n",
              "           6.5706889e-03, -8.6802800e-05,  2.2787252e-03],\n",
              "         [-7.9496149e-03, -1.1964389e-02,  3.0009034e-03, ...,\n",
              "           9.4500731e-04, -7.6610236e-03, -4.0517966e-03],\n",
              "         [-1.0419147e-02, -1.9172132e-03, -1.8488410e-03, ...,\n",
              "          -9.8521439e-03, -9.1947056e-03, -3.8588676e-03],\n",
              "         ...,\n",
              "         [ 1.9727685e-02,  5.1514995e-03,  5.0470210e-04, ...,\n",
              "           7.9879221e-03, -1.5715914e-02, -1.5420471e-02],\n",
              "         [ 1.9674426e-02,  4.9494710e-03,  7.6198956e-04, ...,\n",
              "           8.1872223e-03, -1.5836863e-02, -1.5465294e-02],\n",
              "         [ 1.9618403e-02,  4.8312917e-03,  9.3623012e-04, ...,\n",
              "           8.3174212e-03, -1.5893219e-02, -1.5487210e-02]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[ 0.01957889,  0.00483868,  0.00089701, ...,  0.00838655,\n",
              "         -0.01585034, -0.01546374],\n",
              "        [ 0.01962126,  0.00483659,  0.00093241, ...,  0.00832381,\n",
              "         -0.01586853, -0.01545491],\n",
              "        [ 0.01956014,  0.0047906 ,  0.00102653, ...,  0.00842833,\n",
              "         -0.01593046, -0.01549074],\n",
              "        ...,\n",
              "        [ 0.01944697,  0.00469999,  0.00107691, ...,  0.00842686,\n",
              "         -0.01595084, -0.01549138],\n",
              "        [ 0.01955052,  0.0047616 ,  0.00105747, ...,  0.00842357,\n",
              "         -0.01592554, -0.0154865 ],\n",
              "        [ 0.0196184 ,  0.00483129,  0.00093623, ...,  0.00831742,\n",
              "         -0.01589322, -0.01548721]], dtype=float32)>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder(example_input_batch, simple_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OZZaTEN1OLoy"
      },
      "outputs": [],
      "source": [
        "simple_output, simple_states = encoder(example_input_batch, simple_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YYpWG4P1OLoz"
      },
      "outputs": [],
      "source": [
        "class Attention(keras.layers.Layer):\n",
        "    def __init__ (self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "    def call (self, query, values):\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "        atteion_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = atteion_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, atteion_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjV4hTA0OLo0",
        "outputId": "dcc498f9-4990-4c49-c84a-1b1756f6f0d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[ 7.1667298e-03,  5.3439499e-03, -2.2248339e-03, ...,\n",
              "          2.4999985e-03, -7.2825309e-03, -9.5850490e-03],\n",
              "        [ 6.8199532e-03,  5.1684859e-03, -1.5664676e-03, ...,\n",
              "          2.6855646e-03, -6.2899645e-03, -7.0009045e-03],\n",
              "        [ 1.0203638e-02,  4.2281952e-03, -9.1903516e-05, ...,\n",
              "          4.8851687e-03, -1.0887261e-02, -8.4632635e-03],\n",
              "        ...,\n",
              "        [ 7.1569751e-03,  3.1073373e-03, -8.8585378e-04, ...,\n",
              "          8.5433722e-03, -7.4149831e-03, -8.0103474e-03],\n",
              "        [ 8.6027756e-03,  2.4226005e-03, -2.1138897e-03, ...,\n",
              "          4.5032171e-03, -8.9810733e-03, -8.8280383e-03],\n",
              "        [ 9.5744897e-03,  1.8695681e-03, -1.1786344e-03, ...,\n",
              "          1.5377755e-03, -1.0182157e-02, -7.9458747e-03]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 16, 1), dtype=float32, numpy=\n",
              " array([[[0.06258687],\n",
              "         [0.06270896],\n",
              "         [0.06239355],\n",
              "         ...,\n",
              "         [0.06330437],\n",
              "         [0.06331644],\n",
              "         [0.06332105]],\n",
              " \n",
              "        [[0.06266754],\n",
              "         [0.06252275],\n",
              "         [0.06178444],\n",
              "         ...,\n",
              "         [0.06337906],\n",
              "         [0.0633925 ],\n",
              "         [0.06339845]],\n",
              " \n",
              "        [[0.06253921],\n",
              "         [0.06236032],\n",
              "         [0.06241526],\n",
              "         ...,\n",
              "         [0.06327739],\n",
              "         [0.06327913],\n",
              "         [0.06327811]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.06224721],\n",
              "         [0.06196703],\n",
              "         [0.06173768],\n",
              "         ...,\n",
              "         [0.06297167],\n",
              "         [0.06297497],\n",
              "         [0.06297595]],\n",
              " \n",
              "        [[0.06288353],\n",
              "         [0.06199915],\n",
              "         [0.06224011],\n",
              "         ...,\n",
              "         [0.06361537],\n",
              "         [0.06362079],\n",
              "         [0.06362211]],\n",
              " \n",
              "        [[0.06235233],\n",
              "         [0.06289322],\n",
              "         [0.06367952],\n",
              "         ...,\n",
              "         [0.0630773 ],\n",
              "         [0.06308611],\n",
              "         [0.06308846]]], dtype=float32)>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_layer = Attention(10)\n",
        "attention_layer(simple_hidden, simple_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bjSgNIePOLo0"
      },
      "outputs": [],
      "source": [
        "attention_result, attention_weights = attention_layer(simple_hidden, simple_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iNJCCtGqOLpN"
      },
      "outputs": [],
      "source": [
        "class Decoder(keras.Model):\n",
        "    def __init__ (self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True)\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        self.attention = Attention(self.dec_units)\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bxajC8rZOLpN"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(vocab_targ_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px-ZMn3QOLpO",
        "outputId": "e337c53f-c8ad-4c58-ddc0-0016e50bd551"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 3727), dtype=float32, numpy=\n",
              " array([[-0.00563016, -0.00031051,  0.00013611, ...,  0.00173186,\n",
              "          0.00554163,  0.0011226 ],\n",
              "        [-0.00565664, -0.00013238, -0.0002351 , ...,  0.00107353,\n",
              "          0.00512314,  0.0015196 ],\n",
              "        [-0.00522375, -0.00067919,  0.00018229, ...,  0.00192473,\n",
              "          0.00495865,  0.00121993],\n",
              "        ...,\n",
              "        [-0.00563348, -0.00080164, -0.00041911, ...,  0.00169302,\n",
              "          0.00539299,  0.00211256],\n",
              "        [-0.00549585, -0.00089033, -0.00032904, ...,  0.00158492,\n",
              "          0.00486909,  0.00165807],\n",
              "        [-0.00556515, -0.00102758, -0.00012648, ...,  0.00123833,\n",
              "          0.00518886,  0.00121592]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[ 0.00113923, -0.00465844, -0.00455933, ...,  0.00870538,\n",
              "         -0.00070354, -0.00083257],\n",
              "        [ 0.00187236, -0.00442646, -0.00352619, ...,  0.00832067,\n",
              "         -0.00153717, -0.00137283],\n",
              "        [ 0.0014789 , -0.00540294, -0.00401729, ...,  0.00897577,\n",
              "         -0.00131119, -0.0011663 ],\n",
              "        ...,\n",
              "        [ 0.00059818, -0.00539492, -0.00306764, ...,  0.00963507,\n",
              "         -0.0004705 , -0.0019939 ],\n",
              "        [ 0.00122928, -0.00581536, -0.00479483, ...,  0.00885009,\n",
              "         -0.00039022, -0.00040595],\n",
              "        [ 0.00098869, -0.00431742, -0.00506066, ...,  0.00856881,\n",
              "         -0.0012452 , -0.00114463]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 16, 1), dtype=float32, numpy=\n",
              " array([[[0.06324456],\n",
              "         [0.06253944],\n",
              "         [0.06316221],\n",
              "         ...,\n",
              "         [0.06203976],\n",
              "         [0.06203571],\n",
              "         [0.06203379]],\n",
              " \n",
              "        [[0.06335333],\n",
              "         [0.06265724],\n",
              "         [0.06223634],\n",
              "         ...,\n",
              "         [0.06213534],\n",
              "         [0.06213594],\n",
              "         [0.06213685]],\n",
              " \n",
              "        [[0.0633813 ],\n",
              "         [0.06308025],\n",
              "         [0.06293908],\n",
              "         ...,\n",
              "         [0.06215977],\n",
              "         [0.06216127],\n",
              "         [0.06216257]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.06331804],\n",
              "         [0.06321014],\n",
              "         [0.06267633],\n",
              "         ...,\n",
              "         [0.06209367],\n",
              "         [0.06209731],\n",
              "         [0.06209977]],\n",
              " \n",
              "        [[0.06338648],\n",
              "         [0.06360991],\n",
              "         [0.06290609],\n",
              "         ...,\n",
              "         [0.06216818],\n",
              "         [0.06216865],\n",
              "         [0.06216916]],\n",
              " \n",
              "        [[0.06352574],\n",
              "         [0.06324282],\n",
              "         [0.06245467],\n",
              "         ...,\n",
              "         [0.06229453],\n",
              "         [0.06229848],\n",
              "         [0.06230159]]], dtype=float32)>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder(tf.random.uniform((BATCH_SIZE, 1)), simple_hidden, simple_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Wl5_kepyOLpO"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yYqsJU3rOLpO"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jZf5FLvtOLpP"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'chckpnts'\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uBhxGIvqOLpP"
      },
      "outputs": [],
      "source": [
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<strat>']] * BATCH_SIZE, 1)\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU_b4OopOLpP",
        "outputId": "ba2af2e3-e52f-4a5f-d90b-18afb76b5a43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7b086b25f250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7b086b25f250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Loss:  4.6504993\n",
            "Epoch:  0\n",
            "Loss:  4.771959\n",
            "Epoch:  0\n",
            "Loss:  4.725208\n",
            "Epoch:  0\n",
            "Loss:  4.4264317\n",
            "Epoch:  0\n",
            "Loss:  3.2801247\n",
            "Epoch:  0\n",
            "Loss:  4.251987\n",
            "Epoch:  0\n",
            "Loss:  3.7642245\n",
            "Epoch:  0\n",
            "Loss:  3.0847738\n",
            "Epoch:  0\n",
            "Loss:  2.8026917\n",
            "Epoch:  0\n",
            "Loss:  2.8952105\n",
            "Epoch:  0\n",
            "Loss:  3.015023\n",
            "Epoch:  0\n",
            "Loss:  3.016374\n",
            "Epoch:  0\n",
            "Loss:  2.9506352\n",
            "Epoch:  0\n",
            "Loss:  2.9943612\n",
            "Epoch:  0\n",
            "Loss:  2.9972167\n",
            "Epoch:  0\n",
            "Loss:  2.994089\n",
            "Epoch:  0\n",
            "Loss:  2.9249868\n",
            "Epoch:  0\n",
            "Loss:  2.7441268\n",
            "Epoch:  0\n",
            "Loss:  2.9279447\n",
            "Epoch:  0\n",
            "Loss:  2.7836058\n",
            "Epoch:  0\n",
            "Loss:  2.8666267\n",
            "Epoch:  0\n",
            "Loss:  2.7861228\n",
            "Epoch:  0\n",
            "Loss:  2.7839332\n",
            "Epoch:  0\n",
            "Loss:  2.636765\n",
            "Epoch:  0\n",
            "Loss:  2.748929\n",
            "Epoch:  0\n",
            "Loss:  2.7458498\n",
            "Epoch:  0\n",
            "Loss:  2.7463543\n",
            "Epoch:  0\n",
            "Loss:  2.6621003\n",
            "Epoch:  0\n",
            "Loss:  2.624762\n",
            "Epoch:  0\n",
            "Loss:  2.5128038\n",
            "Epoch:  0\n",
            "Loss:  2.4609804\n",
            "Epoch:  0\n",
            "Loss:  2.637305\n",
            "Epoch:  0\n",
            "Loss:  2.4807222\n",
            "Epoch:  0\n",
            "Loss:  2.4728024\n",
            "Epoch:  0\n",
            "Loss:  2.4210694\n",
            "Epoch:  0\n",
            "Loss:  2.6067138\n",
            "Epoch:  0\n",
            "Loss:  2.6067238\n",
            "Epoch:  0\n",
            "Loss:  2.4361615\n",
            "Epoch:  0\n",
            "Loss:  2.4835382\n",
            "Epoch:  0\n",
            "Loss:  2.4329515\n",
            "Epoch:  0\n",
            "Loss:  2.4446793\n",
            "Epoch:  0\n",
            "Loss:  2.3823628\n",
            "Epoch:  0\n",
            "Loss:  2.43358\n",
            "Epoch:  0\n",
            "Loss:  2.4168136\n",
            "Epoch:  0\n",
            "Loss:  2.336346\n",
            "Epoch:  0\n",
            "Loss:  2.3189182\n",
            "Epoch:  0\n",
            "Loss:  2.3137112\n",
            "Epoch:  0\n",
            "Loss:  2.4176834\n",
            "Epoch:  0\n",
            "Loss:  2.358384\n",
            "Epoch:  0\n",
            "Loss:  2.4209173\n",
            "Epoch:  0\n",
            "Loss:  2.4781513\n",
            "Epoch:  0\n",
            "Loss:  2.373541\n",
            "Epoch:  0\n",
            "Loss:  2.3917093\n",
            "Epoch:  0\n",
            "Loss:  2.2970252\n",
            "Epoch:  0\n",
            "Loss:  2.3215988\n",
            "Epoch:  0\n",
            "Loss:  2.2887073\n",
            "Epoch:  0\n",
            "Loss:  2.288175\n",
            "Epoch:  0\n",
            "Loss:  2.3458505\n",
            "Epoch:  0\n",
            "Loss:  2.252112\n",
            "Epoch:  0\n",
            "Loss:  2.3437703\n",
            "Epoch:  0\n",
            "Loss:  2.2590857\n",
            "Epoch:  0\n",
            "Loss:  2.3522832\n",
            "Epoch:  0\n",
            "Loss:  2.2865155\n",
            "Epoch:  0\n",
            "Loss:  2.3473554\n",
            "Epoch:  0\n",
            "Loss:  2.2060819\n",
            "Epoch:  0\n",
            "Loss:  2.331118\n",
            "Epoch:  0\n",
            "Loss:  2.220298\n",
            "Epoch:  0\n",
            "Loss:  2.1075747\n",
            "Epoch:  0\n",
            "Loss:  2.3825955\n",
            "Epoch:  0\n",
            "Loss:  2.260221\n",
            "Epoch:  0\n",
            "Loss:  2.2587667\n",
            "Epoch:  0\n",
            "Loss:  2.324403\n",
            "Epoch:  0\n",
            "Loss:  2.2763531\n",
            "Epoch:  0\n",
            "Loss:  2.3050804\n",
            "Epoch:  0\n",
            "Loss:  2.2107599\n",
            "Epoch:  0\n",
            "Loss:  2.2319973\n",
            "Epoch:  0\n",
            "Loss:  2.2697437\n",
            "Epoch:  0\n",
            "Loss:  2.1985214\n",
            "Epoch:  0\n",
            "Loss:  2.2597082\n",
            "Epoch:  0\n",
            "Loss:  2.1970487\n",
            "Epoch:  0\n",
            "Loss:  2.3196747\n",
            "Epoch:  0\n",
            "Loss:  2.251789\n",
            "Epoch:  0\n",
            "Loss:  2.2855306\n",
            "Epoch:  0\n",
            "Loss:  2.2583232\n",
            "Epoch:  0\n",
            "Loss:  2.1457975\n",
            "Epoch:  0\n",
            "Loss:  2.2033706\n",
            "Epoch:  0\n",
            "Loss:  2.2289104\n",
            "Epoch:  0\n",
            "Loss:  2.190846\n",
            "Epoch:  0\n",
            "Loss:  2.2207172\n",
            "Epoch:  0\n",
            "Loss:  2.246744\n",
            "Epoch:  0\n",
            "Loss:  2.1724534\n",
            "Epoch:  0\n",
            "Loss:  2.1554024\n",
            "Epoch:  0\n",
            "Loss:  2.2404008\n",
            "Epoch:  0\n",
            "Loss:  2.2946637\n",
            "Epoch:  0\n",
            "Loss:  2.3580952\n",
            "Epoch:  0\n",
            "Loss:  2.0637457\n",
            "Epoch:  0\n",
            "Loss:  2.2093673\n",
            "Epoch:  0\n",
            "Loss:  2.0772676\n",
            "Epoch:  0\n",
            "Loss:  2.1247087\n",
            "Epoch:  0\n",
            "Loss:  2.0120234\n",
            "Epoch:  0\n",
            "Loss:  2.2049851\n",
            "Epoch:  0\n",
            "Loss:  2.139772\n",
            "Epoch:  0\n",
            "Loss:  2.1888115\n",
            "Epoch:  0\n",
            "Loss:  2.0786588\n",
            "Epoch:  0\n",
            "Loss:  2.2066708\n",
            "Epoch:  0\n",
            "Loss:  2.0650964\n",
            "Epoch:  0\n",
            "Loss:  2.1549792\n",
            "Epoch:  0\n",
            "Loss:  2.2271714\n",
            "Epoch:  0\n",
            "Loss:  1.945549\n",
            "Epoch:  0\n",
            "Loss:  1.9281454\n",
            "Epoch:  0\n",
            "Loss:  2.0940642\n",
            "Epoch:  0\n",
            "Loss:  2.0739908\n",
            "Epoch:  0\n",
            "Loss:  2.0666673\n",
            "Epoch:  0\n",
            "Loss:  2.0743418\n",
            "Epoch:  0\n",
            "Loss:  2.1677024\n",
            "Epoch:  0\n",
            "Loss:  2.1518104\n",
            "Epoch:  0\n",
            "Loss:  2.0746531\n",
            "Epoch:  0\n",
            "Loss:  2.092303\n",
            "Epoch:  0\n",
            "Loss:  2.0481868\n",
            "Epoch:  0\n",
            "Loss:  2.0735161\n",
            "Epoch:  0\n",
            "Loss:  2.1473355\n",
            "Epoch:  0\n",
            "Loss:  2.0133255\n",
            "Epoch:  0\n",
            "Loss:  2.1464643\n",
            "Epoch:  0\n",
            "Loss:  2.0749633\n",
            "Epoch:  0\n",
            "Loss:  2.111773\n",
            "Epoch:  0\n",
            "Loss:  1.9788635\n",
            "Epoch:  0\n",
            "Loss:  2.1281114\n",
            "Epoch:  0\n",
            "Loss:  2.139144\n",
            "Epoch:  0\n",
            "Loss:  2.0239265\n",
            "Epoch:  0\n",
            "Loss:  1.9946098\n",
            "Epoch:  0\n",
            "Loss:  2.1302514\n",
            "Epoch:  0\n",
            "Loss:  2.0577948\n",
            "Epoch:  0\n",
            "Loss:  1.9846538\n",
            "Epoch:  0\n",
            "Loss:  1.9760374\n",
            "Epoch:  0\n",
            "Loss:  2.0144513\n",
            "Epoch:  0\n",
            "Loss:  2.1636138\n",
            "Epoch:  0\n",
            "Loss:  1.926511\n",
            "Epoch:  0\n",
            "Loss:  2.1252458\n",
            "Epoch:  0\n",
            "Loss:  1.989188\n",
            "Epoch:  0\n",
            "Loss:  1.925683\n",
            "Epoch:  0\n",
            "Loss:  2.00181\n",
            "Epoch:  0\n",
            "Loss:  2.0828388\n",
            "Epoch:  0\n",
            "Loss:  1.9666603\n",
            "Epoch:  0\n",
            "Loss:  1.9970049\n",
            "Epoch:  0\n",
            "Loss:  2.048393\n",
            "Epoch:  0\n",
            "Loss:  1.9155529\n",
            "Epoch:  0\n",
            "Loss:  2.0632553\n",
            "Epoch:  0\n",
            "Loss:  1.9853443\n",
            "Epoch:  0\n",
            "Loss:  1.9683714\n",
            "Epoch:  0\n",
            "Loss:  1.995923\n",
            "Epoch:  0\n",
            "Loss:  1.9671886\n",
            "Epoch:  0\n",
            "Loss:  1.965545\n",
            "Epoch:  0\n",
            "Loss:  1.8430026\n",
            "Epoch:  0\n",
            "Loss:  1.9351429\n",
            "Epoch:  0\n",
            "Loss:  1.891763\n",
            "Epoch:  0\n",
            "Loss:  2.1041112\n",
            "Epoch:  0\n",
            "Loss:  1.9794403\n",
            "Epoch:  0\n",
            "Loss:  2.068048\n",
            "Epoch:  0\n",
            "Loss:  1.9530771\n",
            "Epoch:  0\n",
            "Loss:  1.874898\n",
            "Epoch:  0\n",
            "Loss:  2.0826328\n",
            "Epoch:  0\n",
            "Loss:  2.0131679\n",
            "Epoch:  0\n",
            "Loss:  2.038447\n",
            "Epoch:  0\n",
            "Loss:  1.9687595\n",
            "Epoch:  0\n",
            "Loss:  1.841268\n",
            "Epoch:  0\n",
            "Loss:  1.9937255\n",
            "Epoch:  0\n",
            "Loss:  2.0077689\n",
            "Epoch:  0\n",
            "Loss:  1.906197\n",
            "Epoch:  0\n",
            "Loss:  1.8122761\n",
            "Epoch:  0\n",
            "Loss:  1.9160893\n",
            "Epoch:  0\n",
            "Loss:  1.9250158\n",
            "Epoch:  0\n",
            "Loss:  1.9654442\n",
            "Epoch:  0\n",
            "Loss:  1.8990469\n",
            "Epoch:  0\n",
            "Loss:  1.8987201\n",
            "Epoch:  0\n",
            "Loss:  1.9503744\n",
            "Epoch:  0\n",
            "Loss:  1.9214981\n",
            "Epoch:  0\n",
            "Loss:  2.0026174\n",
            "Epoch:  0\n",
            "Loss:  1.9239705\n",
            "Epoch:  0\n",
            "Loss:  1.7968498\n",
            "Epoch:  0\n",
            "Loss:  1.939421\n",
            "Epoch:  0\n",
            "Loss:  1.8332926\n",
            "Epoch:  0\n",
            "Loss:  1.9644133\n",
            "Epoch:  0\n",
            "Loss:  1.837085\n",
            "Epoch:  0\n",
            "Loss:  1.8887438\n",
            "Epoch:  0\n",
            "Loss:  1.9161136\n",
            "Epoch:  0\n",
            "Loss:  1.9209726\n",
            "Epoch:  0\n",
            "Loss:  1.9497194\n",
            "Epoch:  0\n",
            "Loss:  2.1070247\n",
            "Epoch:  0\n",
            "Loss:  1.9545753\n",
            "Epoch:  0\n",
            "Loss:  1.8747699\n",
            "Epoch:  0\n",
            "Loss:  1.8645979\n",
            "Epoch:  0\n",
            "Loss:  1.9588146\n",
            "Epoch:  0\n",
            "Loss:  1.8484476\n",
            "Epoch:  0\n",
            "Loss:  1.8950154\n",
            "Epoch:  0\n",
            "Loss:  1.8219818\n",
            "Epoch:  0\n",
            "Loss:  1.8845831\n",
            "Epoch:  0\n",
            "Loss:  1.8699592\n",
            "Epoch:  0\n",
            "Loss:  1.9327567\n",
            "Epoch:  0\n",
            "Loss:  1.8971653\n",
            "Epoch:  0\n",
            "Loss:  1.8416078\n",
            "Epoch:  0\n",
            "Loss:  1.8126554\n",
            "Epoch:  0\n",
            "Loss:  1.8998789\n",
            "Epoch:  0\n",
            "Loss:  1.835881\n",
            "Epoch:  0\n",
            "Loss:  1.7457142\n",
            "Epoch:  0\n",
            "Loss:  1.8533239\n",
            "Epoch:  0\n",
            "Loss:  1.7865263\n",
            "Epoch:  0\n",
            "Loss:  1.8684391\n",
            "Epoch:  0\n",
            "Loss:  1.9652224\n",
            "Epoch:  0\n",
            "Loss:  2.0032585\n",
            "Epoch:  0\n",
            "Loss:  1.8993658\n",
            "Epoch:  0\n",
            "Loss:  1.8840284\n",
            "Epoch:  0\n",
            "Loss:  1.8728892\n",
            "Epoch:  0\n",
            "Loss:  1.7836018\n",
            "Epoch:  0\n",
            "Loss:  1.7833517\n",
            "Epoch:  0\n",
            "Loss:  1.8932089\n",
            "Epoch:  0\n",
            "Loss:  1.7978475\n",
            "Epoch:  0\n",
            "Loss:  1.7962519\n",
            "Epoch:  0\n",
            "Loss:  1.7862917\n",
            "Epoch:  0\n",
            "Loss:  1.9274095\n",
            "Epoch:  0\n",
            "Loss:  1.9432932\n",
            "Epoch:  0\n",
            "Loss:  1.7692394\n",
            "Epoch:  0\n",
            "Loss:  1.8759\n",
            "Epoch:  0\n",
            "Loss:  1.7609482\n",
            "Epoch:  0\n",
            "Loss:  1.727315\n",
            "Epoch:  0\n",
            "Loss:  1.8043859\n",
            "Epoch:  0\n",
            "Loss:  1.7727125\n",
            "Epoch:  0\n",
            "Loss:  1.7450749\n",
            "Epoch:  0\n",
            "Loss:  1.8863825\n",
            "Epoch:  0\n",
            "Loss:  1.8209026\n",
            "Epoch:  0\n",
            "Loss:  1.8151209\n",
            "Epoch:  0\n",
            "Loss:  1.7523829\n",
            "Epoch:  0\n",
            "Loss:  1.8918432\n",
            "Epoch:  0\n",
            "Loss:  1.7218937\n",
            "Epoch:  0\n",
            "Loss:  1.7801349\n",
            "Epoch:  0\n",
            "Loss:  1.9273129\n",
            "Epoch:  0\n",
            "Loss:  1.8092886\n",
            "Epoch:  0\n",
            "Loss:  1.8314149\n",
            "Epoch:  0\n",
            "Loss:  1.7773367\n",
            "Epoch:  0\n",
            "Loss:  1.7006712\n",
            "Epoch:  0\n",
            "Loss:  1.8361254\n",
            "Epoch:  0\n",
            "Loss:  1.7834047\n",
            "Epoch:  0\n",
            "Loss:  1.7779295\n",
            "Epoch:  0\n",
            "Loss:  1.8195902\n",
            "Epoch:  0\n",
            "Loss:  1.776503\n",
            "Epoch:  0\n",
            "Loss:  1.8825461\n",
            "Epoch:  0\n",
            "Loss:  1.8078907\n",
            "Epoch:  0\n",
            "Loss:  1.7785612\n",
            "Epoch:  0\n",
            "Loss:  1.8366554\n",
            "Epoch:  0\n",
            "Loss:  1.7333324\n",
            "Epoch:  0\n",
            "Loss:  1.786486\n",
            "Epoch:  1\n",
            "Loss:  1.7502785\n",
            "Epoch:  1\n",
            "Loss:  1.7595949\n",
            "Epoch:  1\n",
            "Loss:  1.6900507\n",
            "Epoch:  1\n",
            "Loss:  1.8197687\n",
            "Epoch:  1\n",
            "Loss:  1.7274067\n",
            "Epoch:  1\n",
            "Loss:  1.7817141\n",
            "Epoch:  1\n",
            "Loss:  1.6890072\n",
            "Epoch:  1\n",
            "Loss:  1.6745151\n",
            "Epoch:  1\n",
            "Loss:  1.7038605\n",
            "Epoch:  1\n",
            "Loss:  1.6525084\n",
            "Epoch:  1\n",
            "Loss:  1.7347208\n",
            "Epoch:  1\n",
            "Loss:  1.6863267\n",
            "Epoch:  1\n",
            "Loss:  1.6841214\n",
            "Epoch:  1\n",
            "Loss:  1.8319094\n",
            "Epoch:  1\n",
            "Loss:  1.6475061\n",
            "Epoch:  1\n",
            "Loss:  1.7076641\n",
            "Epoch:  1\n",
            "Loss:  1.6571829\n",
            "Epoch:  1\n",
            "Loss:  1.6994028\n",
            "Epoch:  1\n",
            "Loss:  1.7077837\n",
            "Epoch:  1\n",
            "Loss:  1.7267898\n",
            "Epoch:  1\n",
            "Loss:  1.6486905\n",
            "Epoch:  1\n",
            "Loss:  1.6678613\n",
            "Epoch:  1\n",
            "Loss:  1.7031858\n",
            "Epoch:  1\n",
            "Loss:  1.7708372\n",
            "Epoch:  1\n",
            "Loss:  1.5969433\n",
            "Epoch:  1\n",
            "Loss:  1.7406203\n",
            "Epoch:  1\n",
            "Loss:  1.647258\n",
            "Epoch:  1\n",
            "Loss:  1.7177368\n",
            "Epoch:  1\n",
            "Loss:  1.787955\n",
            "Epoch:  1\n",
            "Loss:  1.7104622\n",
            "Epoch:  1\n",
            "Loss:  1.6694828\n",
            "Epoch:  1\n",
            "Loss:  1.734154\n",
            "Epoch:  1\n",
            "Loss:  1.7254082\n",
            "Epoch:  1\n",
            "Loss:  1.6243035\n",
            "Epoch:  1\n",
            "Loss:  1.6712036\n",
            "Epoch:  1\n",
            "Loss:  1.5873328\n",
            "Epoch:  1\n",
            "Loss:  1.6463101\n",
            "Epoch:  1\n",
            "Loss:  1.7357314\n",
            "Epoch:  1\n",
            "Loss:  1.6973705\n",
            "Epoch:  1\n",
            "Loss:  1.7060112\n",
            "Epoch:  1\n",
            "Loss:  1.6220449\n",
            "Epoch:  1\n",
            "Loss:  1.6130545\n",
            "Epoch:  1\n",
            "Loss:  1.6769378\n",
            "Epoch:  1\n",
            "Loss:  1.6779219\n",
            "Epoch:  1\n",
            "Loss:  1.61569\n",
            "Epoch:  1\n",
            "Loss:  1.6374197\n",
            "Epoch:  1\n",
            "Loss:  1.5651524\n",
            "Epoch:  1\n",
            "Loss:  1.626817\n",
            "Epoch:  1\n",
            "Loss:  1.7032642\n",
            "Epoch:  1\n",
            "Loss:  1.6949497\n",
            "Epoch:  1\n",
            "Loss:  1.6284606\n",
            "Epoch:  1\n",
            "Loss:  1.5039116\n",
            "Epoch:  1\n",
            "Loss:  1.8262784\n",
            "Epoch:  1\n",
            "Loss:  1.6630102\n",
            "Epoch:  1\n",
            "Loss:  1.5594845\n",
            "Epoch:  1\n",
            "Loss:  1.6015959\n",
            "Epoch:  1\n",
            "Loss:  1.6345327\n",
            "Epoch:  1\n",
            "Loss:  1.6853796\n",
            "Epoch:  1\n",
            "Loss:  1.6639048\n",
            "Epoch:  1\n",
            "Loss:  1.7136196\n",
            "Epoch:  1\n",
            "Loss:  1.6390505\n",
            "Epoch:  1\n",
            "Loss:  1.6034352\n",
            "Epoch:  1\n",
            "Loss:  1.6349264\n",
            "Epoch:  1\n",
            "Loss:  1.637277\n",
            "Epoch:  1\n",
            "Loss:  1.6255203\n",
            "Epoch:  1\n",
            "Loss:  1.5900522\n",
            "Epoch:  1\n",
            "Loss:  1.6731749\n",
            "Epoch:  1\n",
            "Loss:  1.6851218\n",
            "Epoch:  1\n",
            "Loss:  1.6814792\n",
            "Epoch:  1\n",
            "Loss:  1.6513342\n",
            "Epoch:  1\n",
            "Loss:  1.5981249\n",
            "Epoch:  1\n",
            "Loss:  1.5994108\n",
            "Epoch:  1\n",
            "Loss:  1.6843411\n",
            "Epoch:  1\n",
            "Loss:  1.6410205\n",
            "Epoch:  1\n",
            "Loss:  1.5356344\n",
            "Epoch:  1\n",
            "Loss:  1.6791255\n",
            "Epoch:  1\n",
            "Loss:  1.6508138\n",
            "Epoch:  1\n",
            "Loss:  1.5867972\n",
            "Epoch:  1\n",
            "Loss:  1.5429318\n",
            "Epoch:  1\n",
            "Loss:  1.5195383\n",
            "Epoch:  1\n",
            "Loss:  1.637853\n",
            "Epoch:  1\n",
            "Loss:  1.6992604\n",
            "Epoch:  1\n",
            "Loss:  1.6407621\n",
            "Epoch:  1\n",
            "Loss:  1.6663339\n",
            "Epoch:  1\n",
            "Loss:  1.552633\n",
            "Epoch:  1\n",
            "Loss:  1.633452\n",
            "Epoch:  1\n",
            "Loss:  1.7246189\n",
            "Epoch:  1\n",
            "Loss:  1.6321383\n",
            "Epoch:  1\n",
            "Loss:  1.5975691\n",
            "Epoch:  1\n",
            "Loss:  1.594468\n",
            "Epoch:  1\n",
            "Loss:  1.5553464\n",
            "Epoch:  1\n",
            "Loss:  1.5851066\n",
            "Epoch:  1\n",
            "Loss:  1.5611051\n",
            "Epoch:  1\n",
            "Loss:  1.5421118\n",
            "Epoch:  1\n",
            "Loss:  1.6018893\n",
            "Epoch:  1\n",
            "Loss:  1.6477938\n",
            "Epoch:  1\n",
            "Loss:  1.6466501\n",
            "Epoch:  1\n",
            "Loss:  1.4931927\n",
            "Epoch:  1\n",
            "Loss:  1.5754576\n",
            "Epoch:  1\n",
            "Loss:  1.592936\n",
            "Epoch:  1\n",
            "Loss:  1.5394007\n",
            "Epoch:  1\n",
            "Loss:  1.7595942\n",
            "Epoch:  1\n",
            "Loss:  1.6337048\n",
            "Epoch:  1\n",
            "Loss:  1.517062\n",
            "Epoch:  1\n",
            "Loss:  1.5544026\n",
            "Epoch:  1\n",
            "Loss:  1.5591719\n",
            "Epoch:  1\n",
            "Loss:  1.6340911\n",
            "Epoch:  1\n",
            "Loss:  1.4505379\n",
            "Epoch:  1\n",
            "Loss:  1.5451468\n",
            "Epoch:  1\n",
            "Loss:  1.5230162\n",
            "Epoch:  1\n",
            "Loss:  1.6349785\n",
            "Epoch:  1\n",
            "Loss:  1.5876052\n",
            "Epoch:  1\n",
            "Loss:  1.626298\n",
            "Epoch:  1\n",
            "Loss:  1.5171055\n",
            "Epoch:  1\n",
            "Loss:  1.5689192\n",
            "Epoch:  1\n",
            "Loss:  1.5994227\n",
            "Epoch:  1\n",
            "Loss:  1.6873925\n",
            "Epoch:  1\n",
            "Loss:  1.4780307\n",
            "Epoch:  1\n",
            "Loss:  1.637433\n",
            "Epoch:  1\n",
            "Loss:  1.5269148\n",
            "Epoch:  1\n",
            "Loss:  1.6698116\n",
            "Epoch:  1\n",
            "Loss:  1.4979494\n",
            "Epoch:  1\n",
            "Loss:  1.706523\n",
            "Epoch:  1\n",
            "Loss:  1.442467\n",
            "Epoch:  1\n",
            "Loss:  1.6296778\n",
            "Epoch:  1\n",
            "Loss:  1.5346625\n",
            "Epoch:  1\n",
            "Loss:  1.503617\n",
            "Epoch:  1\n",
            "Loss:  1.5524994\n",
            "Epoch:  1\n",
            "Loss:  1.6423826\n",
            "Epoch:  1\n",
            "Loss:  1.4542938\n",
            "Epoch:  1\n",
            "Loss:  1.6009556\n",
            "Epoch:  1\n",
            "Loss:  1.6404047\n",
            "Epoch:  1\n",
            "Loss:  1.4734256\n",
            "Epoch:  1\n",
            "Loss:  1.6393894\n",
            "Epoch:  1\n",
            "Loss:  1.6375105\n",
            "Epoch:  1\n",
            "Loss:  1.562166\n",
            "Epoch:  1\n",
            "Loss:  1.5670565\n",
            "Epoch:  1\n",
            "Loss:  1.6270001\n",
            "Epoch:  1\n",
            "Loss:  1.4818494\n",
            "Epoch:  1\n",
            "Loss:  1.5594008\n",
            "Epoch:  1\n",
            "Loss:  1.4762509\n",
            "Epoch:  1\n",
            "Loss:  1.4926215\n",
            "Epoch:  1\n",
            "Loss:  1.5014892\n",
            "Epoch:  1\n",
            "Loss:  1.5775228\n",
            "Epoch:  1\n",
            "Loss:  1.6244485\n",
            "Epoch:  1\n",
            "Loss:  1.4766169\n",
            "Epoch:  1\n",
            "Loss:  1.5926929\n",
            "Epoch:  1\n",
            "Loss:  1.5881082\n",
            "Epoch:  1\n",
            "Loss:  1.485514\n",
            "Epoch:  1\n",
            "Loss:  1.4707794\n",
            "Epoch:  1\n",
            "Loss:  1.5434422\n",
            "Epoch:  1\n",
            "Loss:  1.5617816\n",
            "Epoch:  1\n",
            "Loss:  1.4765217\n",
            "Epoch:  1\n",
            "Loss:  1.5533901\n",
            "Epoch:  1\n",
            "Loss:  1.5330775\n",
            "Epoch:  1\n",
            "Loss:  1.4809632\n",
            "Epoch:  1\n",
            "Loss:  1.4944127\n",
            "Epoch:  1\n",
            "Loss:  1.5558842\n",
            "Epoch:  1\n",
            "Loss:  1.4749887\n",
            "Epoch:  1\n",
            "Loss:  1.4906807\n",
            "Epoch:  1\n",
            "Loss:  1.5999438\n",
            "Epoch:  1\n",
            "Loss:  1.5460066\n",
            "Epoch:  1\n",
            "Loss:  1.546741\n",
            "Epoch:  1\n",
            "Loss:  1.5167624\n",
            "Epoch:  1\n",
            "Loss:  1.5513519\n",
            "Epoch:  1\n",
            "Loss:  1.5140511\n",
            "Epoch:  1\n",
            "Loss:  1.5092819\n",
            "Epoch:  1\n",
            "Loss:  1.458503\n",
            "Epoch:  1\n",
            "Loss:  1.5726236\n",
            "Epoch:  1\n",
            "Loss:  1.5282099\n",
            "Epoch:  1\n",
            "Loss:  1.4539942\n",
            "Epoch:  1\n",
            "Loss:  1.606218\n",
            "Epoch:  1\n",
            "Loss:  1.3753135\n",
            "Epoch:  1\n",
            "Loss:  1.4984956\n",
            "Epoch:  1\n",
            "Loss:  1.5464457\n",
            "Epoch:  1\n",
            "Loss:  1.4575598\n",
            "Epoch:  1\n",
            "Loss:  1.46368\n",
            "Epoch:  1\n",
            "Loss:  1.7608992\n",
            "Epoch:  1\n",
            "Loss:  1.5239061\n",
            "Epoch:  1\n",
            "Loss:  1.643512\n",
            "Epoch:  1\n",
            "Loss:  1.5181131\n",
            "Epoch:  1\n",
            "Loss:  1.5617546\n",
            "Epoch:  1\n",
            "Loss:  1.426799\n",
            "Epoch:  1\n",
            "Loss:  1.5613883\n",
            "Epoch:  1\n",
            "Loss:  1.5135903\n",
            "Epoch:  1\n",
            "Loss:  1.6044757\n",
            "Epoch:  1\n",
            "Loss:  1.4912612\n",
            "Epoch:  1\n",
            "Loss:  1.4797719\n",
            "Epoch:  1\n",
            "Loss:  1.4694726\n",
            "Epoch:  1\n",
            "Loss:  1.3861153\n",
            "Epoch:  1\n",
            "Loss:  1.4742751\n",
            "Epoch:  1\n",
            "Loss:  1.4199054\n",
            "Epoch:  1\n",
            "Loss:  1.5291283\n",
            "Epoch:  1\n",
            "Loss:  1.542235\n",
            "Epoch:  1\n",
            "Loss:  1.4799122\n",
            "Epoch:  1\n",
            "Loss:  1.462132\n",
            "Epoch:  1\n",
            "Loss:  1.5492179\n",
            "Epoch:  1\n",
            "Loss:  1.5490282\n",
            "Epoch:  1\n",
            "Loss:  1.3772925\n",
            "Epoch:  1\n",
            "Loss:  1.5131952\n",
            "Epoch:  1\n",
            "Loss:  1.5773817\n",
            "Epoch:  1\n",
            "Loss:  1.4625727\n",
            "Epoch:  1\n",
            "Loss:  1.4581363\n",
            "Epoch:  1\n",
            "Loss:  1.4161882\n",
            "Epoch:  1\n",
            "Loss:  1.4122975\n",
            "Epoch:  1\n",
            "Loss:  1.4983506\n",
            "Epoch:  1\n",
            "Loss:  1.5838405\n",
            "Epoch:  1\n",
            "Loss:  1.4018486\n",
            "Epoch:  1\n",
            "Loss:  1.4566405\n",
            "Epoch:  1\n",
            "Loss:  1.5906731\n",
            "Epoch:  1\n",
            "Loss:  1.3118654\n",
            "Epoch:  1\n",
            "Loss:  1.5001192\n",
            "Epoch:  1\n",
            "Loss:  1.5090433\n",
            "Epoch:  1\n",
            "Loss:  1.3840528\n",
            "Epoch:  1\n",
            "Loss:  1.5035692\n",
            "Epoch:  1\n",
            "Loss:  1.5124638\n",
            "Epoch:  1\n",
            "Loss:  1.4482931\n",
            "Epoch:  1\n",
            "Loss:  1.3923128\n",
            "Epoch:  1\n",
            "Loss:  1.4508688\n",
            "Epoch:  1\n",
            "Loss:  1.4509417\n",
            "Epoch:  1\n",
            "Loss:  1.4431776\n",
            "Epoch:  1\n",
            "Loss:  1.4361453\n",
            "Epoch:  1\n",
            "Loss:  1.5175062\n",
            "Epoch:  1\n",
            "Loss:  1.424308\n",
            "Epoch:  1\n",
            "Loss:  1.4589062\n",
            "Epoch:  1\n",
            "Loss:  1.4346062\n",
            "Epoch:  1\n",
            "Loss:  1.4963607\n",
            "Epoch:  1\n",
            "Loss:  1.5751853\n",
            "Epoch:  1\n",
            "Loss:  1.5459471\n",
            "Epoch:  1\n",
            "Loss:  1.5047508\n",
            "Epoch:  1\n",
            "Loss:  1.4486598\n",
            "Epoch:  1\n",
            "Loss:  1.4050376\n",
            "Epoch:  1\n",
            "Loss:  1.5187157\n",
            "Epoch:  1\n",
            "Loss:  1.3564268\n",
            "Epoch:  1\n",
            "Loss:  1.522909\n",
            "Epoch:  1\n",
            "Loss:  1.4780015\n",
            "Epoch:  1\n",
            "Loss:  1.4659619\n",
            "Epoch:  1\n",
            "Loss:  1.4971408\n",
            "Epoch:  1\n",
            "Loss:  1.3036935\n",
            "Epoch:  1\n",
            "Loss:  1.5174781\n",
            "Epoch:  1\n",
            "Loss:  1.4066472\n",
            "Epoch:  1\n",
            "Loss:  1.5075302\n",
            "Epoch:  1\n",
            "Loss:  1.3464421\n",
            "Epoch:  1\n",
            "Loss:  1.3837677\n",
            "Epoch:  1\n",
            "Loss:  1.4042867\n",
            "Epoch:  1\n",
            "Loss:  1.3602035\n",
            "Epoch:  1\n",
            "Loss:  1.477201\n",
            "Epoch:  1\n",
            "Loss:  1.4157146\n",
            "Epoch:  1\n",
            "Loss:  1.432383\n",
            "Epoch:  1\n",
            "Loss:  1.406141\n",
            "Epoch:  2\n",
            "Loss:  1.3192049\n",
            "Epoch:  2\n",
            "Loss:  1.3646427\n",
            "Epoch:  2\n",
            "Loss:  1.271529\n",
            "Epoch:  2\n",
            "Loss:  1.2101517\n",
            "Epoch:  2\n",
            "Loss:  1.3319008\n",
            "Epoch:  2\n",
            "Loss:  1.2750618\n",
            "Epoch:  2\n",
            "Loss:  1.2174962\n",
            "Epoch:  2\n",
            "Loss:  1.2257202\n",
            "Epoch:  2\n",
            "Loss:  1.2959425\n",
            "Epoch:  2\n",
            "Loss:  1.221424\n",
            "Epoch:  2\n",
            "Loss:  1.2595873\n",
            "Epoch:  2\n",
            "Loss:  1.3216254\n",
            "Epoch:  2\n",
            "Loss:  1.2309029\n",
            "Epoch:  2\n",
            "Loss:  1.287698\n",
            "Epoch:  2\n",
            "Loss:  1.3085186\n",
            "Epoch:  2\n",
            "Loss:  1.3046027\n",
            "Epoch:  2\n",
            "Loss:  1.3615794\n",
            "Epoch:  2\n",
            "Loss:  1.3417075\n",
            "Epoch:  2\n",
            "Loss:  1.3339803\n",
            "Epoch:  2\n",
            "Loss:  1.3039109\n",
            "Epoch:  2\n",
            "Loss:  1.2340293\n",
            "Epoch:  2\n",
            "Loss:  1.460324\n",
            "Epoch:  2\n",
            "Loss:  1.3030745\n",
            "Epoch:  2\n",
            "Loss:  1.278568\n",
            "Epoch:  2\n",
            "Loss:  1.4094203\n",
            "Epoch:  2\n",
            "Loss:  1.2195748\n",
            "Epoch:  2\n",
            "Loss:  1.2307727\n",
            "Epoch:  2\n",
            "Loss:  1.3529367\n",
            "Epoch:  2\n",
            "Loss:  1.1840217\n",
            "Epoch:  2\n",
            "Loss:  1.2473774\n",
            "Epoch:  2\n",
            "Loss:  1.2124547\n",
            "Epoch:  2\n",
            "Loss:  1.2432252\n",
            "Epoch:  2\n",
            "Loss:  1.2924953\n",
            "Epoch:  2\n",
            "Loss:  1.3245151\n",
            "Epoch:  2\n",
            "Loss:  1.2781382\n",
            "Epoch:  2\n",
            "Loss:  1.2645987\n",
            "Epoch:  2\n",
            "Loss:  1.2187841\n",
            "Epoch:  2\n",
            "Loss:  1.1955802\n",
            "Epoch:  2\n",
            "Loss:  1.2718076\n",
            "Epoch:  2\n",
            "Loss:  1.2881771\n",
            "Epoch:  2\n",
            "Loss:  1.3176236\n",
            "Epoch:  2\n",
            "Loss:  1.1813365\n",
            "Epoch:  2\n",
            "Loss:  1.2409829\n",
            "Epoch:  2\n",
            "Loss:  1.1924509\n",
            "Epoch:  2\n",
            "Loss:  1.4326059\n",
            "Epoch:  2\n",
            "Loss:  1.1651934\n",
            "Epoch:  2\n",
            "Loss:  1.3093728\n",
            "Epoch:  2\n",
            "Loss:  1.2452192\n",
            "Epoch:  2\n",
            "Loss:  1.218629\n",
            "Epoch:  2\n",
            "Loss:  1.3054345\n",
            "Epoch:  2\n",
            "Loss:  1.3298004\n",
            "Epoch:  2\n",
            "Loss:  1.1805725\n",
            "Epoch:  2\n",
            "Loss:  1.3337104\n",
            "Epoch:  2\n",
            "Loss:  1.2912159\n",
            "Epoch:  2\n",
            "Loss:  1.3885978\n",
            "Epoch:  2\n",
            "Loss:  1.2790837\n",
            "Epoch:  2\n",
            "Loss:  1.2505085\n",
            "Epoch:  2\n",
            "Loss:  1.3484471\n",
            "Epoch:  2\n",
            "Loss:  1.2395679\n",
            "Epoch:  2\n",
            "Loss:  1.2266407\n",
            "Epoch:  2\n",
            "Loss:  1.2406389\n",
            "Epoch:  2\n",
            "Loss:  1.1038618\n",
            "Epoch:  2\n",
            "Loss:  1.3283861\n",
            "Epoch:  2\n",
            "Loss:  1.3201956\n",
            "Epoch:  2\n",
            "Loss:  1.2698634\n",
            "Epoch:  2\n",
            "Loss:  1.2858061\n",
            "Epoch:  2\n",
            "Loss:  1.2194333\n",
            "Epoch:  2\n",
            "Loss:  1.2344028\n",
            "Epoch:  2\n",
            "Loss:  1.2687523\n",
            "Epoch:  2\n",
            "Loss:  1.2276785\n",
            "Epoch:  2\n",
            "Loss:  1.2107344\n",
            "Epoch:  2\n",
            "Loss:  1.2434347\n",
            "Epoch:  2\n",
            "Loss:  1.0980793\n",
            "Epoch:  2\n",
            "Loss:  1.314563\n",
            "Epoch:  2\n",
            "Loss:  1.3020899\n",
            "Epoch:  2\n",
            "Loss:  1.2884132\n",
            "Epoch:  2\n",
            "Loss:  1.3422688\n",
            "Epoch:  2\n",
            "Loss:  1.2793634\n",
            "Epoch:  2\n",
            "Loss:  1.2225161\n",
            "Epoch:  2\n",
            "Loss:  1.2345878\n",
            "Epoch:  2\n",
            "Loss:  1.302191\n",
            "Epoch:  2\n",
            "Loss:  1.2027484\n",
            "Epoch:  2\n",
            "Loss:  1.2753627\n",
            "Epoch:  2\n",
            "Loss:  1.2261288\n",
            "Epoch:  2\n",
            "Loss:  1.17862\n",
            "Epoch:  2\n",
            "Loss:  1.2369369\n",
            "Epoch:  2\n",
            "Loss:  1.397505\n",
            "Epoch:  2\n",
            "Loss:  1.212211\n",
            "Epoch:  2\n",
            "Loss:  1.194997\n",
            "Epoch:  2\n",
            "Loss:  1.2924707\n",
            "Epoch:  2\n",
            "Loss:  1.2731048\n",
            "Epoch:  2\n",
            "Loss:  1.260977\n",
            "Epoch:  2\n",
            "Loss:  1.3212937\n",
            "Epoch:  2\n",
            "Loss:  1.20876\n",
            "Epoch:  2\n",
            "Loss:  1.1448172\n",
            "Epoch:  2\n",
            "Loss:  1.2571006\n",
            "Epoch:  2\n",
            "Loss:  1.2358263\n",
            "Epoch:  2\n",
            "Loss:  1.182721\n",
            "Epoch:  2\n",
            "Loss:  1.1955602\n",
            "Epoch:  2\n",
            "Loss:  1.1904773\n",
            "Epoch:  2\n",
            "Loss:  1.1837637\n",
            "Epoch:  2\n",
            "Loss:  1.1966834\n",
            "Epoch:  2\n",
            "Loss:  1.1146505\n",
            "Epoch:  2\n",
            "Loss:  1.2315581\n",
            "Epoch:  2\n",
            "Loss:  1.3374895\n",
            "Epoch:  2\n",
            "Loss:  1.254236\n",
            "Epoch:  2\n",
            "Loss:  1.1178747\n",
            "Epoch:  2\n",
            "Loss:  1.2189503\n",
            "Epoch:  2\n",
            "Loss:  1.2228876\n",
            "Epoch:  2\n",
            "Loss:  1.3517156\n",
            "Epoch:  2\n",
            "Loss:  1.1495339\n",
            "Epoch:  2\n",
            "Loss:  1.1223371\n",
            "Epoch:  2\n",
            "Loss:  1.1961639\n",
            "Epoch:  2\n",
            "Loss:  1.3787286\n",
            "Epoch:  2\n",
            "Loss:  1.1161668\n",
            "Epoch:  2\n",
            "Loss:  1.1515185\n",
            "Epoch:  2\n",
            "Loss:  1.1562742\n",
            "Epoch:  2\n",
            "Loss:  1.1186717\n",
            "Epoch:  2\n",
            "Loss:  1.2924608\n",
            "Epoch:  2\n",
            "Loss:  1.2423385\n",
            "Epoch:  2\n",
            "Loss:  1.1478546\n",
            "Epoch:  2\n",
            "Loss:  1.2720053\n",
            "Epoch:  2\n",
            "Loss:  1.1919334\n",
            "Epoch:  2\n",
            "Loss:  1.2040681\n",
            "Epoch:  2\n",
            "Loss:  1.2441491\n",
            "Epoch:  2\n",
            "Loss:  1.2246401\n",
            "Epoch:  2\n",
            "Loss:  1.2671676\n",
            "Epoch:  2\n",
            "Loss:  1.2593048\n",
            "Epoch:  2\n",
            "Loss:  1.2509116\n",
            "Epoch:  2\n",
            "Loss:  1.1742349\n",
            "Epoch:  2\n",
            "Loss:  1.108756\n",
            "Epoch:  2\n",
            "Loss:  1.1295973\n",
            "Epoch:  2\n",
            "Loss:  1.2155368\n",
            "Epoch:  2\n",
            "Loss:  1.358657\n",
            "Epoch:  2\n",
            "Loss:  1.2083728\n",
            "Epoch:  2\n",
            "Loss:  1.3207994\n",
            "Epoch:  2\n",
            "Loss:  1.2083359\n",
            "Epoch:  2\n",
            "Loss:  1.1533806\n",
            "Epoch:  2\n",
            "Loss:  1.068633\n",
            "Epoch:  2\n",
            "Loss:  1.1903749\n",
            "Epoch:  2\n",
            "Loss:  1.3313668\n",
            "Epoch:  2\n",
            "Loss:  1.0792756\n",
            "Epoch:  2\n",
            "Loss:  1.156634\n",
            "Epoch:  2\n",
            "Loss:  1.1823708\n",
            "Epoch:  2\n",
            "Loss:  1.258003\n",
            "Epoch:  2\n",
            "Loss:  1.1848748\n",
            "Epoch:  2\n",
            "Loss:  1.1868554\n",
            "Epoch:  2\n",
            "Loss:  1.1835837\n",
            "Epoch:  2\n",
            "Loss:  1.2701935\n",
            "Epoch:  2\n",
            "Loss:  1.2479675\n",
            "Epoch:  2\n",
            "Loss:  1.2329429\n",
            "Epoch:  2\n",
            "Loss:  1.2379818\n",
            "Epoch:  2\n",
            "Loss:  1.2086622\n",
            "Epoch:  2\n",
            "Loss:  1.1617253\n",
            "Epoch:  2\n",
            "Loss:  1.1285614\n",
            "Epoch:  2\n",
            "Loss:  1.2345524\n",
            "Epoch:  2\n",
            "Loss:  1.0939196\n",
            "Epoch:  2\n",
            "Loss:  1.1980397\n",
            "Epoch:  2\n",
            "Loss:  1.0973349\n",
            "Epoch:  2\n",
            "Loss:  1.152836\n",
            "Epoch:  2\n",
            "Loss:  1.1575783\n",
            "Epoch:  2\n",
            "Loss:  1.1463189\n",
            "Epoch:  2\n",
            "Loss:  1.0554574\n",
            "Epoch:  2\n",
            "Loss:  1.2127416\n",
            "Epoch:  2\n",
            "Loss:  1.1306598\n",
            "Epoch:  2\n",
            "Loss:  1.2021439\n",
            "Epoch:  2\n",
            "Loss:  1.1477135\n",
            "Epoch:  2\n",
            "Loss:  1.2130353\n",
            "Epoch:  2\n",
            "Loss:  1.177186\n",
            "Epoch:  2\n",
            "Loss:  1.0884336\n",
            "Epoch:  2\n",
            "Loss:  1.250189\n",
            "Epoch:  2\n",
            "Loss:  1.2136672\n",
            "Epoch:  2\n",
            "Loss:  1.123111\n",
            "Epoch:  2\n",
            "Loss:  1.0633037\n",
            "Epoch:  2\n",
            "Loss:  1.1708624\n",
            "Epoch:  2\n",
            "Loss:  1.1238612\n",
            "Epoch:  2\n",
            "Loss:  1.135833\n",
            "Epoch:  2\n",
            "Loss:  1.2049652\n",
            "Epoch:  2\n",
            "Loss:  1.1666952\n",
            "Epoch:  2\n",
            "Loss:  1.141085\n",
            "Epoch:  2\n",
            "Loss:  1.0723736\n",
            "Epoch:  2\n",
            "Loss:  0.9674514\n",
            "Epoch:  2\n",
            "Loss:  1.2367526\n",
            "Epoch:  2\n",
            "Loss:  1.1182022\n",
            "Epoch:  2\n",
            "Loss:  1.1311198\n",
            "Epoch:  2\n",
            "Loss:  1.1505214\n",
            "Epoch:  2\n",
            "Loss:  1.0846318\n",
            "Epoch:  2\n",
            "Loss:  1.2309947\n",
            "Epoch:  2\n",
            "Loss:  1.1766883\n",
            "Epoch:  2\n",
            "Loss:  1.0986388\n",
            "Epoch:  2\n",
            "Loss:  1.1205187\n",
            "Epoch:  2\n",
            "Loss:  1.068224\n",
            "Epoch:  2\n",
            "Loss:  1.057831\n",
            "Epoch:  2\n",
            "Loss:  1.1457537\n",
            "Epoch:  2\n",
            "Loss:  1.1177485\n",
            "Epoch:  2\n",
            "Loss:  1.1904346\n",
            "Epoch:  2\n",
            "Loss:  1.0648825\n",
            "Epoch:  2\n",
            "Loss:  1.1856934\n",
            "Epoch:  2\n",
            "Loss:  1.0721352\n",
            "Epoch:  2\n",
            "Loss:  1.2588073\n",
            "Epoch:  2\n",
            "Loss:  1.0930221\n",
            "Epoch:  2\n",
            "Loss:  1.1791006\n",
            "Epoch:  2\n",
            "Loss:  1.1220568\n",
            "Epoch:  2\n",
            "Loss:  1.1043975\n",
            "Epoch:  2\n",
            "Loss:  1.0113971\n",
            "Epoch:  2\n",
            "Loss:  1.0400515\n",
            "Epoch:  2\n",
            "Loss:  1.0410198\n",
            "Epoch:  2\n",
            "Loss:  1.1100426\n",
            "Epoch:  2\n",
            "Loss:  1.1579617\n",
            "Epoch:  2\n",
            "Loss:  1.1368217\n",
            "Epoch:  2\n",
            "Loss:  1.043987\n",
            "Epoch:  2\n",
            "Loss:  1.0805447\n",
            "Epoch:  2\n",
            "Loss:  1.0088251\n",
            "Epoch:  2\n",
            "Loss:  1.1349254\n",
            "Epoch:  2\n",
            "Loss:  1.2385459\n",
            "Epoch:  2\n",
            "Loss:  1.1179435\n",
            "Epoch:  2\n",
            "Loss:  1.1414723\n",
            "Epoch:  2\n",
            "Loss:  1.0881224\n",
            "Epoch:  2\n",
            "Loss:  1.0919927\n",
            "Epoch:  2\n",
            "Loss:  1.1236619\n",
            "Epoch:  2\n",
            "Loss:  1.1032013\n",
            "Epoch:  2\n",
            "Loss:  1.1710314\n",
            "Epoch:  2\n",
            "Loss:  1.088545\n",
            "Epoch:  2\n",
            "Loss:  1.062249\n",
            "Epoch:  2\n",
            "Loss:  1.0171541\n",
            "Epoch:  2\n",
            "Loss:  1.132304\n",
            "Epoch:  2\n",
            "Loss:  1.0861987\n",
            "Epoch:  2\n",
            "Loss:  1.0347501\n",
            "Epoch:  2\n",
            "Loss:  1.0831058\n",
            "Epoch:  2\n",
            "Loss:  1.164212\n",
            "Epoch:  2\n",
            "Loss:  1.0954653\n",
            "Epoch:  2\n",
            "Loss:  1.0962542\n",
            "Epoch:  2\n",
            "Loss:  1.1360171\n",
            "Epoch:  2\n",
            "Loss:  1.2071726\n",
            "Epoch:  2\n",
            "Loss:  1.1028813\n",
            "Epoch:  2\n",
            "Loss:  1.0928955\n",
            "Epoch:  2\n",
            "Loss:  0.96234715\n",
            "Epoch:  2\n",
            "Loss:  1.14876\n",
            "Epoch:  2\n",
            "Loss:  1.1815112\n",
            "Epoch:  2\n",
            "Loss:  1.0689065\n",
            "Epoch:  2\n",
            "Loss:  1.1829331\n",
            "Epoch:  2\n",
            "Loss:  1.0739361\n",
            "Epoch:  2\n",
            "Loss:  1.1775986\n",
            "Epoch:  2\n",
            "Loss:  1.0548745\n",
            "Epoch:  2\n",
            "Loss:  0.9986721\n",
            "Epoch:  2\n",
            "Loss:  1.04222\n",
            "Epoch:  2\n",
            "Loss:  0.9569129\n",
            "Epoch:  2\n",
            "Loss:  1.090875\n",
            "Epoch:  2\n",
            "Loss:  1.1388493\n",
            "Epoch:  2\n",
            "Loss:  0.98310834\n",
            "Epoch:  3\n",
            "Loss:  0.926716\n",
            "Epoch:  3\n",
            "Loss:  0.88200843\n",
            "Epoch:  3\n",
            "Loss:  1.0466983\n",
            "Epoch:  3\n",
            "Loss:  0.89096594\n",
            "Epoch:  3\n",
            "Loss:  0.95280665\n",
            "Epoch:  3\n",
            "Loss:  0.87521046\n",
            "Epoch:  3\n",
            "Loss:  0.9091562\n",
            "Epoch:  3\n",
            "Loss:  0.9321939\n",
            "Epoch:  3\n",
            "Loss:  0.9332056\n",
            "Epoch:  3\n",
            "Loss:  0.8763949\n",
            "Epoch:  3\n",
            "Loss:  0.973057\n",
            "Epoch:  3\n",
            "Loss:  0.86576396\n",
            "Epoch:  3\n",
            "Loss:  0.8579713\n",
            "Epoch:  3\n",
            "Loss:  0.86922866\n",
            "Epoch:  3\n",
            "Loss:  0.88726455\n",
            "Epoch:  3\n",
            "Loss:  0.91950893\n",
            "Epoch:  3\n",
            "Loss:  0.95125544\n",
            "Epoch:  3\n",
            "Loss:  0.83313864\n",
            "Epoch:  3\n",
            "Loss:  0.9539526\n",
            "Epoch:  3\n",
            "Loss:  0.876536\n",
            "Epoch:  3\n",
            "Loss:  0.93860483\n",
            "Epoch:  3\n",
            "Loss:  0.9704588\n",
            "Epoch:  3\n",
            "Loss:  0.95405215\n",
            "Epoch:  3\n",
            "Loss:  0.9138018\n",
            "Epoch:  3\n",
            "Loss:  0.8658497\n",
            "Epoch:  3\n",
            "Loss:  0.9293622\n",
            "Epoch:  3\n",
            "Loss:  0.9017736\n",
            "Epoch:  3\n",
            "Loss:  0.93422335\n",
            "Epoch:  3\n",
            "Loss:  0.7918335\n",
            "Epoch:  3\n",
            "Loss:  0.821644\n",
            "Epoch:  3\n",
            "Loss:  0.85551536\n",
            "Epoch:  3\n",
            "Loss:  0.8356851\n",
            "Epoch:  3\n",
            "Loss:  0.9681303\n",
            "Epoch:  3\n",
            "Loss:  0.83871424\n",
            "Epoch:  3\n",
            "Loss:  0.8694943\n",
            "Epoch:  3\n",
            "Loss:  0.8201526\n",
            "Epoch:  3\n",
            "Loss:  0.80672514\n",
            "Epoch:  3\n",
            "Loss:  0.8831498\n",
            "Epoch:  3\n",
            "Loss:  0.8956353\n",
            "Epoch:  3\n",
            "Loss:  0.80409414\n",
            "Epoch:  3\n",
            "Loss:  0.77796936\n",
            "Epoch:  3\n",
            "Loss:  0.8493762\n",
            "Epoch:  3\n",
            "Loss:  0.93134946\n",
            "Epoch:  3\n",
            "Loss:  0.8458031\n",
            "Epoch:  3\n",
            "Loss:  0.80507195\n",
            "Epoch:  3\n",
            "Loss:  0.8439895\n",
            "Epoch:  3\n",
            "Loss:  1.0232214\n",
            "Epoch:  3\n",
            "Loss:  0.85371923\n",
            "Epoch:  3\n",
            "Loss:  0.8046962\n",
            "Epoch:  3\n",
            "Loss:  0.94588125\n",
            "Epoch:  3\n",
            "Loss:  0.82055247\n",
            "Epoch:  3\n",
            "Loss:  0.91957074\n",
            "Epoch:  3\n",
            "Loss:  0.9236576\n",
            "Epoch:  3\n",
            "Loss:  0.9040283\n",
            "Epoch:  3\n",
            "Loss:  0.8933892\n",
            "Epoch:  3\n",
            "Loss:  0.85934293\n",
            "Epoch:  3\n",
            "Loss:  0.9185972\n",
            "Epoch:  3\n",
            "Loss:  0.8873556\n",
            "Epoch:  3\n",
            "Loss:  0.82445514\n",
            "Epoch:  3\n",
            "Loss:  0.8472854\n",
            "Epoch:  3\n",
            "Loss:  0.8525322\n",
            "Epoch:  3\n",
            "Loss:  0.88352096\n",
            "Epoch:  3\n",
            "Loss:  0.8594969\n",
            "Epoch:  3\n",
            "Loss:  0.8115735\n",
            "Epoch:  3\n",
            "Loss:  0.9820097\n",
            "Epoch:  3\n",
            "Loss:  0.9888629\n",
            "Epoch:  3\n",
            "Loss:  0.92381513\n",
            "Epoch:  3\n",
            "Loss:  0.8454671\n",
            "Epoch:  3\n",
            "Loss:  0.8260206\n",
            "Epoch:  3\n",
            "Loss:  0.88288116\n",
            "Epoch:  3\n",
            "Loss:  0.80156744\n",
            "Epoch:  3\n",
            "Loss:  0.95599717\n",
            "Epoch:  3\n",
            "Loss:  0.83571196\n",
            "Epoch:  3\n",
            "Loss:  0.8473872\n",
            "Epoch:  3\n",
            "Loss:  1.0525852\n",
            "Epoch:  3\n",
            "Loss:  0.87510556\n",
            "Epoch:  3\n",
            "Loss:  0.9376472\n",
            "Epoch:  3\n",
            "Loss:  0.8075207\n",
            "Epoch:  3\n",
            "Loss:  0.7648893\n",
            "Epoch:  3\n",
            "Loss:  0.8203004\n",
            "Epoch:  3\n",
            "Loss:  0.73816097\n",
            "Epoch:  3\n",
            "Loss:  0.9302312\n",
            "Epoch:  3\n",
            "Loss:  0.8631403\n",
            "Epoch:  3\n",
            "Loss:  0.8903018\n",
            "Epoch:  3\n",
            "Loss:  0.7926422\n",
            "Epoch:  3\n",
            "Loss:  0.8977548\n",
            "Epoch:  3\n",
            "Loss:  0.99566543\n",
            "Epoch:  3\n",
            "Loss:  0.93828696\n",
            "Epoch:  3\n",
            "Loss:  0.8791525\n",
            "Epoch:  3\n",
            "Loss:  0.8711029\n",
            "Epoch:  3\n",
            "Loss:  0.89757174\n",
            "Epoch:  3\n",
            "Loss:  0.82805645\n",
            "Epoch:  3\n",
            "Loss:  0.8596841\n",
            "Epoch:  3\n",
            "Loss:  0.87711334\n",
            "Epoch:  3\n",
            "Loss:  0.8687898\n",
            "Epoch:  3\n",
            "Loss:  0.8349563\n",
            "Epoch:  3\n",
            "Loss:  0.9115281\n",
            "Epoch:  3\n",
            "Loss:  0.85985005\n",
            "Epoch:  3\n",
            "Loss:  0.84086907\n",
            "Epoch:  3\n",
            "Loss:  0.9091257\n",
            "Epoch:  3\n",
            "Loss:  0.85725766\n",
            "Epoch:  3\n",
            "Loss:  0.85883266\n",
            "Epoch:  3\n",
            "Loss:  0.8928512\n",
            "Epoch:  3\n",
            "Loss:  0.8357379\n",
            "Epoch:  3\n",
            "Loss:  0.8526595\n",
            "Epoch:  3\n",
            "Loss:  0.8277906\n",
            "Epoch:  3\n",
            "Loss:  0.944517\n",
            "Epoch:  3\n",
            "Loss:  0.82687247\n",
            "Epoch:  3\n",
            "Loss:  0.7390591\n",
            "Epoch:  3\n",
            "Loss:  0.75637007\n",
            "Epoch:  3\n",
            "Loss:  0.8999259\n",
            "Epoch:  3\n",
            "Loss:  0.77055734\n",
            "Epoch:  3\n",
            "Loss:  0.7590446\n",
            "Epoch:  3\n",
            "Loss:  0.92632324\n",
            "Epoch:  3\n",
            "Loss:  0.849648\n",
            "Epoch:  3\n",
            "Loss:  0.9419754\n",
            "Epoch:  3\n",
            "Loss:  0.8607993\n",
            "Epoch:  3\n",
            "Loss:  0.8253398\n",
            "Epoch:  3\n",
            "Loss:  0.873175\n",
            "Epoch:  3\n",
            "Loss:  0.8582848\n",
            "Epoch:  3\n",
            "Loss:  0.90406513\n",
            "Epoch:  3\n",
            "Loss:  0.9377886\n",
            "Epoch:  3\n",
            "Loss:  0.76583046\n",
            "Epoch:  3\n",
            "Loss:  0.9280141\n",
            "Epoch:  3\n",
            "Loss:  0.8705778\n",
            "Epoch:  3\n",
            "Loss:  0.8382338\n",
            "Epoch:  3\n",
            "Loss:  0.9294893\n",
            "Epoch:  3\n",
            "Loss:  0.90748435\n",
            "Epoch:  3\n",
            "Loss:  0.8835039\n",
            "Epoch:  3\n",
            "Loss:  0.8468772\n",
            "Epoch:  3\n",
            "Loss:  0.8699622\n",
            "Epoch:  3\n",
            "Loss:  0.8941902\n",
            "Epoch:  3\n",
            "Loss:  0.9302786\n",
            "Epoch:  3\n",
            "Loss:  0.8548354\n",
            "Epoch:  3\n",
            "Loss:  0.90801656\n",
            "Epoch:  3\n",
            "Loss:  0.8336649\n",
            "Epoch:  3\n",
            "Loss:  0.8597747\n",
            "Epoch:  3\n",
            "Loss:  0.8193742\n",
            "Epoch:  3\n",
            "Loss:  0.78942686\n",
            "Epoch:  3\n",
            "Loss:  0.8582985\n",
            "Epoch:  3\n",
            "Loss:  0.90256107\n",
            "Epoch:  3\n",
            "Loss:  0.81709975\n",
            "Epoch:  3\n",
            "Loss:  0.83768547\n",
            "Epoch:  3\n",
            "Loss:  0.87236726\n",
            "Epoch:  3\n",
            "Loss:  0.82501686\n",
            "Epoch:  3\n",
            "Loss:  0.80541575\n",
            "Epoch:  3\n",
            "Loss:  0.95041895\n",
            "Epoch:  3\n",
            "Loss:  0.9330742\n",
            "Epoch:  3\n",
            "Loss:  0.8081829\n",
            "Epoch:  3\n",
            "Loss:  0.7836858\n",
            "Epoch:  3\n",
            "Loss:  0.8147979\n",
            "Epoch:  3\n",
            "Loss:  0.8631504\n",
            "Epoch:  3\n",
            "Loss:  0.6971492\n",
            "Epoch:  3\n",
            "Loss:  0.81023633\n",
            "Epoch:  3\n",
            "Loss:  0.85540104\n",
            "Epoch:  3\n",
            "Loss:  0.8118267\n",
            "Epoch:  3\n",
            "Loss:  0.766183\n",
            "Epoch:  3\n",
            "Loss:  0.8579342\n",
            "Epoch:  3\n",
            "Loss:  0.8735671\n",
            "Epoch:  3\n",
            "Loss:  0.8714822\n",
            "Epoch:  3\n",
            "Loss:  0.882218\n",
            "Epoch:  3\n",
            "Loss:  0.7792515\n",
            "Epoch:  3\n",
            "Loss:  0.8780786\n",
            "Epoch:  3\n",
            "Loss:  0.81856126\n",
            "Epoch:  3\n",
            "Loss:  0.79513395\n",
            "Epoch:  3\n",
            "Loss:  0.85942376\n",
            "Epoch:  3\n",
            "Loss:  0.9284665\n",
            "Epoch:  3\n",
            "Loss:  0.7427074\n",
            "Epoch:  3\n",
            "Loss:  0.9169736\n",
            "Epoch:  3\n",
            "Loss:  0.7664956\n",
            "Epoch:  3\n",
            "Loss:  0.7845269\n",
            "Epoch:  3\n",
            "Loss:  0.7167347\n",
            "Epoch:  3\n",
            "Loss:  0.8090488\n",
            "Epoch:  3\n",
            "Loss:  0.7346701\n",
            "Epoch:  3\n",
            "Loss:  0.86439896\n",
            "Epoch:  3\n",
            "Loss:  0.9044177\n",
            "Epoch:  3\n",
            "Loss:  0.7827095\n",
            "Epoch:  3\n",
            "Loss:  0.9187206\n",
            "Epoch:  3\n",
            "Loss:  0.7983992\n",
            "Epoch:  3\n",
            "Loss:  0.86233604\n",
            "Epoch:  3\n",
            "Loss:  0.8272025\n",
            "Epoch:  3\n",
            "Loss:  0.80365914\n",
            "Epoch:  3\n",
            "Loss:  0.9239486\n",
            "Epoch:  3\n",
            "Loss:  0.84322083\n",
            "Epoch:  3\n",
            "Loss:  0.81883925\n",
            "Epoch:  3\n",
            "Loss:  0.89088154\n",
            "Epoch:  3\n",
            "Loss:  0.8850117\n",
            "Epoch:  3\n",
            "Loss:  0.909396\n",
            "Epoch:  3\n",
            "Loss:  0.8181888\n",
            "Epoch:  3\n",
            "Loss:  0.7795565\n",
            "Epoch:  3\n",
            "Loss:  0.86165965\n",
            "Epoch:  3\n",
            "Loss:  0.82748544\n",
            "Epoch:  3\n",
            "Loss:  0.76277834\n",
            "Epoch:  3\n",
            "Loss:  0.9423448\n",
            "Epoch:  3\n",
            "Loss:  0.87399054\n",
            "Epoch:  3\n",
            "Loss:  0.9529227\n",
            "Epoch:  3\n",
            "Loss:  0.8223583\n",
            "Epoch:  3\n",
            "Loss:  0.7507385\n",
            "Epoch:  3\n",
            "Loss:  0.8547467\n",
            "Epoch:  3\n",
            "Loss:  0.8045082\n",
            "Epoch:  3\n",
            "Loss:  0.83879966\n",
            "Epoch:  3\n",
            "Loss:  0.76603067\n",
            "Epoch:  3\n",
            "Loss:  0.77027285\n",
            "Epoch:  3\n",
            "Loss:  0.8492505\n",
            "Epoch:  3\n",
            "Loss:  0.810497\n",
            "Epoch:  3\n",
            "Loss:  0.7955681\n",
            "Epoch:  3\n",
            "Loss:  0.80445176\n",
            "Epoch:  3\n",
            "Loss:  0.87740993\n",
            "Epoch:  3\n",
            "Loss:  0.73259276\n",
            "Epoch:  3\n",
            "Loss:  0.81331795\n",
            "Epoch:  3\n",
            "Loss:  0.93308705\n",
            "Epoch:  3\n",
            "Loss:  0.8022804\n",
            "Epoch:  3\n",
            "Loss:  0.6587563\n",
            "Epoch:  3\n",
            "Loss:  0.84056175\n",
            "Epoch:  3\n",
            "Loss:  0.84423894\n",
            "Epoch:  3\n",
            "Loss:  0.85861474\n",
            "Epoch:  3\n",
            "Loss:  0.806218\n",
            "Epoch:  3\n",
            "Loss:  0.79928064\n",
            "Epoch:  3\n",
            "Loss:  0.84614813\n",
            "Epoch:  3\n",
            "Loss:  0.9228088\n",
            "Epoch:  3\n",
            "Loss:  0.910141\n",
            "Epoch:  3\n",
            "Loss:  0.747384\n",
            "Epoch:  3\n",
            "Loss:  0.81494236\n",
            "Epoch:  3\n",
            "Loss:  0.81948584\n",
            "Epoch:  3\n",
            "Loss:  0.85088426\n",
            "Epoch:  3\n",
            "Loss:  0.7301079\n",
            "Epoch:  3\n",
            "Loss:  0.9078536\n",
            "Epoch:  3\n",
            "Loss:  0.870489\n",
            "Epoch:  3\n",
            "Loss:  0.8731284\n",
            "Epoch:  3\n",
            "Loss:  0.813223\n",
            "Epoch:  3\n",
            "Loss:  0.74895364\n",
            "Epoch:  3\n",
            "Loss:  0.7532317\n",
            "Epoch:  3\n",
            "Loss:  0.8340887\n",
            "Epoch:  3\n",
            "Loss:  0.7714458\n",
            "Epoch:  3\n",
            "Loss:  0.80291426\n",
            "Epoch:  3\n",
            "Loss:  0.8602883\n",
            "Epoch:  3\n",
            "Loss:  0.75870657\n",
            "Epoch:  3\n",
            "Loss:  0.8047764\n",
            "Epoch:  3\n",
            "Loss:  0.8319848\n",
            "Epoch:  3\n",
            "Loss:  0.7918879\n",
            "Epoch:  3\n",
            "Loss:  0.7731448\n",
            "Epoch:  3\n",
            "Loss:  0.7480453\n",
            "Epoch:  3\n",
            "Loss:  0.8781397\n",
            "Epoch:  3\n",
            "Loss:  0.7736021\n",
            "Epoch:  3\n",
            "Loss:  0.8228143\n",
            "Epoch:  3\n",
            "Loss:  0.7617568\n",
            "Epoch:  3\n",
            "Loss:  0.739697\n",
            "Epoch:  3\n",
            "Loss:  0.86493367\n",
            "Epoch:  3\n",
            "Loss:  0.7864859\n",
            "Epoch:  3\n",
            "Loss:  0.81464803\n",
            "Epoch:  4\n",
            "Loss:  0.7566031\n",
            "Epoch:  4\n",
            "Loss:  0.63123524\n",
            "Epoch:  4\n",
            "Loss:  0.576779\n",
            "Epoch:  4\n",
            "Loss:  0.6326921\n",
            "Epoch:  4\n",
            "Loss:  0.56124663\n",
            "Epoch:  4\n",
            "Loss:  0.6323398\n",
            "Epoch:  4\n",
            "Loss:  0.6516618\n",
            "Epoch:  4\n",
            "Loss:  0.58796394\n",
            "Epoch:  4\n",
            "Loss:  0.55310476\n",
            "Epoch:  4\n",
            "Loss:  0.63302577\n",
            "Epoch:  4\n",
            "Loss:  0.58463705\n",
            "Epoch:  4\n",
            "Loss:  0.54295045\n",
            "Epoch:  4\n",
            "Loss:  0.6232188\n",
            "Epoch:  4\n",
            "Loss:  0.68260443\n",
            "Epoch:  4\n",
            "Loss:  0.6373187\n",
            "Epoch:  4\n",
            "Loss:  0.5394534\n",
            "Epoch:  4\n",
            "Loss:  0.5081884\n",
            "Epoch:  4\n",
            "Loss:  0.5240748\n",
            "Epoch:  4\n",
            "Loss:  0.6284123\n",
            "Epoch:  4\n",
            "Loss:  0.4763556\n",
            "Epoch:  4\n",
            "Loss:  0.65215266\n",
            "Epoch:  4\n",
            "Loss:  0.49555\n",
            "Epoch:  4\n",
            "Loss:  0.59705067\n",
            "Epoch:  4\n",
            "Loss:  0.6714479\n",
            "Epoch:  4\n",
            "Loss:  0.59099674\n",
            "Epoch:  4\n",
            "Loss:  0.6082677\n",
            "Epoch:  4\n",
            "Loss:  0.664384\n",
            "Epoch:  4\n",
            "Loss:  0.57034296\n",
            "Epoch:  4\n",
            "Loss:  0.5301505\n",
            "Epoch:  4\n",
            "Loss:  0.54106003\n",
            "Epoch:  4\n",
            "Loss:  0.5532784\n",
            "Epoch:  4\n",
            "Loss:  0.5723309\n",
            "Epoch:  4\n",
            "Loss:  0.53898513\n",
            "Epoch:  4\n",
            "Loss:  0.6919838\n",
            "Epoch:  4\n",
            "Loss:  0.5082311\n",
            "Epoch:  4\n",
            "Loss:  0.5540926\n",
            "Epoch:  4\n",
            "Loss:  0.59147525\n",
            "Epoch:  4\n",
            "Loss:  0.6144529\n",
            "Epoch:  4\n",
            "Loss:  0.711912\n",
            "Epoch:  4\n",
            "Loss:  0.64286226\n",
            "Epoch:  4\n",
            "Loss:  0.54511887\n",
            "Epoch:  4\n",
            "Loss:  0.5892939\n",
            "Epoch:  4\n",
            "Loss:  0.55740994\n",
            "Epoch:  4\n",
            "Loss:  0.6260479\n",
            "Epoch:  4\n",
            "Loss:  0.56506\n",
            "Epoch:  4\n",
            "Loss:  0.60062325\n",
            "Epoch:  4\n",
            "Loss:  0.47596806\n",
            "Epoch:  4\n",
            "Loss:  0.61219805\n",
            "Epoch:  4\n",
            "Loss:  0.6539803\n",
            "Epoch:  4\n",
            "Loss:  0.5551308\n",
            "Epoch:  4\n",
            "Loss:  0.641919\n",
            "Epoch:  4\n",
            "Loss:  0.55950123\n",
            "Epoch:  4\n",
            "Loss:  0.5973329\n",
            "Epoch:  4\n",
            "Loss:  0.50658864\n",
            "Epoch:  4\n",
            "Loss:  0.6318109\n",
            "Epoch:  4\n",
            "Loss:  0.53721595\n",
            "Epoch:  4\n",
            "Loss:  0.66040534\n",
            "Epoch:  4\n",
            "Loss:  0.53366476\n",
            "Epoch:  4\n",
            "Loss:  0.67504585\n",
            "Epoch:  4\n",
            "Loss:  0.66094136\n",
            "Epoch:  4\n",
            "Loss:  0.69073915\n",
            "Epoch:  4\n",
            "Loss:  0.543625\n",
            "Epoch:  4\n",
            "Loss:  0.66597474\n",
            "Epoch:  4\n",
            "Loss:  0.6550028\n",
            "Epoch:  4\n",
            "Loss:  0.6411915\n",
            "Epoch:  4\n",
            "Loss:  0.5383261\n",
            "Epoch:  4\n",
            "Loss:  0.650385\n",
            "Epoch:  4\n",
            "Loss:  0.634879\n",
            "Epoch:  4\n",
            "Loss:  0.5853716\n",
            "Epoch:  4\n",
            "Loss:  0.6382381\n",
            "Epoch:  4\n",
            "Loss:  0.63809466\n",
            "Epoch:  4\n",
            "Loss:  0.56293833\n",
            "Epoch:  4\n",
            "Loss:  0.5466616\n",
            "Epoch:  4\n",
            "Loss:  0.5880121\n",
            "Epoch:  4\n",
            "Loss:  0.5545749\n",
            "Epoch:  4\n",
            "Loss:  0.6403955\n",
            "Epoch:  4\n",
            "Loss:  0.6132939\n",
            "Epoch:  4\n",
            "Loss:  0.57859147\n",
            "Epoch:  4\n",
            "Loss:  0.578467\n",
            "Epoch:  4\n",
            "Loss:  0.6424145\n",
            "Epoch:  4\n",
            "Loss:  0.5296763\n",
            "Epoch:  4\n",
            "Loss:  0.68941694\n",
            "Epoch:  4\n",
            "Loss:  0.61899346\n",
            "Epoch:  4\n",
            "Loss:  0.5544492\n",
            "Epoch:  4\n",
            "Loss:  0.55355453\n",
            "Epoch:  4\n",
            "Loss:  0.62481415\n",
            "Epoch:  4\n",
            "Loss:  0.6268164\n",
            "Epoch:  4\n",
            "Loss:  0.60676324\n",
            "Epoch:  4\n",
            "Loss:  0.56645155\n",
            "Epoch:  4\n",
            "Loss:  0.5638133\n",
            "Epoch:  4\n",
            "Loss:  0.5847635\n",
            "Epoch:  4\n",
            "Loss:  0.6060661\n",
            "Epoch:  4\n",
            "Loss:  0.6547637\n",
            "Epoch:  4\n",
            "Loss:  0.69525826\n",
            "Epoch:  4\n",
            "Loss:  0.5954996\n",
            "Epoch:  4\n",
            "Loss:  0.557344\n",
            "Epoch:  4\n",
            "Loss:  0.6808327\n",
            "Epoch:  4\n",
            "Loss:  0.6033215\n",
            "Epoch:  4\n",
            "Loss:  0.64534956\n",
            "Epoch:  4\n",
            "Loss:  0.5625371\n",
            "Epoch:  4\n",
            "Loss:  0.7465682\n",
            "Epoch:  4\n",
            "Loss:  0.6792023\n",
            "Epoch:  4\n",
            "Loss:  0.6200378\n",
            "Epoch:  4\n",
            "Loss:  0.5552444\n",
            "Epoch:  4\n",
            "Loss:  0.6757177\n",
            "Epoch:  4\n",
            "Loss:  0.5823995\n",
            "Epoch:  4\n",
            "Loss:  0.6901111\n",
            "Epoch:  4\n",
            "Loss:  0.58037025\n",
            "Epoch:  4\n",
            "Loss:  0.5909039\n",
            "Epoch:  4\n",
            "Loss:  0.57285917\n",
            "Epoch:  4\n",
            "Loss:  0.54574627\n",
            "Epoch:  4\n",
            "Loss:  0.69419026\n",
            "Epoch:  4\n",
            "Loss:  0.53188735\n",
            "Epoch:  4\n",
            "Loss:  0.59605306\n",
            "Epoch:  4\n",
            "Loss:  0.5353343\n",
            "Epoch:  4\n",
            "Loss:  0.6097108\n",
            "Epoch:  4\n",
            "Loss:  0.6087005\n",
            "Epoch:  4\n",
            "Loss:  0.6511587\n",
            "Epoch:  4\n",
            "Loss:  0.5287273\n",
            "Epoch:  4\n",
            "Loss:  0.6174339\n",
            "Epoch:  4\n",
            "Loss:  0.49602422\n",
            "Epoch:  4\n",
            "Loss:  0.6079613\n",
            "Epoch:  4\n",
            "Loss:  0.5387939\n",
            "Epoch:  4\n",
            "Loss:  0.5376087\n",
            "Epoch:  4\n",
            "Loss:  0.6572741\n",
            "Epoch:  4\n",
            "Loss:  0.57803196\n",
            "Epoch:  4\n",
            "Loss:  0.65416086\n",
            "Epoch:  4\n",
            "Loss:  0.60763454\n",
            "Epoch:  4\n",
            "Loss:  0.6326735\n",
            "Epoch:  4\n",
            "Loss:  0.7011558\n",
            "Epoch:  4\n",
            "Loss:  0.6027924\n",
            "Epoch:  4\n",
            "Loss:  0.64763564\n",
            "Epoch:  4\n",
            "Loss:  0.64436066\n",
            "Epoch:  4\n",
            "Loss:  0.66393596\n",
            "Epoch:  4\n",
            "Loss:  0.59902537\n",
            "Epoch:  4\n",
            "Loss:  0.594627\n",
            "Epoch:  4\n",
            "Loss:  0.67227876\n",
            "Epoch:  4\n",
            "Loss:  0.5832366\n",
            "Epoch:  4\n",
            "Loss:  0.6163724\n",
            "Epoch:  4\n",
            "Loss:  0.69393647\n",
            "Epoch:  4\n",
            "Loss:  0.5612775\n",
            "Epoch:  4\n",
            "Loss:  0.62306726\n",
            "Epoch:  4\n",
            "Loss:  0.62553865\n",
            "Epoch:  4\n",
            "Loss:  0.6437257\n",
            "Epoch:  4\n",
            "Loss:  0.6344913\n",
            "Epoch:  4\n",
            "Loss:  0.6954175\n",
            "Epoch:  4\n",
            "Loss:  0.6918005\n",
            "Epoch:  4\n",
            "Loss:  0.5981919\n",
            "Epoch:  4\n",
            "Loss:  0.7134605\n",
            "Epoch:  4\n",
            "Loss:  0.67629296\n",
            "Epoch:  4\n",
            "Loss:  0.7081481\n",
            "Epoch:  4\n",
            "Loss:  0.7184074\n",
            "Epoch:  4\n",
            "Loss:  0.7402477\n",
            "Epoch:  4\n",
            "Loss:  0.50006634\n",
            "Epoch:  4\n",
            "Loss:  0.54372805\n",
            "Epoch:  4\n",
            "Loss:  0.6118062\n",
            "Epoch:  4\n",
            "Loss:  0.51327646\n",
            "Epoch:  4\n",
            "Loss:  0.595469\n",
            "Epoch:  4\n",
            "Loss:  0.511444\n",
            "Epoch:  4\n",
            "Loss:  0.6474878\n",
            "Epoch:  4\n",
            "Loss:  0.615809\n",
            "Epoch:  4\n",
            "Loss:  0.61910355\n",
            "Epoch:  4\n",
            "Loss:  0.54945517\n",
            "Epoch:  4\n",
            "Loss:  0.5995455\n",
            "Epoch:  4\n",
            "Loss:  0.5401317\n",
            "Epoch:  4\n",
            "Loss:  0.5853989\n",
            "Epoch:  4\n",
            "Loss:  0.69612354\n",
            "Epoch:  4\n",
            "Loss:  0.67333186\n",
            "Epoch:  4\n",
            "Loss:  0.6197669\n",
            "Epoch:  4\n",
            "Loss:  0.59966546\n",
            "Epoch:  4\n",
            "Loss:  0.630609\n",
            "Epoch:  4\n",
            "Loss:  0.5771627\n",
            "Epoch:  4\n",
            "Loss:  0.573883\n",
            "Epoch:  4\n",
            "Loss:  0.5951431\n",
            "Epoch:  4\n",
            "Loss:  0.59197104\n",
            "Epoch:  4\n",
            "Loss:  0.5887636\n",
            "Epoch:  4\n",
            "Loss:  0.654354\n",
            "Epoch:  4\n",
            "Loss:  0.49244198\n",
            "Epoch:  4\n",
            "Loss:  0.74309623\n",
            "Epoch:  4\n",
            "Loss:  0.5644294\n",
            "Epoch:  4\n",
            "Loss:  0.4640935\n",
            "Epoch:  4\n",
            "Loss:  0.53202015\n",
            "Epoch:  4\n",
            "Loss:  0.61323553\n",
            "Epoch:  4\n",
            "Loss:  0.6414477\n",
            "Epoch:  4\n",
            "Loss:  0.6125557\n",
            "Epoch:  4\n",
            "Loss:  0.54971373\n",
            "Epoch:  4\n",
            "Loss:  0.61162627\n",
            "Epoch:  4\n",
            "Loss:  0.54389364\n",
            "Epoch:  4\n",
            "Loss:  0.6030112\n",
            "Epoch:  4\n",
            "Loss:  0.65654236\n",
            "Epoch:  4\n",
            "Loss:  0.58681846\n",
            "Epoch:  4\n",
            "Loss:  0.7147644\n",
            "Epoch:  4\n",
            "Loss:  0.670588\n",
            "Epoch:  4\n",
            "Loss:  0.535081\n",
            "Epoch:  4\n",
            "Loss:  0.52714837\n",
            "Epoch:  4\n",
            "Loss:  0.5812337\n",
            "Epoch:  4\n",
            "Loss:  0.6342923\n",
            "Epoch:  4\n",
            "Loss:  0.50280327\n",
            "Epoch:  4\n",
            "Loss:  0.5004717\n",
            "Epoch:  4\n",
            "Loss:  0.5075342\n",
            "Epoch:  4\n",
            "Loss:  0.6313906\n",
            "Epoch:  4\n",
            "Loss:  0.62604535\n",
            "Epoch:  4\n",
            "Loss:  0.6887127\n",
            "Epoch:  4\n",
            "Loss:  0.5927521\n",
            "Epoch:  4\n",
            "Loss:  0.6025753\n",
            "Epoch:  4\n",
            "Loss:  0.68842566\n",
            "Epoch:  4\n",
            "Loss:  0.54764086\n",
            "Epoch:  4\n",
            "Loss:  0.6651308\n",
            "Epoch:  4\n",
            "Loss:  0.6474447\n",
            "Epoch:  4\n",
            "Loss:  0.6179458\n",
            "Epoch:  4\n",
            "Loss:  0.58712023\n",
            "Epoch:  4\n",
            "Loss:  0.5681526\n",
            "Epoch:  4\n",
            "Loss:  0.56245506\n",
            "Epoch:  4\n",
            "Loss:  0.55102915\n",
            "Epoch:  4\n",
            "Loss:  0.5982691\n",
            "Epoch:  4\n",
            "Loss:  0.607065\n",
            "Epoch:  4\n",
            "Loss:  0.5860649\n",
            "Epoch:  4\n",
            "Loss:  0.5226373\n",
            "Epoch:  4\n",
            "Loss:  0.61778414\n",
            "Epoch:  4\n",
            "Loss:  0.71672523\n",
            "Epoch:  4\n",
            "Loss:  0.4855259\n",
            "Epoch:  4\n",
            "Loss:  0.6045763\n",
            "Epoch:  4\n",
            "Loss:  0.6539335\n",
            "Epoch:  4\n",
            "Loss:  0.54226345\n",
            "Epoch:  4\n",
            "Loss:  0.6588887\n",
            "Epoch:  4\n",
            "Loss:  0.56651163\n",
            "Epoch:  4\n",
            "Loss:  0.57060117\n",
            "Epoch:  4\n",
            "Loss:  0.5290758\n",
            "Epoch:  4\n",
            "Loss:  0.56509715\n",
            "Epoch:  4\n",
            "Loss:  0.6023066\n",
            "Epoch:  4\n",
            "Loss:  0.5764331\n",
            "Epoch:  4\n",
            "Loss:  0.58923614\n",
            "Epoch:  4\n",
            "Loss:  0.5158131\n",
            "Epoch:  4\n",
            "Loss:  0.5596043\n",
            "Epoch:  4\n",
            "Loss:  0.5421676\n",
            "Epoch:  4\n",
            "Loss:  0.530118\n",
            "Epoch:  4\n",
            "Loss:  0.5790499\n",
            "Epoch:  4\n",
            "Loss:  0.49804154\n",
            "Epoch:  4\n",
            "Loss:  0.51974964\n",
            "Epoch:  4\n",
            "Loss:  0.6463729\n",
            "Epoch:  4\n",
            "Loss:  0.61121833\n",
            "Epoch:  4\n",
            "Loss:  0.64038056\n",
            "Epoch:  4\n",
            "Loss:  0.5199991\n",
            "Epoch:  4\n",
            "Loss:  0.5340281\n",
            "Epoch:  4\n",
            "Loss:  0.5661008\n",
            "Epoch:  4\n",
            "Loss:  0.53023726\n",
            "Epoch:  4\n",
            "Loss:  0.5673857\n",
            "Epoch:  4\n",
            "Loss:  0.5326427\n",
            "Epoch:  4\n",
            "Loss:  0.52564293\n",
            "Epoch:  4\n",
            "Loss:  0.5864555\n",
            "Epoch:  5\n",
            "Loss:  0.41611457\n",
            "Epoch:  5\n",
            "Loss:  0.43713307\n",
            "Epoch:  5\n",
            "Loss:  0.4259158\n",
            "Epoch:  5\n",
            "Loss:  0.4427169\n",
            "Epoch:  5\n",
            "Loss:  0.3285505\n",
            "Epoch:  5\n",
            "Loss:  0.39708108\n",
            "Epoch:  5\n",
            "Loss:  0.44689378\n",
            "Epoch:  5\n",
            "Loss:  0.4360252\n",
            "Epoch:  5\n",
            "Loss:  0.37552804\n",
            "Epoch:  5\n",
            "Loss:  0.33960468\n",
            "Epoch:  5\n",
            "Loss:  0.35996935\n",
            "Epoch:  5\n",
            "Loss:  0.43227297\n",
            "Epoch:  5\n",
            "Loss:  0.38834035\n",
            "Epoch:  5\n",
            "Loss:  0.4384091\n",
            "Epoch:  5\n",
            "Loss:  0.36756766\n",
            "Epoch:  5\n",
            "Loss:  0.41849104\n",
            "Epoch:  5\n",
            "Loss:  0.37713403\n",
            "Epoch:  5\n",
            "Loss:  0.41164356\n",
            "Epoch:  5\n",
            "Loss:  0.33856285\n",
            "Epoch:  5\n",
            "Loss:  0.4497775\n",
            "Epoch:  5\n",
            "Loss:  0.35055584\n",
            "Epoch:  5\n",
            "Loss:  0.37255222\n",
            "Epoch:  5\n",
            "Loss:  0.37405658\n",
            "Epoch:  5\n",
            "Loss:  0.44661862\n",
            "Epoch:  5\n",
            "Loss:  0.41638547\n",
            "Epoch:  5\n",
            "Loss:  0.3773199\n",
            "Epoch:  5\n",
            "Loss:  0.42711872\n",
            "Epoch:  5\n",
            "Loss:  0.33748353\n",
            "Epoch:  5\n",
            "Loss:  0.45238823\n",
            "Epoch:  5\n",
            "Loss:  0.47846407\n",
            "Epoch:  5\n",
            "Loss:  0.388516\n",
            "Epoch:  5\n",
            "Loss:  0.41563877\n",
            "Epoch:  5\n",
            "Loss:  0.35354525\n",
            "Epoch:  5\n",
            "Loss:  0.4189911\n",
            "Epoch:  5\n",
            "Loss:  0.36429852\n",
            "Epoch:  5\n",
            "Loss:  0.39083713\n",
            "Epoch:  5\n",
            "Loss:  0.50027543\n",
            "Epoch:  5\n",
            "Loss:  0.35168505\n",
            "Epoch:  5\n",
            "Loss:  0.4065433\n",
            "Epoch:  5\n",
            "Loss:  0.36628628\n",
            "Epoch:  5\n",
            "Loss:  0.34223932\n",
            "Epoch:  5\n",
            "Loss:  0.37682092\n",
            "Epoch:  5\n",
            "Loss:  0.4397491\n",
            "Epoch:  5\n",
            "Loss:  0.37726244\n",
            "Epoch:  5\n",
            "Loss:  0.41785017\n",
            "Epoch:  5\n",
            "Loss:  0.4379868\n",
            "Epoch:  5\n",
            "Loss:  0.41701317\n",
            "Epoch:  5\n",
            "Loss:  0.3171099\n",
            "Epoch:  5\n",
            "Loss:  0.3714125\n",
            "Epoch:  5\n",
            "Loss:  0.4312114\n",
            "Epoch:  5\n",
            "Loss:  0.4041792\n",
            "Epoch:  5\n",
            "Loss:  0.4144867\n",
            "Epoch:  5\n",
            "Loss:  0.46216148\n",
            "Epoch:  5\n",
            "Loss:  0.43141705\n",
            "Epoch:  5\n",
            "Loss:  0.42511424\n",
            "Epoch:  5\n",
            "Loss:  0.5028657\n",
            "Epoch:  5\n",
            "Loss:  0.37633243\n",
            "Epoch:  5\n",
            "Loss:  0.44695044\n",
            "Epoch:  5\n",
            "Loss:  0.39046937\n",
            "Epoch:  5\n",
            "Loss:  0.39796036\n",
            "Epoch:  5\n",
            "Loss:  0.50607324\n",
            "Epoch:  5\n",
            "Loss:  0.4414135\n",
            "Epoch:  5\n",
            "Loss:  0.43942666\n",
            "Epoch:  5\n",
            "Loss:  0.40319577\n",
            "Epoch:  5\n",
            "Loss:  0.31174055\n",
            "Epoch:  5\n",
            "Loss:  0.52838707\n",
            "Epoch:  5\n",
            "Loss:  0.38492605\n",
            "Epoch:  5\n",
            "Loss:  0.42822146\n",
            "Epoch:  5\n",
            "Loss:  0.42219424\n",
            "Epoch:  5\n",
            "Loss:  0.3513672\n",
            "Epoch:  5\n",
            "Loss:  0.4076386\n",
            "Epoch:  5\n",
            "Loss:  0.45145145\n",
            "Epoch:  5\n",
            "Loss:  0.46904197\n",
            "Epoch:  5\n",
            "Loss:  0.3969509\n",
            "Epoch:  5\n",
            "Loss:  0.36235923\n",
            "Epoch:  5\n",
            "Loss:  0.37810382\n",
            "Epoch:  5\n",
            "Loss:  0.31944233\n",
            "Epoch:  5\n",
            "Loss:  0.4694345\n",
            "Epoch:  5\n",
            "Loss:  0.4200162\n",
            "Epoch:  5\n",
            "Loss:  0.41433796\n",
            "Epoch:  5\n",
            "Loss:  0.45003724\n",
            "Epoch:  5\n",
            "Loss:  0.43985516\n",
            "Epoch:  5\n",
            "Loss:  0.44608164\n",
            "Epoch:  5\n",
            "Loss:  0.47208494\n",
            "Epoch:  5\n",
            "Loss:  0.4272821\n",
            "Epoch:  5\n",
            "Loss:  0.46858627\n",
            "Epoch:  5\n",
            "Loss:  0.4379734\n",
            "Epoch:  5\n",
            "Loss:  0.37499282\n",
            "Epoch:  5\n",
            "Loss:  0.362068\n",
            "Epoch:  5\n",
            "Loss:  0.4135909\n",
            "Epoch:  5\n",
            "Loss:  0.38956344\n",
            "Epoch:  5\n",
            "Loss:  0.46870142\n",
            "Epoch:  5\n",
            "Loss:  0.46949205\n",
            "Epoch:  5\n",
            "Loss:  0.46535286\n",
            "Epoch:  5\n",
            "Loss:  0.41258615\n",
            "Epoch:  5\n",
            "Loss:  0.3779428\n",
            "Epoch:  5\n",
            "Loss:  0.4331832\n",
            "Epoch:  5\n",
            "Loss:  0.33827257\n",
            "Epoch:  5\n",
            "Loss:  0.42216104\n",
            "Epoch:  5\n",
            "Loss:  0.37412068\n",
            "Epoch:  5\n",
            "Loss:  0.41608357\n",
            "Epoch:  5\n",
            "Loss:  0.42234802\n",
            "Epoch:  5\n",
            "Loss:  0.42707333\n",
            "Epoch:  5\n",
            "Loss:  0.41136974\n",
            "Epoch:  5\n",
            "Loss:  0.47197166\n",
            "Epoch:  5\n",
            "Loss:  0.3807665\n",
            "Epoch:  5\n",
            "Loss:  0.3966856\n",
            "Epoch:  5\n",
            "Loss:  0.5153343\n",
            "Epoch:  5\n",
            "Loss:  0.50872123\n",
            "Epoch:  5\n",
            "Loss:  0.42963386\n",
            "Epoch:  5\n",
            "Loss:  0.4272762\n",
            "Epoch:  5\n",
            "Loss:  0.4576086\n",
            "Epoch:  5\n",
            "Loss:  0.4855837\n",
            "Epoch:  5\n",
            "Loss:  0.47560358\n",
            "Epoch:  5\n",
            "Loss:  0.39975432\n",
            "Epoch:  5\n",
            "Loss:  0.40672716\n",
            "Epoch:  5\n",
            "Loss:  0.4101624\n",
            "Epoch:  5\n",
            "Loss:  0.41966057\n",
            "Epoch:  5\n",
            "Loss:  0.49847874\n",
            "Epoch:  5\n",
            "Loss:  0.48902902\n",
            "Epoch:  5\n",
            "Loss:  0.4295853\n",
            "Epoch:  5\n",
            "Loss:  0.34354392\n",
            "Epoch:  5\n",
            "Loss:  0.4820715\n",
            "Epoch:  5\n",
            "Loss:  0.38799894\n",
            "Epoch:  5\n",
            "Loss:  0.47847778\n",
            "Epoch:  5\n",
            "Loss:  0.43055725\n",
            "Epoch:  5\n",
            "Loss:  0.45267257\n",
            "Epoch:  5\n",
            "Loss:  0.43225417\n",
            "Epoch:  5\n",
            "Loss:  0.4514317\n",
            "Epoch:  5\n",
            "Loss:  0.39534357\n",
            "Epoch:  5\n",
            "Loss:  0.51165766\n",
            "Epoch:  5\n",
            "Loss:  0.41489428\n",
            "Epoch:  5\n",
            "Loss:  0.41323954\n",
            "Epoch:  5\n",
            "Loss:  0.4192717\n",
            "Epoch:  5\n",
            "Loss:  0.3877163\n",
            "Epoch:  5\n",
            "Loss:  0.3246102\n",
            "Epoch:  5\n",
            "Loss:  0.43944806\n",
            "Epoch:  5\n",
            "Loss:  0.45588747\n",
            "Epoch:  5\n",
            "Loss:  0.40254623\n",
            "Epoch:  5\n",
            "Loss:  0.38089466\n",
            "Epoch:  5\n",
            "Loss:  0.50373054\n",
            "Epoch:  5\n",
            "Loss:  0.51308954\n",
            "Epoch:  5\n",
            "Loss:  0.38701257\n",
            "Epoch:  5\n",
            "Loss:  0.42094526\n",
            "Epoch:  5\n",
            "Loss:  0.51194674\n",
            "Epoch:  5\n",
            "Loss:  0.3567919\n",
            "Epoch:  5\n",
            "Loss:  0.4903098\n",
            "Epoch:  5\n",
            "Loss:  0.38834545\n",
            "Epoch:  5\n",
            "Loss:  0.46015066\n",
            "Epoch:  5\n",
            "Loss:  0.4544042\n",
            "Epoch:  5\n",
            "Loss:  0.3643159\n",
            "Epoch:  5\n",
            "Loss:  0.432617\n",
            "Epoch:  5\n",
            "Loss:  0.48138118\n",
            "Epoch:  5\n",
            "Loss:  0.35268793\n",
            "Epoch:  5\n",
            "Loss:  0.40729517\n",
            "Epoch:  5\n",
            "Loss:  0.40809622\n",
            "Epoch:  5\n",
            "Loss:  0.4666825\n",
            "Epoch:  5\n",
            "Loss:  0.45323643\n",
            "Epoch:  5\n",
            "Loss:  0.44405937\n",
            "Epoch:  5\n",
            "Loss:  0.43700904\n",
            "Epoch:  5\n",
            "Loss:  0.4222262\n",
            "Epoch:  5\n",
            "Loss:  0.350148\n",
            "Epoch:  5\n",
            "Loss:  0.36072606\n",
            "Epoch:  5\n",
            "Loss:  0.36213046\n",
            "Epoch:  5\n",
            "Loss:  0.45015588\n",
            "Epoch:  5\n",
            "Loss:  0.5098785\n",
            "Epoch:  5\n",
            "Loss:  0.43022782\n",
            "Epoch:  5\n",
            "Loss:  0.418322\n",
            "Epoch:  5\n",
            "Loss:  0.41228595\n",
            "Epoch:  5\n",
            "Loss:  0.45589367\n",
            "Epoch:  5\n",
            "Loss:  0.38620648\n",
            "Epoch:  5\n",
            "Loss:  0.48638934\n",
            "Epoch:  5\n",
            "Loss:  0.45091572\n",
            "Epoch:  5\n",
            "Loss:  0.46370593\n",
            "Epoch:  5\n",
            "Loss:  0.4373595\n",
            "Epoch:  5\n",
            "Loss:  0.42674416\n",
            "Epoch:  5\n",
            "Loss:  0.42570728\n",
            "Epoch:  5\n",
            "Loss:  0.41536504\n",
            "Epoch:  5\n",
            "Loss:  0.5056676\n",
            "Epoch:  5\n",
            "Loss:  0.45851564\n",
            "Epoch:  5\n",
            "Loss:  0.37488595\n",
            "Epoch:  5\n",
            "Loss:  0.48529783\n",
            "Epoch:  5\n",
            "Loss:  0.43887544\n",
            "Epoch:  5\n",
            "Loss:  0.43660784\n",
            "Epoch:  5\n",
            "Loss:  0.35955834\n",
            "Epoch:  5\n",
            "Loss:  0.46399775\n",
            "Epoch:  5\n",
            "Loss:  0.42993125\n",
            "Epoch:  5\n",
            "Loss:  0.4714002\n",
            "Epoch:  5\n",
            "Loss:  0.4597656\n",
            "Epoch:  5\n",
            "Loss:  0.3806552\n",
            "Epoch:  5\n",
            "Loss:  0.42243332\n",
            "Epoch:  5\n",
            "Loss:  0.42358407\n",
            "Epoch:  5\n",
            "Loss:  0.43561903\n",
            "Epoch:  5\n",
            "Loss:  0.47144452\n",
            "Epoch:  5\n",
            "Loss:  0.4363111\n",
            "Epoch:  5\n",
            "Loss:  0.44905448\n",
            "Epoch:  5\n",
            "Loss:  0.37666565\n",
            "Epoch:  5\n",
            "Loss:  0.49319345\n",
            "Epoch:  5\n",
            "Loss:  0.45381004\n",
            "Epoch:  5\n",
            "Loss:  0.32764715\n",
            "Epoch:  5\n",
            "Loss:  0.4325067\n",
            "Epoch:  5\n",
            "Loss:  0.40119427\n",
            "Epoch:  5\n",
            "Loss:  0.4471522\n",
            "Epoch:  5\n",
            "Loss:  0.5402757\n",
            "Epoch:  5\n",
            "Loss:  0.44753647\n",
            "Epoch:  5\n",
            "Loss:  0.47005945\n",
            "Epoch:  5\n",
            "Loss:  0.48609668\n",
            "Epoch:  5\n",
            "Loss:  0.38485205\n",
            "Epoch:  5\n",
            "Loss:  0.45691818\n",
            "Epoch:  5\n",
            "Loss:  0.4592053\n",
            "Epoch:  5\n",
            "Loss:  0.43003082\n",
            "Epoch:  5\n",
            "Loss:  0.4189709\n",
            "Epoch:  5\n",
            "Loss:  0.44372025\n",
            "Epoch:  5\n",
            "Loss:  0.43884563\n",
            "Epoch:  5\n",
            "Loss:  0.51101965\n",
            "Epoch:  5\n",
            "Loss:  0.44047135\n",
            "Epoch:  5\n",
            "Loss:  0.40590924\n",
            "Epoch:  5\n",
            "Loss:  0.4673032\n",
            "Epoch:  5\n",
            "Loss:  0.36665875\n",
            "Epoch:  5\n",
            "Loss:  0.40143266\n",
            "Epoch:  5\n",
            "Loss:  0.48819104\n",
            "Epoch:  5\n",
            "Loss:  0.40403003\n",
            "Epoch:  5\n",
            "Loss:  0.41186413\n",
            "Epoch:  5\n",
            "Loss:  0.35328728\n",
            "Epoch:  5\n",
            "Loss:  0.5570836\n",
            "Epoch:  5\n",
            "Loss:  0.35965803\n",
            "Epoch:  5\n",
            "Loss:  0.4836902\n",
            "Epoch:  5\n",
            "Loss:  0.36940184\n",
            "Epoch:  5\n",
            "Loss:  0.3613294\n",
            "Epoch:  5\n",
            "Loss:  0.4185329\n",
            "Epoch:  5\n",
            "Loss:  0.40973958\n",
            "Epoch:  5\n",
            "Loss:  0.38607833\n",
            "Epoch:  5\n",
            "Loss:  0.45465714\n",
            "Epoch:  5\n",
            "Loss:  0.3896648\n",
            "Epoch:  5\n",
            "Loss:  0.40963173\n",
            "Epoch:  5\n",
            "Loss:  0.40819222\n",
            "Epoch:  5\n",
            "Loss:  0.40123016\n",
            "Epoch:  5\n",
            "Loss:  0.4472447\n",
            "Epoch:  5\n",
            "Loss:  0.38462567\n",
            "Epoch:  5\n",
            "Loss:  0.41204196\n",
            "Epoch:  5\n",
            "Loss:  0.49583405\n",
            "Epoch:  5\n",
            "Loss:  0.41024572\n",
            "Epoch:  5\n",
            "Loss:  0.44470215\n",
            "Epoch:  5\n",
            "Loss:  0.38220856\n",
            "Epoch:  5\n",
            "Loss:  0.48554635\n",
            "Epoch:  5\n",
            "Loss:  0.40402794\n",
            "Epoch:  5\n",
            "Loss:  0.5091791\n",
            "Epoch:  5\n",
            "Loss:  0.43968883\n",
            "Epoch:  5\n",
            "Loss:  0.46665803\n",
            "Epoch:  5\n",
            "Loss:  0.45030528\n",
            "Epoch:  6\n",
            "Loss:  0.41774434\n",
            "Epoch:  6\n",
            "Loss:  0.23766568\n",
            "Epoch:  6\n",
            "Loss:  0.27393222\n",
            "Epoch:  6\n",
            "Loss:  0.29264873\n",
            "Epoch:  6\n",
            "Loss:  0.33131838\n",
            "Epoch:  6\n",
            "Loss:  0.28509602\n",
            "Epoch:  6\n",
            "Loss:  0.29223862\n",
            "Epoch:  6\n",
            "Loss:  0.19792894\n",
            "Epoch:  6\n",
            "Loss:  0.2983634\n",
            "Epoch:  6\n",
            "Loss:  0.24817967\n",
            "Epoch:  6\n",
            "Loss:  0.29214212\n",
            "Epoch:  6\n",
            "Loss:  0.267851\n",
            "Epoch:  6\n",
            "Loss:  0.326085\n",
            "Epoch:  6\n",
            "Loss:  0.26849657\n",
            "Epoch:  6\n",
            "Loss:  0.2642583\n",
            "Epoch:  6\n",
            "Loss:  0.27135053\n",
            "Epoch:  6\n",
            "Loss:  0.28754765\n",
            "Epoch:  6\n",
            "Loss:  0.27770892\n",
            "Epoch:  6\n",
            "Loss:  0.33416897\n",
            "Epoch:  6\n",
            "Loss:  0.2671972\n",
            "Epoch:  6\n",
            "Loss:  0.30126137\n",
            "Epoch:  6\n",
            "Loss:  0.2604349\n",
            "Epoch:  6\n",
            "Loss:  0.21463995\n",
            "Epoch:  6\n",
            "Loss:  0.3721997\n",
            "Epoch:  6\n",
            "Loss:  0.2787865\n",
            "Epoch:  6\n",
            "Loss:  0.25466436\n",
            "Epoch:  6\n",
            "Loss:  0.34982106\n",
            "Epoch:  6\n",
            "Loss:  0.2455422\n",
            "Epoch:  6\n",
            "Loss:  0.26286906\n",
            "Epoch:  6\n",
            "Loss:  0.36894745\n",
            "Epoch:  6\n",
            "Loss:  0.29992127\n",
            "Epoch:  6\n",
            "Loss:  0.30684456\n",
            "Epoch:  6\n",
            "Loss:  0.29391104\n",
            "Epoch:  6\n",
            "Loss:  0.2278715\n",
            "Epoch:  6\n",
            "Loss:  0.29753116\n",
            "Epoch:  6\n",
            "Loss:  0.33408272\n",
            "Epoch:  6\n",
            "Loss:  0.26413193\n",
            "Epoch:  6\n",
            "Loss:  0.22437835\n",
            "Epoch:  6\n",
            "Loss:  0.25525892\n",
            "Epoch:  6\n",
            "Loss:  0.2464211\n",
            "Epoch:  6\n",
            "Loss:  0.2534973\n",
            "Epoch:  6\n",
            "Loss:  0.3279738\n",
            "Epoch:  6\n",
            "Loss:  0.27953827\n",
            "Epoch:  6\n",
            "Loss:  0.28151968\n",
            "Epoch:  6\n",
            "Loss:  0.29081383\n",
            "Epoch:  6\n",
            "Loss:  0.29649258\n",
            "Epoch:  6\n",
            "Loss:  0.3397195\n",
            "Epoch:  6\n",
            "Loss:  0.28177127\n",
            "Epoch:  6\n",
            "Loss:  0.34295183\n",
            "Epoch:  6\n",
            "Loss:  0.28564945\n",
            "Epoch:  6\n",
            "Loss:  0.24113116\n",
            "Epoch:  6\n",
            "Loss:  0.3034569\n",
            "Epoch:  6\n",
            "Loss:  0.28545803\n",
            "Epoch:  6\n",
            "Loss:  0.33421502\n",
            "Epoch:  6\n",
            "Loss:  0.27140144\n",
            "Epoch:  6\n",
            "Loss:  0.2644058\n",
            "Epoch:  6\n",
            "Loss:  0.30362925\n",
            "Epoch:  6\n",
            "Loss:  0.30327263\n",
            "Epoch:  6\n",
            "Loss:  0.2633382\n",
            "Epoch:  6\n",
            "Loss:  0.27653342\n",
            "Epoch:  6\n",
            "Loss:  0.32374358\n",
            "Epoch:  6\n",
            "Loss:  0.3325223\n",
            "Epoch:  6\n",
            "Loss:  0.2940227\n",
            "Epoch:  6\n",
            "Loss:  0.2976469\n",
            "Epoch:  6\n",
            "Loss:  0.24405845\n",
            "Epoch:  6\n",
            "Loss:  0.2989454\n",
            "Epoch:  6\n",
            "Loss:  0.2803467\n",
            "Epoch:  6\n",
            "Loss:  0.3000415\n",
            "Epoch:  6\n",
            "Loss:  0.25140917\n",
            "Epoch:  6\n",
            "Loss:  0.31567937\n",
            "Epoch:  6\n",
            "Loss:  0.2704924\n",
            "Epoch:  6\n",
            "Loss:  0.3097572\n",
            "Epoch:  6\n",
            "Loss:  0.3061448\n",
            "Epoch:  6\n",
            "Loss:  0.3287465\n",
            "Epoch:  6\n",
            "Loss:  0.25218102\n",
            "Epoch:  6\n",
            "Loss:  0.33472928\n",
            "Epoch:  6\n",
            "Loss:  0.2629904\n",
            "Epoch:  6\n",
            "Loss:  0.25900203\n",
            "Epoch:  6\n",
            "Loss:  0.26516217\n",
            "Epoch:  6\n",
            "Loss:  0.3644082\n",
            "Epoch:  6\n",
            "Loss:  0.2600755\n",
            "Epoch:  6\n",
            "Loss:  0.25981468\n",
            "Epoch:  6\n",
            "Loss:  0.27342016\n",
            "Epoch:  6\n",
            "Loss:  0.28982684\n",
            "Epoch:  6\n",
            "Loss:  0.2871484\n",
            "Epoch:  6\n",
            "Loss:  0.26524478\n",
            "Epoch:  6\n",
            "Loss:  0.28349632\n",
            "Epoch:  6\n",
            "Loss:  0.30668598\n",
            "Epoch:  6\n",
            "Loss:  0.2899647\n",
            "Epoch:  6\n",
            "Loss:  0.24314694\n",
            "Epoch:  6\n",
            "Loss:  0.3034771\n",
            "Epoch:  6\n",
            "Loss:  0.37513557\n",
            "Epoch:  6\n",
            "Loss:  0.28808996\n",
            "Epoch:  6\n",
            "Loss:  0.2661984\n",
            "Epoch:  6\n",
            "Loss:  0.27866158\n",
            "Epoch:  6\n",
            "Loss:  0.33228832\n",
            "Epoch:  6\n",
            "Loss:  0.3497453\n",
            "Epoch:  6\n",
            "Loss:  0.3387937\n",
            "Epoch:  6\n",
            "Loss:  0.2637092\n",
            "Epoch:  6\n",
            "Loss:  0.29908672\n",
            "Epoch:  6\n",
            "Loss:  0.30136615\n",
            "Epoch:  6\n",
            "Loss:  0.25247473\n",
            "Epoch:  6\n",
            "Loss:  0.31236762\n",
            "Epoch:  6\n",
            "Loss:  0.3250389\n",
            "Epoch:  6\n",
            "Loss:  0.2984026\n",
            "Epoch:  6\n",
            "Loss:  0.30496496\n",
            "Epoch:  6\n",
            "Loss:  0.26010942\n",
            "Epoch:  6\n",
            "Loss:  0.21127096\n",
            "Epoch:  6\n",
            "Loss:  0.29495564\n",
            "Epoch:  6\n",
            "Loss:  0.25208515\n",
            "Epoch:  6\n",
            "Loss:  0.2426449\n",
            "Epoch:  6\n",
            "Loss:  0.24098296\n",
            "Epoch:  6\n",
            "Loss:  0.31304452\n",
            "Epoch:  6\n",
            "Loss:  0.33016905\n",
            "Epoch:  6\n",
            "Loss:  0.324915\n",
            "Epoch:  6\n",
            "Loss:  0.29696676\n",
            "Epoch:  6\n",
            "Loss:  0.3459931\n",
            "Epoch:  6\n",
            "Loss:  0.27891535\n",
            "Epoch:  6\n",
            "Loss:  0.30591434\n",
            "Epoch:  6\n",
            "Loss:  0.31879777\n",
            "Epoch:  6\n",
            "Loss:  0.34271008\n",
            "Epoch:  6\n",
            "Loss:  0.3193716\n",
            "Epoch:  6\n",
            "Loss:  0.3786183\n",
            "Epoch:  6\n",
            "Loss:  0.29304323\n",
            "Epoch:  6\n",
            "Loss:  0.34034246\n",
            "Epoch:  6\n",
            "Loss:  0.28238142\n",
            "Epoch:  6\n",
            "Loss:  0.3429392\n",
            "Epoch:  6\n",
            "Loss:  0.27517697\n",
            "Epoch:  6\n",
            "Loss:  0.27203172\n",
            "Epoch:  6\n",
            "Loss:  0.22624941\n",
            "Epoch:  6\n",
            "Loss:  0.25033352\n",
            "Epoch:  6\n",
            "Loss:  0.33501115\n",
            "Epoch:  6\n",
            "Loss:  0.25090232\n",
            "Epoch:  6\n",
            "Loss:  0.29149652\n",
            "Epoch:  6\n",
            "Loss:  0.32525456\n",
            "Epoch:  6\n",
            "Loss:  0.2724764\n",
            "Epoch:  6\n",
            "Loss:  0.2761148\n",
            "Epoch:  6\n",
            "Loss:  0.3300722\n",
            "Epoch:  6\n",
            "Loss:  0.33284032\n",
            "Epoch:  6\n",
            "Loss:  0.36291677\n",
            "Epoch:  6\n",
            "Loss:  0.29679817\n",
            "Epoch:  6\n",
            "Loss:  0.28306878\n",
            "Epoch:  6\n",
            "Loss:  0.307797\n",
            "Epoch:  6\n",
            "Loss:  0.3191951\n",
            "Epoch:  6\n",
            "Loss:  0.29800385\n",
            "Epoch:  6\n",
            "Loss:  0.2553953\n",
            "Epoch:  6\n",
            "Loss:  0.3401939\n",
            "Epoch:  6\n",
            "Loss:  0.31620267\n",
            "Epoch:  6\n",
            "Loss:  0.27770638\n",
            "Epoch:  6\n",
            "Loss:  0.33231407\n",
            "Epoch:  6\n",
            "Loss:  0.34435162\n",
            "Epoch:  6\n",
            "Loss:  0.28301644\n",
            "Epoch:  6\n",
            "Loss:  0.39402372\n",
            "Epoch:  6\n",
            "Loss:  0.29166645\n",
            "Epoch:  6\n",
            "Loss:  0.2530713\n",
            "Epoch:  6\n",
            "Loss:  0.3787225\n",
            "Epoch:  6\n",
            "Loss:  0.2779238\n",
            "Epoch:  6\n",
            "Loss:  0.24150121\n",
            "Epoch:  6\n",
            "Loss:  0.37174398\n",
            "Epoch:  6\n",
            "Loss:  0.2904935\n",
            "Epoch:  6\n",
            "Loss:  0.23084795\n",
            "Epoch:  6\n",
            "Loss:  0.31600803\n",
            "Epoch:  6\n",
            "Loss:  0.336899\n",
            "Epoch:  6\n",
            "Loss:  0.2804374\n",
            "Epoch:  6\n",
            "Loss:  0.3825487\n",
            "Epoch:  6\n",
            "Loss:  0.27801228\n",
            "Epoch:  6\n",
            "Loss:  0.34449518\n",
            "Epoch:  6\n",
            "Loss:  0.37210536\n",
            "Epoch:  6\n",
            "Loss:  0.36699522\n",
            "Epoch:  6\n",
            "Loss:  0.3179012\n",
            "Epoch:  6\n",
            "Loss:  0.30378965\n",
            "Epoch:  6\n",
            "Loss:  0.33168772\n",
            "Epoch:  6\n",
            "Loss:  0.3178594\n",
            "Epoch:  6\n",
            "Loss:  0.38404626\n",
            "Epoch:  6\n",
            "Loss:  0.3416798\n",
            "Epoch:  6\n",
            "Loss:  0.31051385\n",
            "Epoch:  6\n",
            "Loss:  0.2679245\n",
            "Epoch:  6\n",
            "Loss:  0.2972021\n",
            "Epoch:  6\n",
            "Loss:  0.3394327\n",
            "Epoch:  6\n",
            "Loss:  0.29940352\n",
            "Epoch:  6\n",
            "Loss:  0.38960007\n",
            "Epoch:  6\n",
            "Loss:  0.29373875\n",
            "Epoch:  6\n",
            "Loss:  0.29007393\n",
            "Epoch:  6\n",
            "Loss:  0.4016849\n",
            "Epoch:  6\n",
            "Loss:  0.32387108\n",
            "Epoch:  6\n",
            "Loss:  0.31664085\n",
            "Epoch:  6\n",
            "Loss:  0.34340352\n",
            "Epoch:  6\n",
            "Loss:  0.33032814\n",
            "Epoch:  6\n",
            "Loss:  0.35703006\n",
            "Epoch:  6\n",
            "Loss:  0.28164825\n",
            "Epoch:  6\n",
            "Loss:  0.37214166\n",
            "Epoch:  6\n",
            "Loss:  0.39204794\n",
            "Epoch:  6\n",
            "Loss:  0.31333792\n",
            "Epoch:  6\n",
            "Loss:  0.25888428\n",
            "Epoch:  6\n",
            "Loss:  0.25279844\n",
            "Epoch:  6\n",
            "Loss:  0.3263423\n",
            "Epoch:  6\n",
            "Loss:  0.31087726\n",
            "Epoch:  6\n",
            "Loss:  0.3451742\n",
            "Epoch:  6\n",
            "Loss:  0.37277296\n",
            "Epoch:  6\n",
            "Loss:  0.3342611\n",
            "Epoch:  6\n",
            "Loss:  0.2955238\n",
            "Epoch:  6\n",
            "Loss:  0.29819793\n",
            "Epoch:  6\n",
            "Loss:  0.22254618\n",
            "Epoch:  6\n",
            "Loss:  0.3207392\n",
            "Epoch:  6\n",
            "Loss:  0.34522152\n",
            "Epoch:  6\n",
            "Loss:  0.2210236\n",
            "Epoch:  6\n",
            "Loss:  0.22990675\n",
            "Epoch:  6\n",
            "Loss:  0.2779894\n",
            "Epoch:  6\n",
            "Loss:  0.29979712\n",
            "Epoch:  6\n",
            "Loss:  0.26965863\n",
            "Epoch:  6\n",
            "Loss:  0.35707998\n",
            "Epoch:  6\n",
            "Loss:  0.31450003\n",
            "Epoch:  6\n",
            "Loss:  0.28343138\n",
            "Epoch:  6\n",
            "Loss:  0.31299788\n",
            "Epoch:  6\n",
            "Loss:  0.31355777\n",
            "Epoch:  6\n",
            "Loss:  0.32749936\n",
            "Epoch:  6\n",
            "Loss:  0.302635\n",
            "Epoch:  6\n",
            "Loss:  0.3127249\n",
            "Epoch:  6\n",
            "Loss:  0.34666592\n",
            "Epoch:  6\n",
            "Loss:  0.35153311\n",
            "Epoch:  6\n",
            "Loss:  0.3199827\n",
            "Epoch:  6\n",
            "Loss:  0.36658412\n",
            "Epoch:  6\n",
            "Loss:  0.354603\n",
            "Epoch:  6\n",
            "Loss:  0.3315499\n",
            "Epoch:  6\n",
            "Loss:  0.2955089\n",
            "Epoch:  6\n",
            "Loss:  0.2506687\n",
            "Epoch:  6\n",
            "Loss:  0.3378431\n",
            "Epoch:  6\n",
            "Loss:  0.2866004\n",
            "Epoch:  6\n",
            "Loss:  0.3056138\n",
            "Epoch:  6\n",
            "Loss:  0.33557728\n",
            "Epoch:  6\n",
            "Loss:  0.2818155\n",
            "Epoch:  6\n",
            "Loss:  0.4085338\n",
            "Epoch:  6\n",
            "Loss:  0.34473214\n",
            "Epoch:  6\n",
            "Loss:  0.3907842\n",
            "Epoch:  6\n",
            "Loss:  0.31417966\n",
            "Epoch:  6\n",
            "Loss:  0.30286542\n",
            "Epoch:  6\n",
            "Loss:  0.33090013\n",
            "Epoch:  6\n",
            "Loss:  0.30632895\n",
            "Epoch:  6\n",
            "Loss:  0.30408484\n",
            "Epoch:  6\n",
            "Loss:  0.27591297\n",
            "Epoch:  6\n",
            "Loss:  0.3398036\n",
            "Epoch:  6\n",
            "Loss:  0.2723754\n",
            "Epoch:  6\n",
            "Loss:  0.29121706\n",
            "Epoch:  6\n",
            "Loss:  0.25485414\n",
            "Epoch:  6\n",
            "Loss:  0.25662673\n",
            "Epoch:  6\n",
            "Loss:  0.30105484\n",
            "Epoch:  6\n",
            "Loss:  0.33875555\n",
            "Epoch:  6\n",
            "Loss:  0.3322416\n",
            "Epoch:  6\n",
            "Loss:  0.40823668\n",
            "Epoch:  6\n",
            "Loss:  0.33162707\n",
            "Epoch:  7\n",
            "Loss:  0.21029799\n",
            "Epoch:  7\n",
            "Loss:  0.19046594\n",
            "Epoch:  7\n",
            "Loss:  0.21441965\n",
            "Epoch:  7\n",
            "Loss:  0.18215914\n",
            "Epoch:  7\n",
            "Loss:  0.19202468\n",
            "Epoch:  7\n",
            "Loss:  0.17714986\n",
            "Epoch:  7\n",
            "Loss:  0.17631117\n",
            "Epoch:  7\n",
            "Loss:  0.15948966\n",
            "Epoch:  7\n",
            "Loss:  0.20624204\n",
            "Epoch:  7\n",
            "Loss:  0.20159781\n",
            "Epoch:  7\n",
            "Loss:  0.23109607\n",
            "Epoch:  7\n",
            "Loss:  0.17454769\n",
            "Epoch:  7\n",
            "Loss:  0.22021484\n",
            "Epoch:  7\n",
            "Loss:  0.2258136\n",
            "Epoch:  7\n",
            "Loss:  0.21997467\n",
            "Epoch:  7\n",
            "Loss:  0.20415919\n",
            "Epoch:  7\n",
            "Loss:  0.17257783\n",
            "Epoch:  7\n",
            "Loss:  0.21143062\n",
            "Epoch:  7\n",
            "Loss:  0.18681096\n",
            "Epoch:  7\n",
            "Loss:  0.32145348\n",
            "Epoch:  7\n",
            "Loss:  0.17560598\n",
            "Epoch:  7\n",
            "Loss:  0.23123911\n",
            "Epoch:  7\n",
            "Loss:  0.1795952\n",
            "Epoch:  7\n",
            "Loss:  0.21001992\n",
            "Epoch:  7\n",
            "Loss:  0.18296494\n",
            "Epoch:  7\n",
            "Loss:  0.22172323\n",
            "Epoch:  7\n",
            "Loss:  0.22601208\n",
            "Epoch:  7\n",
            "Loss:  0.26082236\n",
            "Epoch:  7\n",
            "Loss:  0.18267098\n",
            "Epoch:  7\n",
            "Loss:  0.24743512\n",
            "Epoch:  7\n",
            "Loss:  0.26198667\n",
            "Epoch:  7\n",
            "Loss:  0.1934292\n",
            "Epoch:  7\n",
            "Loss:  0.17353483\n",
            "Epoch:  7\n",
            "Loss:  0.21846692\n",
            "Epoch:  7\n",
            "Loss:  0.19546798\n",
            "Epoch:  7\n",
            "Loss:  0.20337227\n",
            "Epoch:  7\n",
            "Loss:  0.19692804\n",
            "Epoch:  7\n",
            "Loss:  0.21356864\n",
            "Epoch:  7\n",
            "Loss:  0.16777049\n",
            "Epoch:  7\n",
            "Loss:  0.20972422\n",
            "Epoch:  7\n",
            "Loss:  0.20573373\n",
            "Epoch:  7\n",
            "Loss:  0.1752119\n",
            "Epoch:  7\n",
            "Loss:  0.17222823\n",
            "Epoch:  7\n",
            "Loss:  0.19681528\n",
            "Epoch:  7\n",
            "Loss:  0.22240975\n",
            "Epoch:  7\n",
            "Loss:  0.22828045\n",
            "Epoch:  7\n",
            "Loss:  0.23342207\n",
            "Epoch:  7\n",
            "Loss:  0.19621065\n",
            "Epoch:  7\n",
            "Loss:  0.22803812\n",
            "Epoch:  7\n",
            "Loss:  0.15281886\n",
            "Epoch:  7\n",
            "Loss:  0.16168873\n",
            "Epoch:  7\n",
            "Loss:  0.1814452\n",
            "Epoch:  7\n",
            "Loss:  0.19139022\n",
            "Epoch:  7\n",
            "Loss:  0.19533788\n",
            "Epoch:  7\n",
            "Loss:  0.23034406\n",
            "Epoch:  7\n",
            "Loss:  0.229744\n",
            "Epoch:  7\n",
            "Loss:  0.21331921\n",
            "Epoch:  7\n",
            "Loss:  0.19885914\n",
            "Epoch:  7\n",
            "Loss:  0.19015124\n",
            "Epoch:  7\n",
            "Loss:  0.18048353\n",
            "Epoch:  7\n",
            "Loss:  0.18767019\n",
            "Epoch:  7\n",
            "Loss:  0.18174699\n",
            "Epoch:  7\n",
            "Loss:  0.18514392\n",
            "Epoch:  7\n",
            "Loss:  0.25700212\n",
            "Epoch:  7\n",
            "Loss:  0.22454102\n",
            "Epoch:  7\n",
            "Loss:  0.2181611\n",
            "Epoch:  7\n",
            "Loss:  0.19735537\n",
            "Epoch:  7\n",
            "Loss:  0.20157859\n",
            "Epoch:  7\n",
            "Loss:  0.18456616\n",
            "Epoch:  7\n",
            "Loss:  0.21111691\n",
            "Epoch:  7\n",
            "Loss:  0.2118226\n",
            "Epoch:  7\n",
            "Loss:  0.24300125\n",
            "Epoch:  7\n",
            "Loss:  0.20892927\n",
            "Epoch:  7\n",
            "Loss:  0.18992826\n",
            "Epoch:  7\n",
            "Loss:  0.2088126\n",
            "Epoch:  7\n",
            "Loss:  0.20036335\n",
            "Epoch:  7\n",
            "Loss:  0.24856873\n",
            "Epoch:  7\n",
            "Loss:  0.19326568\n",
            "Epoch:  7\n",
            "Loss:  0.1882634\n",
            "Epoch:  7\n",
            "Loss:  0.2557473\n",
            "Epoch:  7\n",
            "Loss:  0.204584\n",
            "Epoch:  7\n",
            "Loss:  0.20403774\n",
            "Epoch:  7\n",
            "Loss:  0.16832486\n",
            "Epoch:  7\n",
            "Loss:  0.161599\n",
            "Epoch:  7\n",
            "Loss:  0.23184144\n",
            "Epoch:  7\n",
            "Loss:  0.19426042\n",
            "Epoch:  7\n",
            "Loss:  0.24068865\n",
            "Epoch:  7\n",
            "Loss:  0.18780495\n",
            "Epoch:  7\n",
            "Loss:  0.25817403\n",
            "Epoch:  7\n",
            "Loss:  0.27897173\n",
            "Epoch:  7\n",
            "Loss:  0.16573748\n",
            "Epoch:  7\n",
            "Loss:  0.16943917\n",
            "Epoch:  7\n",
            "Loss:  0.17674501\n",
            "Epoch:  7\n",
            "Loss:  0.1998931\n",
            "Epoch:  7\n",
            "Loss:  0.21572797\n",
            "Epoch:  7\n",
            "Loss:  0.19662865\n",
            "Epoch:  7\n",
            "Loss:  0.23259906\n",
            "Epoch:  7\n",
            "Loss:  0.1879868\n",
            "Epoch:  7\n",
            "Loss:  0.2015398\n",
            "Epoch:  7\n",
            "Loss:  0.26693597\n",
            "Epoch:  7\n",
            "Loss:  0.18264881\n",
            "Epoch:  7\n",
            "Loss:  0.2773117\n",
            "Epoch:  7\n",
            "Loss:  0.23047376\n",
            "Epoch:  7\n",
            "Loss:  0.20156078\n",
            "Epoch:  7\n",
            "Loss:  0.20913032\n",
            "Epoch:  7\n",
            "Loss:  0.19269508\n",
            "Epoch:  7\n",
            "Loss:  0.24036579\n",
            "Epoch:  7\n",
            "Loss:  0.2365042\n",
            "Epoch:  7\n",
            "Loss:  0.2142938\n",
            "Epoch:  7\n",
            "Loss:  0.24463537\n",
            "Epoch:  7\n",
            "Loss:  0.1854465\n",
            "Epoch:  7\n",
            "Loss:  0.1934032\n",
            "Epoch:  7\n",
            "Loss:  0.21781746\n",
            "Epoch:  7\n",
            "Loss:  0.2365034\n",
            "Epoch:  7\n",
            "Loss:  0.23852745\n",
            "Epoch:  7\n",
            "Loss:  0.21074024\n",
            "Epoch:  7\n",
            "Loss:  0.23528759\n",
            "Epoch:  7\n",
            "Loss:  0.22444387\n",
            "Epoch:  7\n",
            "Loss:  0.20346102\n",
            "Epoch:  7\n",
            "Loss:  0.24484773\n",
            "Epoch:  7\n",
            "Loss:  0.1947078\n",
            "Epoch:  7\n",
            "Loss:  0.19633782\n",
            "Epoch:  7\n",
            "Loss:  0.19647509\n",
            "Epoch:  7\n",
            "Loss:  0.25437018\n",
            "Epoch:  7\n",
            "Loss:  0.1976151\n",
            "Epoch:  7\n",
            "Loss:  0.20616357\n",
            "Epoch:  7\n",
            "Loss:  0.19934943\n",
            "Epoch:  7\n",
            "Loss:  0.23715596\n",
            "Epoch:  7\n",
            "Loss:  0.20799676\n",
            "Epoch:  7\n",
            "Loss:  0.25830087\n",
            "Epoch:  7\n",
            "Loss:  0.22122064\n",
            "Epoch:  7\n",
            "Loss:  0.24544302\n",
            "Epoch:  7\n",
            "Loss:  0.30180138\n",
            "Epoch:  7\n",
            "Loss:  0.23061118\n",
            "Epoch:  7\n",
            "Loss:  0.25112098\n",
            "Epoch:  7\n",
            "Loss:  0.221831\n",
            "Epoch:  7\n",
            "Loss:  0.20460252\n",
            "Epoch:  7\n",
            "Loss:  0.20935258\n",
            "Epoch:  7\n",
            "Loss:  0.27584496\n",
            "Epoch:  7\n",
            "Loss:  0.2296079\n",
            "Epoch:  7\n",
            "Loss:  0.2597217\n",
            "Epoch:  7\n",
            "Loss:  0.24061036\n",
            "Epoch:  7\n",
            "Loss:  0.1885121\n",
            "Epoch:  7\n",
            "Loss:  0.22955105\n",
            "Epoch:  7\n",
            "Loss:  0.267765\n",
            "Epoch:  7\n",
            "Loss:  0.2728062\n",
            "Epoch:  7\n",
            "Loss:  0.21590202\n",
            "Epoch:  7\n",
            "Loss:  0.26820248\n",
            "Epoch:  7\n",
            "Loss:  0.26203325\n",
            "Epoch:  7\n",
            "Loss:  0.21990106\n",
            "Epoch:  7\n",
            "Loss:  0.19009453\n",
            "Epoch:  7\n",
            "Loss:  0.18948741\n",
            "Epoch:  7\n",
            "Loss:  0.16852213\n",
            "Epoch:  7\n",
            "Loss:  0.21149428\n",
            "Epoch:  7\n",
            "Loss:  0.24700567\n",
            "Epoch:  7\n",
            "Loss:  0.19954139\n",
            "Epoch:  7\n",
            "Loss:  0.2555849\n",
            "Epoch:  7\n",
            "Loss:  0.21769795\n",
            "Epoch:  7\n",
            "Loss:  0.23536864\n",
            "Epoch:  7\n",
            "Loss:  0.19990894\n",
            "Epoch:  7\n",
            "Loss:  0.26755533\n",
            "Epoch:  7\n",
            "Loss:  0.19917278\n",
            "Epoch:  7\n",
            "Loss:  0.19545248\n",
            "Epoch:  7\n",
            "Loss:  0.24548984\n",
            "Epoch:  7\n",
            "Loss:  0.23952374\n",
            "Epoch:  7\n",
            "Loss:  0.2272131\n",
            "Epoch:  7\n",
            "Loss:  0.26143104\n",
            "Epoch:  7\n",
            "Loss:  0.20057888\n",
            "Epoch:  7\n",
            "Loss:  0.26226932\n",
            "Epoch:  7\n",
            "Loss:  0.19750059\n",
            "Epoch:  7\n",
            "Loss:  0.2151188\n",
            "Epoch:  7\n",
            "Loss:  0.2573285\n",
            "Epoch:  7\n",
            "Loss:  0.208823\n",
            "Epoch:  7\n",
            "Loss:  0.22951773\n",
            "Epoch:  7\n",
            "Loss:  0.21099487\n",
            "Epoch:  7\n",
            "Loss:  0.21504006\n",
            "Epoch:  7\n",
            "Loss:  0.26077908\n",
            "Epoch:  7\n",
            "Loss:  0.21813825\n",
            "Epoch:  7\n",
            "Loss:  0.23906824\n",
            "Epoch:  7\n",
            "Loss:  0.26539788\n",
            "Epoch:  7\n",
            "Loss:  0.27377194\n",
            "Epoch:  7\n",
            "Loss:  0.19364932\n",
            "Epoch:  7\n",
            "Loss:  0.18432525\n",
            "Epoch:  7\n",
            "Loss:  0.21908355\n",
            "Epoch:  7\n",
            "Loss:  0.2737052\n",
            "Epoch:  7\n",
            "Loss:  0.24405496\n",
            "Epoch:  7\n",
            "Loss:  0.1738884\n",
            "Epoch:  7\n",
            "Loss:  0.21742332\n",
            "Epoch:  7\n",
            "Loss:  0.21902338\n",
            "Epoch:  7\n",
            "Loss:  0.22413388\n",
            "Epoch:  7\n",
            "Loss:  0.1547301\n",
            "Epoch:  7\n",
            "Loss:  0.26178688\n",
            "Epoch:  7\n",
            "Loss:  0.19488424\n",
            "Epoch:  7\n",
            "Loss:  0.23461759\n",
            "Epoch:  7\n",
            "Loss:  0.19515678\n",
            "Epoch:  7\n",
            "Loss:  0.27408057\n",
            "Epoch:  7\n",
            "Loss:  0.21247685\n",
            "Epoch:  7\n",
            "Loss:  0.26928207\n",
            "Epoch:  7\n",
            "Loss:  0.1427562\n",
            "Epoch:  7\n",
            "Loss:  0.23774073\n",
            "Epoch:  7\n",
            "Loss:  0.2835973\n",
            "Epoch:  7\n",
            "Loss:  0.22862963\n",
            "Epoch:  7\n",
            "Loss:  0.29423088\n",
            "Epoch:  7\n",
            "Loss:  0.1586478\n",
            "Epoch:  7\n",
            "Loss:  0.18749869\n",
            "Epoch:  7\n",
            "Loss:  0.2531436\n",
            "Epoch:  7\n",
            "Loss:  0.31762272\n",
            "Epoch:  7\n",
            "Loss:  0.17526954\n",
            "Epoch:  7\n",
            "Loss:  0.21279089\n",
            "Epoch:  7\n",
            "Loss:  0.22410312\n",
            "Epoch:  7\n",
            "Loss:  0.23039632\n",
            "Epoch:  7\n",
            "Loss:  0.2576524\n",
            "Epoch:  7\n",
            "Loss:  0.22058752\n",
            "Epoch:  7\n",
            "Loss:  0.26022083\n",
            "Epoch:  7\n",
            "Loss:  0.29195523\n",
            "Epoch:  7\n",
            "Loss:  0.30295327\n",
            "Epoch:  7\n",
            "Loss:  0.27806458\n",
            "Epoch:  7\n",
            "Loss:  0.21491797\n",
            "Epoch:  7\n",
            "Loss:  0.2943978\n",
            "Epoch:  7\n",
            "Loss:  0.27168986\n",
            "Epoch:  7\n",
            "Loss:  0.28877857\n",
            "Epoch:  7\n",
            "Loss:  0.21638253\n",
            "Epoch:  7\n",
            "Loss:  0.2571371\n",
            "Epoch:  7\n",
            "Loss:  0.21370831\n",
            "Epoch:  7\n",
            "Loss:  0.24276337\n",
            "Epoch:  7\n",
            "Loss:  0.19773331\n",
            "Epoch:  7\n",
            "Loss:  0.27365276\n",
            "Epoch:  7\n",
            "Loss:  0.20658223\n",
            "Epoch:  7\n",
            "Loss:  0.23349614\n",
            "Epoch:  7\n",
            "Loss:  0.24881217\n",
            "Epoch:  7\n",
            "Loss:  0.23631339\n",
            "Epoch:  7\n",
            "Loss:  0.23691654\n",
            "Epoch:  7\n",
            "Loss:  0.26254484\n",
            "Epoch:  7\n",
            "Loss:  0.22802863\n",
            "Epoch:  7\n",
            "Loss:  0.2331949\n",
            "Epoch:  7\n",
            "Loss:  0.21661803\n",
            "Epoch:  7\n",
            "Loss:  0.17999466\n",
            "Epoch:  7\n",
            "Loss:  0.25325266\n",
            "Epoch:  7\n",
            "Loss:  0.21832056\n",
            "Epoch:  7\n",
            "Loss:  0.22986507\n",
            "Epoch:  7\n",
            "Loss:  0.2351532\n",
            "Epoch:  7\n",
            "Loss:  0.24155888\n",
            "Epoch:  7\n",
            "Loss:  0.20203733\n",
            "Epoch:  7\n",
            "Loss:  0.24893329\n",
            "Epoch:  7\n",
            "Loss:  0.22775328\n",
            "Epoch:  7\n",
            "Loss:  0.16595158\n",
            "Epoch:  7\n",
            "Loss:  0.21142069\n",
            "Epoch:  7\n",
            "Loss:  0.24780679\n",
            "Epoch:  7\n",
            "Loss:  0.2519719\n",
            "Epoch:  7\n",
            "Loss:  0.22697458\n",
            "Epoch:  8\n",
            "Loss:  0.13850519\n",
            "Epoch:  8\n",
            "Loss:  0.14709462\n",
            "Epoch:  8\n",
            "Loss:  0.14352882\n",
            "Epoch:  8\n",
            "Loss:  0.16853805\n",
            "Epoch:  8\n",
            "Loss:  0.1953803\n",
            "Epoch:  8\n",
            "Loss:  0.18461701\n",
            "Epoch:  8\n",
            "Loss:  0.14682911\n",
            "Epoch:  8\n",
            "Loss:  0.13288762\n",
            "Epoch:  8\n",
            "Loss:  0.17626001\n",
            "Epoch:  8\n",
            "Loss:  0.15259424\n",
            "Epoch:  8\n",
            "Loss:  0.16396596\n",
            "Epoch:  8\n",
            "Loss:  0.117689766\n",
            "Epoch:  8\n",
            "Loss:  0.15962265\n",
            "Epoch:  8\n",
            "Loss:  0.1510356\n",
            "Epoch:  8\n",
            "Loss:  0.13610741\n",
            "Epoch:  8\n",
            "Loss:  0.13814898\n",
            "Epoch:  8\n",
            "Loss:  0.14397737\n",
            "Epoch:  8\n",
            "Loss:  0.18342549\n",
            "Epoch:  8\n",
            "Loss:  0.12312971\n",
            "Epoch:  8\n",
            "Loss:  0.12567472\n",
            "Epoch:  8\n",
            "Loss:  0.14246944\n",
            "Epoch:  8\n",
            "Loss:  0.123944126\n",
            "Epoch:  8\n",
            "Loss:  0.14390315\n",
            "Epoch:  8\n",
            "Loss:  0.14683732\n",
            "Epoch:  8\n",
            "Loss:  0.14349847\n",
            "Epoch:  8\n",
            "Loss:  0.14514937\n",
            "Epoch:  8\n",
            "Loss:  0.1288149\n",
            "Epoch:  8\n",
            "Loss:  0.12266897\n",
            "Epoch:  8\n",
            "Loss:  0.14540935\n",
            "Epoch:  8\n",
            "Loss:  0.14355245\n",
            "Epoch:  8\n",
            "Loss:  0.12623595\n",
            "Epoch:  8\n",
            "Loss:  0.12483893\n",
            "Epoch:  8\n",
            "Loss:  0.1665215\n",
            "Epoch:  8\n",
            "Loss:  0.16699381\n",
            "Epoch:  8\n",
            "Loss:  0.16739628\n",
            "Epoch:  8\n",
            "Loss:  0.18275668\n",
            "Epoch:  8\n",
            "Loss:  0.12288903\n",
            "Epoch:  8\n",
            "Loss:  0.18826261\n",
            "Epoch:  8\n",
            "Loss:  0.14245823\n",
            "Epoch:  8\n",
            "Loss:  0.11094228\n",
            "Epoch:  8\n",
            "Loss:  0.16046694\n",
            "Epoch:  8\n",
            "Loss:  0.16059373\n",
            "Epoch:  8\n",
            "Loss:  0.1574745\n",
            "Epoch:  8\n",
            "Loss:  0.14225718\n",
            "Epoch:  8\n",
            "Loss:  0.14850385\n",
            "Epoch:  8\n",
            "Loss:  0.14398898\n",
            "Epoch:  8\n",
            "Loss:  0.17234883\n",
            "Epoch:  8\n",
            "Loss:  0.16941234\n",
            "Epoch:  8\n",
            "Loss:  0.13470578\n",
            "Epoch:  8\n",
            "Loss:  0.14057341\n",
            "Epoch:  8\n",
            "Loss:  0.14642283\n",
            "Epoch:  8\n",
            "Loss:  0.09396691\n",
            "Epoch:  8\n",
            "Loss:  0.14656699\n",
            "Epoch:  8\n",
            "Loss:  0.15057199\n",
            "Epoch:  8\n",
            "Loss:  0.14345556\n",
            "Epoch:  8\n",
            "Loss:  0.17331094\n",
            "Epoch:  8\n",
            "Loss:  0.19694768\n",
            "Epoch:  8\n",
            "Loss:  0.19547784\n",
            "Epoch:  8\n",
            "Loss:  0.12429024\n",
            "Epoch:  8\n",
            "Loss:  0.14859997\n",
            "Epoch:  8\n",
            "Loss:  0.16408905\n",
            "Epoch:  8\n",
            "Loss:  0.12909356\n",
            "Epoch:  8\n",
            "Loss:  0.16178586\n",
            "Epoch:  8\n",
            "Loss:  0.17634124\n",
            "Epoch:  8\n",
            "Loss:  0.17198591\n",
            "Epoch:  8\n",
            "Loss:  0.18605556\n",
            "Epoch:  8\n",
            "Loss:  0.13466688\n",
            "Epoch:  8\n",
            "Loss:  0.13405916\n",
            "Epoch:  8\n",
            "Loss:  0.17888841\n",
            "Epoch:  8\n",
            "Loss:  0.1810326\n",
            "Epoch:  8\n",
            "Loss:  0.17330298\n",
            "Epoch:  8\n",
            "Loss:  0.12233684\n",
            "Epoch:  8\n",
            "Loss:  0.20609567\n",
            "Epoch:  8\n",
            "Loss:  0.16634707\n",
            "Epoch:  8\n",
            "Loss:  0.14996946\n",
            "Epoch:  8\n",
            "Loss:  0.0913661\n",
            "Epoch:  8\n",
            "Loss:  0.1498507\n",
            "Epoch:  8\n",
            "Loss:  0.10231905\n",
            "Epoch:  8\n",
            "Loss:  0.1742405\n",
            "Epoch:  8\n",
            "Loss:  0.1705542\n",
            "Epoch:  8\n",
            "Loss:  0.13995036\n",
            "Epoch:  8\n",
            "Loss:  0.15888587\n",
            "Epoch:  8\n",
            "Loss:  0.13455293\n",
            "Epoch:  8\n",
            "Loss:  0.17298397\n",
            "Epoch:  8\n",
            "Loss:  0.14005841\n",
            "Epoch:  8\n",
            "Loss:  0.17758586\n",
            "Epoch:  8\n",
            "Loss:  0.16678585\n",
            "Epoch:  8\n",
            "Loss:  0.19463754\n",
            "Epoch:  8\n",
            "Loss:  0.21346101\n",
            "Epoch:  8\n",
            "Loss:  0.17299995\n",
            "Epoch:  8\n",
            "Loss:  0.1623121\n",
            "Epoch:  8\n",
            "Loss:  0.18112189\n",
            "Epoch:  8\n",
            "Loss:  0.15529221\n",
            "Epoch:  8\n",
            "Loss:  0.19145936\n",
            "Epoch:  8\n",
            "Loss:  0.16081661\n",
            "Epoch:  8\n",
            "Loss:  0.15117773\n",
            "Epoch:  8\n",
            "Loss:  0.14900854\n",
            "Epoch:  8\n",
            "Loss:  0.16369362\n",
            "Epoch:  8\n",
            "Loss:  0.19007057\n",
            "Epoch:  8\n",
            "Loss:  0.13952833\n",
            "Epoch:  8\n",
            "Loss:  0.14836428\n",
            "Epoch:  8\n",
            "Loss:  0.17177844\n",
            "Epoch:  8\n",
            "Loss:  0.16399911\n",
            "Epoch:  8\n",
            "Loss:  0.15024582\n",
            "Epoch:  8\n",
            "Loss:  0.12364982\n",
            "Epoch:  8\n",
            "Loss:  0.18272668\n",
            "Epoch:  8\n",
            "Loss:  0.2138936\n",
            "Epoch:  8\n",
            "Loss:  0.13016571\n",
            "Epoch:  8\n",
            "Loss:  0.15351442\n",
            "Epoch:  8\n",
            "Loss:  0.13796723\n",
            "Epoch:  8\n",
            "Loss:  0.16341548\n",
            "Epoch:  8\n",
            "Loss:  0.14686069\n",
            "Epoch:  8\n",
            "Loss:  0.19604574\n",
            "Epoch:  8\n",
            "Loss:  0.1622146\n",
            "Epoch:  8\n",
            "Loss:  0.1956571\n",
            "Epoch:  8\n",
            "Loss:  0.17922857\n",
            "Epoch:  8\n",
            "Loss:  0.1685686\n",
            "Epoch:  8\n",
            "Loss:  0.14261104\n",
            "Epoch:  8\n",
            "Loss:  0.19752398\n",
            "Epoch:  8\n",
            "Loss:  0.15839478\n",
            "Epoch:  8\n",
            "Loss:  0.15647729\n",
            "Epoch:  8\n",
            "Loss:  0.21696758\n",
            "Epoch:  8\n",
            "Loss:  0.15098366\n",
            "Epoch:  8\n",
            "Loss:  0.20500901\n",
            "Epoch:  8\n",
            "Loss:  0.17655969\n",
            "Epoch:  8\n",
            "Loss:  0.12940991\n",
            "Epoch:  8\n",
            "Loss:  0.17814346\n",
            "Epoch:  8\n",
            "Loss:  0.16862896\n",
            "Epoch:  8\n",
            "Loss:  0.1572493\n",
            "Epoch:  8\n",
            "Loss:  0.14448552\n",
            "Epoch:  8\n",
            "Loss:  0.17800476\n",
            "Epoch:  8\n",
            "Loss:  0.16412294\n",
            "Epoch:  8\n",
            "Loss:  0.1488257\n",
            "Epoch:  8\n",
            "Loss:  0.14859739\n",
            "Epoch:  8\n",
            "Loss:  0.1587773\n",
            "Epoch:  8\n",
            "Loss:  0.16119364\n",
            "Epoch:  8\n",
            "Loss:  0.11886153\n",
            "Epoch:  8\n",
            "Loss:  0.14936855\n",
            "Epoch:  8\n",
            "Loss:  0.17215165\n",
            "Epoch:  8\n",
            "Loss:  0.16605255\n",
            "Epoch:  8\n",
            "Loss:  0.17596929\n",
            "Epoch:  8\n",
            "Loss:  0.18519649\n",
            "Epoch:  8\n",
            "Loss:  0.17620647\n",
            "Epoch:  8\n",
            "Loss:  0.16481467\n",
            "Epoch:  8\n",
            "Loss:  0.16518177\n",
            "Epoch:  8\n",
            "Loss:  0.13736601\n",
            "Epoch:  8\n",
            "Loss:  0.1700975\n",
            "Epoch:  8\n",
            "Loss:  0.16588673\n",
            "Epoch:  8\n",
            "Loss:  0.18516643\n",
            "Epoch:  8\n",
            "Loss:  0.1789948\n",
            "Epoch:  8\n",
            "Loss:  0.15768078\n",
            "Epoch:  8\n",
            "Loss:  0.13313803\n",
            "Epoch:  8\n",
            "Loss:  0.19533715\n",
            "Epoch:  8\n",
            "Loss:  0.14764456\n",
            "Epoch:  8\n",
            "Loss:  0.21149567\n",
            "Epoch:  8\n",
            "Loss:  0.15384404\n",
            "Epoch:  8\n",
            "Loss:  0.15658736\n",
            "Epoch:  8\n",
            "Loss:  0.20186314\n",
            "Epoch:  8\n",
            "Loss:  0.114487685\n",
            "Epoch:  8\n",
            "Loss:  0.15321311\n",
            "Epoch:  8\n",
            "Loss:  0.17743434\n",
            "Epoch:  8\n",
            "Loss:  0.1534908\n",
            "Epoch:  8\n",
            "Loss:  0.16104087\n",
            "Epoch:  8\n",
            "Loss:  0.13262682\n",
            "Epoch:  8\n",
            "Loss:  0.17599821\n",
            "Epoch:  8\n",
            "Loss:  0.24695385\n",
            "Epoch:  8\n",
            "Loss:  0.17862844\n",
            "Epoch:  8\n",
            "Loss:  0.15600051\n",
            "Epoch:  8\n",
            "Loss:  0.1654521\n",
            "Epoch:  8\n",
            "Loss:  0.19799414\n",
            "Epoch:  8\n",
            "Loss:  0.18652995\n",
            "Epoch:  8\n",
            "Loss:  0.20260039\n",
            "Epoch:  8\n",
            "Loss:  0.14976805\n",
            "Epoch:  8\n",
            "Loss:  0.16474763\n",
            "Epoch:  8\n",
            "Loss:  0.20252171\n",
            "Epoch:  8\n",
            "Loss:  0.19684431\n",
            "Epoch:  8\n",
            "Loss:  0.18312478\n",
            "Epoch:  8\n",
            "Loss:  0.16223523\n",
            "Epoch:  8\n",
            "Loss:  0.2135179\n",
            "Epoch:  8\n",
            "Loss:  0.19098057\n",
            "Epoch:  8\n",
            "Loss:  0.13838628\n",
            "Epoch:  8\n",
            "Loss:  0.16673797\n",
            "Epoch:  8\n",
            "Loss:  0.15333837\n",
            "Epoch:  8\n",
            "Loss:  0.14746633\n",
            "Epoch:  8\n",
            "Loss:  0.18742746\n",
            "Epoch:  8\n",
            "Loss:  0.17464106\n",
            "Epoch:  8\n",
            "Loss:  0.18188287\n",
            "Epoch:  8\n",
            "Loss:  0.20065264\n",
            "Epoch:  8\n",
            "Loss:  0.15803783\n",
            "Epoch:  8\n",
            "Loss:  0.22196062\n",
            "Epoch:  8\n",
            "Loss:  0.16765794\n",
            "Epoch:  8\n",
            "Loss:  0.19211183\n",
            "Epoch:  8\n",
            "Loss:  0.18070045\n",
            "Epoch:  8\n",
            "Loss:  0.15236887\n",
            "Epoch:  8\n",
            "Loss:  0.15133223\n",
            "Epoch:  8\n",
            "Loss:  0.15675505\n",
            "Epoch:  8\n",
            "Loss:  0.20378955\n",
            "Epoch:  8\n",
            "Loss:  0.13461335\n",
            "Epoch:  8\n",
            "Loss:  0.15939364\n",
            "Epoch:  8\n",
            "Loss:  0.15677068\n",
            "Epoch:  8\n",
            "Loss:  0.17325965\n",
            "Epoch:  8\n",
            "Loss:  0.15425457\n",
            "Epoch:  8\n",
            "Loss:  0.23534417\n",
            "Epoch:  8\n",
            "Loss:  0.18893285\n",
            "Epoch:  8\n",
            "Loss:  0.20113495\n",
            "Epoch:  8\n",
            "Loss:  0.1442184\n",
            "Epoch:  8\n",
            "Loss:  0.16665426\n",
            "Epoch:  8\n",
            "Loss:  0.12655005\n",
            "Epoch:  8\n",
            "Loss:  0.20343205\n",
            "Epoch:  8\n",
            "Loss:  0.14996798\n",
            "Epoch:  8\n",
            "Loss:  0.15341878\n",
            "Epoch:  8\n",
            "Loss:  0.13443093\n",
            "Epoch:  8\n",
            "Loss:  0.15408143\n",
            "Epoch:  8\n",
            "Loss:  0.15763906\n",
            "Epoch:  8\n",
            "Loss:  0.145641\n",
            "Epoch:  8\n",
            "Loss:  0.13194802\n",
            "Epoch:  8\n",
            "Loss:  0.18188079\n",
            "Epoch:  8\n",
            "Loss:  0.13530967\n",
            "Epoch:  8\n",
            "Loss:  0.16121201\n",
            "Epoch:  8\n",
            "Loss:  0.18898049\n",
            "Epoch:  8\n",
            "Loss:  0.17774065\n",
            "Epoch:  8\n",
            "Loss:  0.17945483\n",
            "Epoch:  8\n",
            "Loss:  0.16961184\n",
            "Epoch:  8\n",
            "Loss:  0.17696749\n",
            "Epoch:  8\n",
            "Loss:  0.14681654\n",
            "Epoch:  8\n",
            "Loss:  0.19998902\n",
            "Epoch:  8\n",
            "Loss:  0.17140146\n",
            "Epoch:  8\n",
            "Loss:  0.1520501\n",
            "Epoch:  8\n",
            "Loss:  0.15837374\n",
            "Epoch:  8\n",
            "Loss:  0.2519424\n",
            "Epoch:  8\n",
            "Loss:  0.18631624\n",
            "Epoch:  8\n",
            "Loss:  0.20408285\n",
            "Epoch:  8\n",
            "Loss:  0.2037609\n",
            "Epoch:  8\n",
            "Loss:  0.13597758\n",
            "Epoch:  8\n",
            "Loss:  0.21158096\n",
            "Epoch:  8\n",
            "Loss:  0.18822633\n",
            "Epoch:  8\n",
            "Loss:  0.2226193\n",
            "Epoch:  8\n",
            "Loss:  0.10946081\n",
            "Epoch:  8\n",
            "Loss:  0.16722143\n",
            "Epoch:  8\n",
            "Loss:  0.19444318\n",
            "Epoch:  8\n",
            "Loss:  0.19364278\n",
            "Epoch:  8\n",
            "Loss:  0.21924391\n",
            "Epoch:  8\n",
            "Loss:  0.12795179\n",
            "Epoch:  8\n",
            "Loss:  0.19488482\n",
            "Epoch:  8\n",
            "Loss:  0.15484855\n",
            "Epoch:  8\n",
            "Loss:  0.19124886\n",
            "Epoch:  8\n",
            "Loss:  0.18036444\n",
            "Epoch:  8\n",
            "Loss:  0.16732557\n",
            "Epoch:  8\n",
            "Loss:  0.19639711\n",
            "Epoch:  8\n",
            "Loss:  0.18041454\n",
            "Epoch:  9\n",
            "Loss:  0.09786151\n",
            "Epoch:  9\n",
            "Loss:  0.08592713\n",
            "Epoch:  9\n",
            "Loss:  0.13201335\n",
            "Epoch:  9\n",
            "Loss:  0.12065971\n",
            "Epoch:  9\n",
            "Loss:  0.123995006\n",
            "Epoch:  9\n",
            "Loss:  0.1063264\n",
            "Epoch:  9\n",
            "Loss:  0.10432483\n",
            "Epoch:  9\n",
            "Loss:  0.09992947\n",
            "Epoch:  9\n",
            "Loss:  0.08800395\n",
            "Epoch:  9\n",
            "Loss:  0.09413226\n",
            "Epoch:  9\n",
            "Loss:  0.110759355\n",
            "Epoch:  9\n",
            "Loss:  0.10744111\n",
            "Epoch:  9\n",
            "Loss:  0.13795479\n",
            "Epoch:  9\n",
            "Loss:  0.13090605\n",
            "Epoch:  9\n",
            "Loss:  0.12739146\n",
            "Epoch:  9\n",
            "Loss:  0.10076445\n",
            "Epoch:  9\n",
            "Loss:  0.10034101\n",
            "Epoch:  9\n",
            "Loss:  0.10350897\n",
            "Epoch:  9\n",
            "Loss:  0.112826094\n",
            "Epoch:  9\n",
            "Loss:  0.10835483\n",
            "Epoch:  9\n",
            "Loss:  0.110531285\n",
            "Epoch:  9\n",
            "Loss:  0.13143116\n",
            "Epoch:  9\n",
            "Loss:  0.12885566\n",
            "Epoch:  9\n",
            "Loss:  0.095568284\n",
            "Epoch:  9\n",
            "Loss:  0.10598292\n",
            "Epoch:  9\n",
            "Loss:  0.09820512\n",
            "Epoch:  9\n",
            "Loss:  0.11442117\n",
            "Epoch:  9\n",
            "Loss:  0.09861032\n",
            "Epoch:  9\n",
            "Loss:  0.05999024\n",
            "Epoch:  9\n",
            "Loss:  0.105096295\n",
            "Epoch:  9\n",
            "Loss:  0.10951445\n",
            "Epoch:  9\n",
            "Loss:  0.11208083\n",
            "Epoch:  9\n",
            "Loss:  0.10166804\n",
            "Epoch:  9\n",
            "Loss:  0.13503502\n",
            "Epoch:  9\n",
            "Loss:  0.13366836\n",
            "Epoch:  9\n",
            "Loss:  0.11609294\n",
            "Epoch:  9\n",
            "Loss:  0.07748841\n",
            "Epoch:  9\n",
            "Loss:  0.13560179\n",
            "Epoch:  9\n",
            "Loss:  0.11633617\n",
            "Epoch:  9\n",
            "Loss:  0.121300004\n",
            "Epoch:  9\n",
            "Loss:  0.11341711\n",
            "Epoch:  9\n",
            "Loss:  0.15079993\n",
            "Epoch:  9\n",
            "Loss:  0.11783372\n",
            "Epoch:  9\n",
            "Loss:  0.13136132\n",
            "Epoch:  9\n",
            "Loss:  0.118496075\n",
            "Epoch:  9\n",
            "Loss:  0.086453274\n",
            "Epoch:  9\n",
            "Loss:  0.09844181\n",
            "Epoch:  9\n",
            "Loss:  0.10838588\n",
            "Epoch:  9\n",
            "Loss:  0.098592415\n",
            "Epoch:  9\n",
            "Loss:  0.11995926\n",
            "Epoch:  9\n",
            "Loss:  0.14914645\n",
            "Epoch:  9\n",
            "Loss:  0.08576406\n",
            "Epoch:  9\n",
            "Loss:  0.08765185\n",
            "Epoch:  9\n",
            "Loss:  0.11509186\n",
            "Epoch:  9\n",
            "Loss:  0.062318366\n",
            "Epoch:  9\n",
            "Loss:  0.10910193\n",
            "Epoch:  9\n",
            "Loss:  0.14152703\n",
            "Epoch:  9\n",
            "Loss:  0.10070495\n",
            "Epoch:  9\n",
            "Loss:  0.14167479\n",
            "Epoch:  9\n",
            "Loss:  0.117532626\n",
            "Epoch:  9\n",
            "Loss:  0.11298065\n",
            "Epoch:  9\n",
            "Loss:  0.14247154\n",
            "Epoch:  9\n",
            "Loss:  0.14529082\n",
            "Epoch:  9\n",
            "Loss:  0.14085375\n",
            "Epoch:  9\n",
            "Loss:  0.12252788\n",
            "Epoch:  9\n",
            "Loss:  0.11794545\n",
            "Epoch:  9\n",
            "Loss:  0.14552584\n",
            "Epoch:  9\n",
            "Loss:  0.108328745\n",
            "Epoch:  9\n",
            "Loss:  0.12377598\n",
            "Epoch:  9\n",
            "Loss:  0.1015083\n",
            "Epoch:  9\n",
            "Loss:  0.16421875\n",
            "Epoch:  9\n",
            "Loss:  0.12613137\n",
            "Epoch:  9\n",
            "Loss:  0.124688186\n",
            "Epoch:  9\n",
            "Loss:  0.11688373\n",
            "Epoch:  9\n",
            "Loss:  0.12322076\n",
            "Epoch:  9\n",
            "Loss:  0.11577314\n",
            "Epoch:  9\n",
            "Loss:  0.14594254\n",
            "Epoch:  9\n",
            "Loss:  0.13137537\n",
            "Epoch:  9\n",
            "Loss:  0.12830395\n",
            "Epoch:  9\n",
            "Loss:  0.087335475\n",
            "Epoch:  9\n",
            "Loss:  0.1404308\n",
            "Epoch:  9\n",
            "Loss:  0.13786186\n",
            "Epoch:  9\n",
            "Loss:  0.12424908\n",
            "Epoch:  9\n",
            "Loss:  0.13442074\n",
            "Epoch:  9\n",
            "Loss:  0.14467384\n",
            "Epoch:  9\n",
            "Loss:  0.12013304\n",
            "Epoch:  9\n",
            "Loss:  0.13700084\n",
            "Epoch:  9\n",
            "Loss:  0.086366445\n",
            "Epoch:  9\n",
            "Loss:  0.11228635\n",
            "Epoch:  9\n",
            "Loss:  0.13734238\n",
            "Epoch:  9\n",
            "Loss:  0.16368833\n",
            "Epoch:  9\n",
            "Loss:  0.10287414\n",
            "Epoch:  9\n",
            "Loss:  0.110210024\n",
            "Epoch:  9\n",
            "Loss:  0.07693253\n",
            "Epoch:  9\n",
            "Loss:  0.12833755\n",
            "Epoch:  9\n",
            "Loss:  0.13161477\n",
            "Epoch:  9\n",
            "Loss:  0.13011287\n",
            "Epoch:  9\n",
            "Loss:  0.13908409\n",
            "Epoch:  9\n",
            "Loss:  0.12608112\n",
            "Epoch:  9\n",
            "Loss:  0.10615474\n",
            "Epoch:  9\n",
            "Loss:  0.092766136\n",
            "Epoch:  9\n",
            "Loss:  0.13554335\n",
            "Epoch:  9\n",
            "Loss:  0.099015296\n",
            "Epoch:  9\n",
            "Loss:  0.16673483\n",
            "Epoch:  9\n",
            "Loss:  0.1075989\n",
            "Epoch:  9\n",
            "Loss:  0.115748204\n",
            "Epoch:  9\n",
            "Loss:  0.09453173\n",
            "Epoch:  9\n",
            "Loss:  0.09219703\n",
            "Epoch:  9\n",
            "Loss:  0.13415486\n",
            "Epoch:  9\n",
            "Loss:  0.0993879\n",
            "Epoch:  9\n",
            "Loss:  0.13287103\n",
            "Epoch:  9\n",
            "Loss:  0.10504787\n",
            "Epoch:  9\n",
            "Loss:  0.14443946\n",
            "Epoch:  9\n",
            "Loss:  0.15041164\n",
            "Epoch:  9\n",
            "Loss:  0.1046301\n",
            "Epoch:  9\n",
            "Loss:  0.14021946\n",
            "Epoch:  9\n",
            "Loss:  0.12713808\n",
            "Epoch:  9\n",
            "Loss:  0.12284677\n",
            "Epoch:  9\n",
            "Loss:  0.1238348\n",
            "Epoch:  9\n",
            "Loss:  0.13807394\n",
            "Epoch:  9\n",
            "Loss:  0.14640173\n",
            "Epoch:  9\n",
            "Loss:  0.12962656\n",
            "Epoch:  9\n",
            "Loss:  0.09772313\n",
            "Epoch:  9\n",
            "Loss:  0.10572096\n",
            "Epoch:  9\n",
            "Loss:  0.1643993\n",
            "Epoch:  9\n",
            "Loss:  0.1276139\n",
            "Epoch:  9\n",
            "Loss:  0.11347721\n",
            "Epoch:  9\n",
            "Loss:  0.09899627\n",
            "Epoch:  9\n",
            "Loss:  0.10956148\n",
            "Epoch:  9\n",
            "Loss:  0.12556958\n",
            "Epoch:  9\n",
            "Loss:  0.116844654\n",
            "Epoch:  9\n",
            "Loss:  0.15407988\n",
            "Epoch:  9\n",
            "Loss:  0.15174943\n",
            "Epoch:  9\n",
            "Loss:  0.12710917\n",
            "Epoch:  9\n",
            "Loss:  0.110254765\n",
            "Epoch:  9\n",
            "Loss:  0.093979366\n",
            "Epoch:  9\n",
            "Loss:  0.12788294\n",
            "Epoch:  9\n",
            "Loss:  0.15386108\n",
            "Epoch:  9\n",
            "Loss:  0.11736794\n",
            "Epoch:  9\n",
            "Loss:  0.15055586\n",
            "Epoch:  9\n",
            "Loss:  0.07449041\n",
            "Epoch:  9\n",
            "Loss:  0.15166251\n",
            "Epoch:  9\n",
            "Loss:  0.12761131\n",
            "Epoch:  9\n",
            "Loss:  0.16703564\n",
            "Epoch:  9\n",
            "Loss:  0.12203026\n",
            "Epoch:  9\n",
            "Loss:  0.11772716\n",
            "Epoch:  9\n",
            "Loss:  0.17266905\n",
            "Epoch:  9\n",
            "Loss:  0.11488874\n",
            "Epoch:  9\n",
            "Loss:  0.14127508\n",
            "Epoch:  9\n",
            "Loss:  0.119254015\n",
            "Epoch:  9\n",
            "Loss:  0.1329238\n",
            "Epoch:  9\n",
            "Loss:  0.14223085\n",
            "Epoch:  9\n",
            "Loss:  0.1490082\n",
            "Epoch:  9\n",
            "Loss:  0.12308121\n",
            "Epoch:  9\n",
            "Loss:  0.13630235\n",
            "Epoch:  9\n",
            "Loss:  0.15747\n",
            "Epoch:  9\n",
            "Loss:  0.12723419\n",
            "Epoch:  9\n",
            "Loss:  0.10823961\n",
            "Epoch:  9\n",
            "Loss:  0.12542413\n",
            "Epoch:  9\n",
            "Loss:  0.1331819\n",
            "Epoch:  9\n",
            "Loss:  0.12872103\n",
            "Epoch:  9\n",
            "Loss:  0.12259428\n",
            "Epoch:  9\n",
            "Loss:  0.12401903\n",
            "Epoch:  9\n",
            "Loss:  0.16386786\n",
            "Epoch:  9\n",
            "Loss:  0.11519836\n",
            "Epoch:  9\n",
            "Loss:  0.11268669\n",
            "Epoch:  9\n",
            "Loss:  0.16564469\n",
            "Epoch:  9\n",
            "Loss:  0.13302411\n",
            "Epoch:  9\n",
            "Loss:  0.14653285\n",
            "Epoch:  9\n",
            "Loss:  0.12645718\n",
            "Epoch:  9\n",
            "Loss:  0.14225943\n",
            "Epoch:  9\n",
            "Loss:  0.11581011\n",
            "Epoch:  9\n",
            "Loss:  0.16218416\n",
            "Epoch:  9\n",
            "Loss:  0.14823782\n",
            "Epoch:  9\n",
            "Loss:  0.15822044\n",
            "Epoch:  9\n",
            "Loss:  0.112741806\n",
            "Epoch:  9\n",
            "Loss:  0.14018606\n",
            "Epoch:  9\n",
            "Loss:  0.14891644\n",
            "Epoch:  9\n",
            "Loss:  0.13005452\n",
            "Epoch:  9\n",
            "Loss:  0.1333004\n",
            "Epoch:  9\n",
            "Loss:  0.1195968\n",
            "Epoch:  9\n",
            "Loss:  0.13320081\n",
            "Epoch:  9\n",
            "Loss:  0.097577274\n",
            "Epoch:  9\n",
            "Loss:  0.15021315\n",
            "Epoch:  9\n",
            "Loss:  0.113086596\n",
            "Epoch:  9\n",
            "Loss:  0.13396238\n",
            "Epoch:  9\n",
            "Loss:  0.09920501\n",
            "Epoch:  9\n",
            "Loss:  0.10279854\n",
            "Epoch:  9\n",
            "Loss:  0.16082063\n",
            "Epoch:  9\n",
            "Loss:  0.13403746\n",
            "Epoch:  9\n",
            "Loss:  0.16717146\n",
            "Epoch:  9\n",
            "Loss:  0.11576166\n",
            "Epoch:  9\n",
            "Loss:  0.15608701\n",
            "Epoch:  9\n",
            "Loss:  0.12543799\n",
            "Epoch:  9\n",
            "Loss:  0.14773159\n",
            "Epoch:  9\n",
            "Loss:  0.09005813\n",
            "Epoch:  9\n",
            "Loss:  0.14508387\n",
            "Epoch:  9\n",
            "Loss:  0.12885056\n",
            "Epoch:  9\n",
            "Loss:  0.18322794\n",
            "Epoch:  9\n",
            "Loss:  0.12678176\n",
            "Epoch:  9\n",
            "Loss:  0.11443684\n",
            "Epoch:  9\n",
            "Loss:  0.12776092\n",
            "Epoch:  9\n",
            "Loss:  0.13937527\n",
            "Epoch:  9\n",
            "Loss:  0.16797909\n",
            "Epoch:  9\n",
            "Loss:  0.16850388\n",
            "Epoch:  9\n",
            "Loss:  0.13177505\n",
            "Epoch:  9\n",
            "Loss:  0.12403698\n",
            "Epoch:  9\n",
            "Loss:  0.14812195\n",
            "Epoch:  9\n",
            "Loss:  0.12838727\n",
            "Epoch:  9\n",
            "Loss:  0.120297864\n",
            "Epoch:  9\n",
            "Loss:  0.10701052\n",
            "Epoch:  9\n",
            "Loss:  0.1361779\n",
            "Epoch:  9\n",
            "Loss:  0.15273544\n",
            "Epoch:  9\n",
            "Loss:  0.11518512\n",
            "Epoch:  9\n",
            "Loss:  0.1403063\n",
            "Epoch:  9\n",
            "Loss:  0.18458033\n",
            "Epoch:  9\n",
            "Loss:  0.12067072\n",
            "Epoch:  9\n",
            "Loss:  0.16320275\n",
            "Epoch:  9\n",
            "Loss:  0.13989356\n",
            "Epoch:  9\n",
            "Loss:  0.19687012\n",
            "Epoch:  9\n",
            "Loss:  0.18307337\n",
            "Epoch:  9\n",
            "Loss:  0.14284816\n",
            "Epoch:  9\n",
            "Loss:  0.1412792\n",
            "Epoch:  9\n",
            "Loss:  0.12724556\n",
            "Epoch:  9\n",
            "Loss:  0.1492208\n",
            "Epoch:  9\n",
            "Loss:  0.11596732\n",
            "Epoch:  9\n",
            "Loss:  0.19134457\n",
            "Epoch:  9\n",
            "Loss:  0.1371683\n",
            "Epoch:  9\n",
            "Loss:  0.13400543\n",
            "Epoch:  9\n",
            "Loss:  0.17464265\n",
            "Epoch:  9\n",
            "Loss:  0.12523521\n",
            "Epoch:  9\n",
            "Loss:  0.13118386\n",
            "Epoch:  9\n",
            "Loss:  0.090667516\n",
            "Epoch:  9\n",
            "Loss:  0.10160408\n",
            "Epoch:  9\n",
            "Loss:  0.19090548\n",
            "Epoch:  9\n",
            "Loss:  0.11291832\n",
            "Epoch:  9\n",
            "Loss:  0.14725259\n",
            "Epoch:  9\n",
            "Loss:  0.13166173\n",
            "Epoch:  9\n",
            "Loss:  0.184597\n",
            "Epoch:  9\n",
            "Loss:  0.10766064\n",
            "Epoch:  9\n",
            "Loss:  0.12033019\n",
            "Epoch:  9\n",
            "Loss:  0.1368449\n",
            "Epoch:  9\n",
            "Loss:  0.1375704\n",
            "Epoch:  9\n",
            "Loss:  0.15046564\n",
            "Epoch:  9\n",
            "Loss:  0.14397112\n",
            "Epoch:  9\n",
            "Loss:  0.11143969\n",
            "Epoch:  9\n",
            "Loss:  0.1892169\n",
            "Epoch:  9\n",
            "Loss:  0.123906374\n",
            "Epoch:  9\n",
            "Loss:  0.13317801\n",
            "Epoch:  9\n",
            "Loss:  0.13640742\n"
          ]
        }
      ],
      "source": [
        "EPOCH = 10\n",
        "for epoch in range(EPOCH):\n",
        "    enc_hidden = encoder.initilize_hidden_state()\n",
        "    total_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "        print('Epoch: ', epoch)\n",
        "        print('Loss: ', batch_loss.numpy())\n",
        "    checkpoint.save(file_prefix='test1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1HgMCCDxOLpQ"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "    sentence = preprocess_senetence(sentence)\n",
        "    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<strat>']], 0)\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "        if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhEwwLg_OLpR",
        "outputId": "a61343a7-ee2d-496f-80f4-f8ea5492afb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7b086cbe1570>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WR0f7vZOLpR",
        "outputId": "b3083909-0824-4cc7-e668-585a0c2db0d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('it s very cold . <end> ', '<strat> hace mucho frio aqui . <end>')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate('hace mucho frio aqui.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43h8Sf3TOphx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
